{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10048507,
          "sourceType": "datasetVersion",
          "datasetId": 6190931
        },
        {
          "sourceId": 10242967,
          "sourceType": "datasetVersion",
          "datasetId": 6334477
        },
        {
          "sourceId": 10316683,
          "sourceType": "datasetVersion",
          "datasetId": 6386966
        }
      ],
      "dockerImageVersionId": 30823,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "name": "cross attention with prompts and weights-1",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24-FYP-Automated-Feedback-Generation/Adaptive-attention/blob/main/cross_attention_with_prompts_and_weights_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "uom200407h_modified_dataset_path = kagglehub.dataset_download('uom200407h/modified-dataset')\n",
        "uom200644f_metacognitive_dataset_path = kagglehub.dataset_download('uom200644f/metacognitive-dataset')\n",
        "bashadithennakoon_metacognitive_feedback_for_algorithm_solving_path = kagglehub.dataset_download('bashadithennakoon/metacognitive-feedback-for-algorithm-solving')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "h_XA7J1LbiI6"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "uom200407h_modified_dataset_path = kagglehub.dataset_download('uom200407h/modified-dataset')\n",
        "uom200644f_metacognitive_dataset_path = kagglehub.dataset_download('uom200644f/metacognitive-dataset')\n",
        "bashadithennakoon_metacognitive_feedback_for_algorithm_solving_path = kagglehub.dataset_download('bashadithennakoon/metacognitive-feedback-for-algorithm-solving')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "WZPr7xkva7Id"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "XOEjCcHQa7Ii",
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:16.945479Z",
          "iopub.execute_input": "2025-01-10T08:41:16.94578Z",
          "iopub.status.idle": "2025-01-10T08:41:17.23795Z",
          "shell.execute_reply.started": "2025-01-10T08:41:16.945752Z",
          "shell.execute_reply": "2025-01-10T08:41:17.237016Z"
        },
        "outputId": "6e18eafa-c7b3-4bb9-ab4f-dedaf92a22b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/input/metacognitive-dataset/metacognitive-dataset.csv\n/kaggle/input/modified-dataset/modified_dataset.csv\n/kaggle/input/metacognitive-feedback-for-algorithm-solving/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:19.274393Z",
          "iopub.execute_input": "2025-01-10T08:41:19.274823Z",
          "iopub.status.idle": "2025-01-10T08:41:23.67472Z",
          "shell.execute_reply.started": "2025-01-10T08:41:19.274798Z",
          "shell.execute_reply": "2025-01-10T08:41:23.67361Z"
        },
        "id": "TYCjdbZUa7Ij",
        "outputId": "1854ce93-b297-4c35-e5fc-59e5bbd37f61"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AutoModel, AutoTokenizer, GPT2Model,GPT2Tokenizer,GPT2LMHeadModel\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration , T5Tokenizer , T5Model\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:23.67634Z",
          "iopub.execute_input": "2025-01-10T08:41:23.676649Z",
          "iopub.status.idle": "2025-01-10T08:41:28.598474Z",
          "shell.execute_reply.started": "2025-01-10T08:41:23.676627Z",
          "shell.execute_reply": "2025-01-10T08:41:28.597727Z"
        },
        "id": "IgJFcjXoa7Il"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:28.599923Z",
          "iopub.execute_input": "2025-01-10T08:41:28.600346Z",
          "iopub.status.idle": "2025-01-10T08:41:28.653213Z",
          "shell.execute_reply.started": "2025-01-10T08:41:28.600323Z",
          "shell.execute_reply": "2025-01-10T08:41:28.652355Z"
        },
        "id": "DpWbDwTja7Im"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:28.65445Z",
          "iopub.execute_input": "2025-01-10T08:41:28.654669Z",
          "iopub.status.idle": "2025-01-10T08:41:28.673965Z",
          "shell.execute_reply.started": "2025-01-10T08:41:28.654648Z",
          "shell.execute_reply": "2025-01-10T08:41:28.673166Z"
        },
        "id": "kdvnV1Efa7Im",
        "outputId": "802e1d3c-dc5d-41ac-d16a-f50ffb3dacf8"
      },
      "outputs": [
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"t5-base\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:28.674895Z",
          "iopub.execute_input": "2025-01-10T08:41:28.675188Z",
          "iopub.status.idle": "2025-01-10T08:41:28.688943Z",
          "shell.execute_reply.started": "2025-01-10T08:41:28.675159Z",
          "shell.execute_reply": "2025-01-10T08:41:28.688333Z"
        },
        "id": "OvfQPyhKa7In"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:28.689713Z",
          "iopub.execute_input": "2025-01-10T08:41:28.69001Z",
          "iopub.status.idle": "2025-01-10T08:41:29.526736Z",
          "shell.execute_reply.started": "2025-01-10T08:41:28.689981Z",
          "shell.execute_reply": "2025-01-10T08:41:29.525763Z"
        },
        "id": "EPXot-9Sa7In",
        "outputId": "c202dd01-1b26-4400-cd53-9c6f676a8c2a",
        "colab": {
          "referenced_widgets": [
            "6b7e83d7d27b49a698e61a2d145fe676",
            "1cd0279fd43349ff90ccea2d1a1af33c",
            "33a5304519034065b2a848de8db6518b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6b7e83d7d27b49a698e61a2d145fe676"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1cd0279fd43349ff90ccea2d1a1af33c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33a5304519034065b2a848de8db6518b"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer.vocab_size"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:29.528609Z",
          "iopub.execute_input": "2025-01-10T08:41:29.52882Z",
          "iopub.status.idle": "2025-01-10T08:41:29.533409Z",
          "shell.execute_reply.started": "2025-01-10T08:41:29.528802Z",
          "shell.execute_reply": "2025-01-10T08:41:29.532639Z"
        },
        "id": "qX1l99_3a7Io",
        "outputId": "803d67af-d77e-4ecf-8be7-b3813bdd5551"
      },
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/plain": "32100"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#set the max length to model's default present max length\n",
        "t5_tokenizer.model_max_length = t5_tokenizer.model_max_length"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:29.534313Z",
          "iopub.execute_input": "2025-01-10T08:41:29.534511Z",
          "iopub.status.idle": "2025-01-10T08:41:29.548321Z",
          "shell.execute_reply.started": "2025-01-10T08:41:29.534494Z",
          "shell.execute_reply": "2025-01-10T08:41:29.547542Z"
        },
        "id": "9XRWaOWWa7Ip"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:29.549039Z",
          "iopub.execute_input": "2025-01-10T08:41:29.549354Z",
          "iopub.status.idle": "2025-01-10T08:41:30.418151Z",
          "shell.execute_reply.started": "2025-01-10T08:41:29.549313Z",
          "shell.execute_reply": "2025-01-10T08:41:30.417486Z"
        },
        "id": "tLqjpzCxa7Ip",
        "outputId": "fd776e6d-245d-4ab9-cc78-99e969b0a830",
        "colab": {
          "referenced_widgets": [
            "bfb2a587745b4f0182d68d485b53a08a",
            "633fe29b8521477399b0d175392c4d8c",
            "229ab741aa1641f2a69ac324d096722e",
            "7a5d2018f2a94fd4941d27d9392236ff",
            "faeb17487dfa4280a4247395e133ff70"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfb2a587745b4f0182d68d485b53a08a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "633fe29b8521477399b0d175392c4d8c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "229ab741aa1641f2a69ac324d096722e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a5d2018f2a94fd4941d27d9392236ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faeb17487dfa4280a4247395e133ff70"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:30.41889Z",
          "iopub.execute_input": "2025-01-10T08:41:30.419091Z",
          "iopub.status.idle": "2025-01-10T08:41:30.422588Z",
          "shell.execute_reply.started": "2025-01-10T08:41:30.419073Z",
          "shell.execute_reply": "2025-01-10T08:41:30.421928Z"
        },
        "id": "LVVTv7zfa7Iq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/kaggle/input/metacognitive-feedback-for-algorithm-solving/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:30.423985Z",
          "iopub.execute_input": "2025-01-10T08:41:30.424304Z",
          "iopub.status.idle": "2025-01-10T08:41:32.29995Z",
          "shell.execute_reply.started": "2025-01-10T08:41:30.424258Z",
          "shell.execute_reply": "2025-01-10T08:41:32.299214Z"
        },
        "id": "XrY_OzWca7Iq"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:32.301132Z",
          "iopub.execute_input": "2025-01-10T08:41:32.301393Z",
          "iopub.status.idle": "2025-01-10T08:41:32.30747Z",
          "shell.execute_reply.started": "2025-01-10T08:41:32.30137Z",
          "shell.execute_reply": "2025-01-10T08:41:32.306653Z"
        },
        "id": "nqzlVJm_a7Ir",
        "outputId": "d80fa861-e2cf-48b2-effc-9fc3d85a4816"
      },
      "outputs": [
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['Question 1', 'Response 1', 'Right answer 1', 'Q01', 'Q02', 'Q03',\n       'Q04', 'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13',\n       'Q14', 'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(\n",
        "    columns={\n",
        "        'Question 1': 'Problem',\n",
        "        'Response 1': 'Student_code',\n",
        "        'Right answer 1': 'Expected_code'\n",
        "    },\n",
        "    inplace=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:32.308342Z",
          "iopub.execute_input": "2025-01-10T08:41:32.308595Z",
          "iopub.status.idle": "2025-01-10T08:41:32.32838Z",
          "shell.execute_reply.started": "2025-01-10T08:41:32.308574Z",
          "shell.execute_reply": "2025-01-10T08:41:32.327578Z"
        },
        "id": "ugJYy8pVa7Ir"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:32.524863Z",
          "iopub.execute_input": "2025-01-10T08:41:32.525142Z",
          "iopub.status.idle": "2025-01-10T08:41:32.54389Z",
          "shell.execute_reply.started": "2025-01-10T08:41:32.525121Z",
          "shell.execute_reply": "2025-01-10T08:41:32.543234Z"
        },
        "id": "mcjarOz3a7Is",
        "outputId": "bf75bf59-0307-4934-fa53-ecb6138d3e6d"
      },
      "outputs": [
        {
          "execution_count": 15,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                             Problem  \\\n0  Develop a Python program that takes the name o...   \n1  Develop a Python program that takes the name o...   \n2  Develop a Python program that takes the name o...   \n\n                                        Student_code  \\\n0  file_input = input()      file_open = open(fil...   \n1  file_input = input()      file_open = open(fil...   \n2  file_input = input()      file_open = open(fil...   \n\n                                       Expected_code        Q01  \\\n0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n\n             Q02               Q03        Q04            Q05            Q06  \\\n0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n\n                Q07  ...        Q09        Q10            Q11            Q12  \\\n0  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n1  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n2  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n\n             Q13        Q14        Q15               Q16  \\\n0  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n1  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n2  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n\n                                metacognitive_vector  \\\n0  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n1  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n2  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n\n                              metacognitive_feedback  \n0  Your initial code serves as a starting point, ...  \n1  Your code exhibits a solid attempt at reading ...  \n2  It looks like you're in a good place with some...  \n\n[3 rows x 21 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Problem</th>\n      <th>Student_code</th>\n      <th>Expected_code</th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>...</th>\n      <th>Q09</th>\n      <th>Q10</th>\n      <th>Q11</th>\n      <th>Q12</th>\n      <th>Q13</th>\n      <th>Q14</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial code serves as a starting point, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your code exhibits a solid attempt at reading ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>It looks like you're in a good place with some...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "student_prompt = \"This is the combination of the problem desccription and the student provided code.\"\n",
        "context_prompt = \"This is the combination of the problem description and the expected correct answer for that algorithm design question.\"\n",
        "metacognitive_components = [\n",
        "                \"Read\", \"Identify\", \"Rephrase\", \"Examples\", \"Breakdown\", \"Estimate\", \"Plan\",\n",
        "                \"Revise\", \"Verify\", \"AvoidMistakes\", \"MonitorSteps\", \"MonitorProcess\",\n",
        "                \"ValidateConstraints\", \"Confirm\", \"CheckRequirements\", \"Reflect\"\n",
        "            ]\n",
        "\n",
        "metacognition_prompt = (\n",
        "            f\"Metacognitive feedback helps students reflect on their algorithm-solving strategies. \"\n",
        "            f\"The passed metacognitive vector is a 16-dimensional vector describing the student's metacognition profile:  \"\n",
        "            f\"where each dimension represents one of 16 metacognitive components, rated as 1 (Almost never), \"\n",
        "            f\"2 (Sometimes), or 3 (Often). These components include: {', '.join(metacognitive_components)}.\"\n",
        "        )\n",
        "decoder_prompt = \"This is the combination student's metacognition profile and the student's code for the algorithm problem with the problem description itself.\"\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:32.984746Z",
          "iopub.execute_input": "2025-01-10T08:41:32.985023Z",
          "iopub.status.idle": "2025-01-10T08:41:32.989191Z",
          "shell.execute_reply.started": "2025-01-10T08:41:32.984998Z",
          "shell.execute_reply": "2025-01-10T08:41:32.988351Z"
        },
        "id": "L2Hfq58LbiJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_problem_student'] = student_prompt + \"  Problem:  \" + df['Problem'] + \".  Student provided code:  \" + df['Student_code']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:34.974543Z",
          "iopub.execute_input": "2025-01-10T08:41:34.974823Z",
          "iopub.status.idle": "2025-01-10T08:41:35.102822Z",
          "shell.execute_reply.started": "2025-01-10T08:41:34.974798Z",
          "shell.execute_reply": "2025-01-10T08:41:35.101905Z"
        },
        "id": "Z7eLV0EQa7Is"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_problem_expected'] = context_prompt + \" Problem:  \" + df['Problem'] + \".  Expected correct ansswer for the problem:  \" + df['Expected_code']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:35.369632Z",
          "iopub.execute_input": "2025-01-10T08:41:35.369912Z",
          "iopub.status.idle": "2025-01-10T08:41:35.464073Z",
          "shell.execute_reply.started": "2025-01-10T08:41:35.369885Z",
          "shell.execute_reply": "2025-01-10T08:41:35.463376Z"
        },
        "id": "7GpCPwv8a7Is"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_metacogntion_prompt'] =  metacognition_prompt + \"Here is the student's metacognition vector: \" + df['metacognitive_vector']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:35.750843Z",
          "iopub.execute_input": "2025-01-10T08:41:35.75112Z",
          "iopub.status.idle": "2025-01-10T08:41:35.759232Z",
          "shell.execute_reply.started": "2025-01-10T08:41:35.751099Z",
          "shell.execute_reply": "2025-01-10T08:41:35.758372Z"
        },
        "id": "ZYp5tO8sbiJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# df['combined_persona_student'] ="
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:36.114184Z",
          "iopub.execute_input": "2025-01-10T08:41:36.1145Z",
          "iopub.status.idle": "2025-01-10T08:41:36.117999Z",
          "shell.execute_reply.started": "2025-01-10T08:41:36.114478Z",
          "shell.execute_reply": "2025-01-10T08:41:36.117124Z"
        },
        "id": "xMEuETjwbiJB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_metacogntion_prompt'][20]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:36.468812Z",
          "iopub.execute_input": "2025-01-10T08:41:36.469117Z",
          "iopub.status.idle": "2025-01-10T08:41:36.474068Z",
          "shell.execute_reply.started": "2025-01-10T08:41:36.469091Z",
          "shell.execute_reply": "2025-01-10T08:41:36.473299Z"
        },
        "id": "egNdrBK0biJB",
        "outputId": "323fa0b3-af37-4008-be53-d029fe7b543b"
      },
      "outputs": [
        {
          "execution_count": 21,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"Metacognitive feedback helps students reflect on their algorithm-solving strategies. The passed metacognitive vector is a 16-dimensional vector describing the student's metacognition profile:  where each dimension represents one of 16 metacognitive components, rated as 1 (Almost never), 2 (Sometimes), or 3 (Often). These components include: Read, Identify, Rephrase, Examples, Breakdown, Estimate, Plan, Revise, Verify, AvoidMistakes, MonitorSteps, MonitorProcess, ValidateConstraints, Confirm, CheckRequirements, Reflect.Here is the student's metacognition vector: ['2 ', '3 ', '2 ', '3 ', '2 ', '2 ', '1 ', '2 ', '3 ', '3 ', '3 ', '3 ', '3 ', '3 ', '2 ', '2 ']\""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:38.878023Z",
          "iopub.execute_input": "2025-01-10T08:41:38.878359Z",
          "iopub.status.idle": "2025-01-10T08:41:38.883218Z",
          "shell.execute_reply.started": "2025-01-10T08:41:38.878327Z",
          "shell.execute_reply": "2025-01-10T08:41:38.88251Z"
        },
        "id": "-EMODMJCa7It",
        "outputId": "a52446ad-fb3f-407e-f25a-de7831b531f3"
      },
      "outputs": [
        {
          "execution_count": 22,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Index(['Problem', 'Student_code', 'Expected_code', 'Q01', 'Q02', 'Q03', 'Q04',\n       'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14',\n       'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback',\n       'combined_problem_student', 'combined_problem_expected',\n       'combined_metacogntion_prompt'],\n      dtype='object')"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Problem', 'metacognitive_feedback', 'combined_problem_student','Student_code'], inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:39.203634Z",
          "iopub.execute_input": "2025-01-10T08:41:39.203893Z",
          "iopub.status.idle": "2025-01-10T08:41:39.227639Z",
          "shell.execute_reply.started": "2025-01-10T08:41:39.203873Z",
          "shell.execute_reply": "2025-01-10T08:41:39.226743Z"
        },
        "id": "94NeCGFua7It"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:39.52499Z",
          "iopub.execute_input": "2025-01-10T08:41:39.525319Z",
          "iopub.status.idle": "2025-01-10T08:41:39.528796Z",
          "shell.execute_reply.started": "2025-01-10T08:41:39.52526Z",
          "shell.execute_reply": "2025-01-10T08:41:39.528063Z"
        },
        "id": "9wKnq90Ua7Iu"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:41.604468Z",
          "iopub.execute_input": "2025-01-10T08:41:41.604756Z",
          "iopub.status.idle": "2025-01-10T08:41:41.633127Z",
          "shell.execute_reply.started": "2025-01-10T08:41:41.604734Z",
          "shell.execute_reply": "2025-01-10T08:41:41.632297Z"
        },
        "id": "ZzXH3PICa7Iu",
        "outputId": "65daf10a-0b96-4de1-d83e-d0c8544943d9"
      },
      "outputs": [
        {
          "execution_count": 25,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Problem                         0\nStudent_code                    0\nExpected_code                   0\nQ01                             0\nQ02                             0\nQ03                             0\nQ04                             0\nQ05                             0\nQ06                             0\nQ07                             0\nQ08                             0\nQ09                             0\nQ10                             0\nQ11                             0\nQ12                             0\nQ13                             0\nQ14                             0\nQ15                             0\nQ16                             0\nmetacognitive_vector            0\nmetacognitive_feedback          0\ncombined_problem_student        0\ncombined_problem_expected       0\ncombined_metacogntion_prompt    0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df['metacognitive_feedback'][100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:43.559187Z",
          "iopub.execute_input": "2025-01-10T08:41:43.559537Z",
          "iopub.status.idle": "2025-01-10T08:41:43.564871Z",
          "shell.execute_reply.started": "2025-01-10T08:41:43.55951Z",
          "shell.execute_reply": "2025-01-10T08:41:43.564073Z"
        },
        "id": "WtKweTkea7Iu",
        "outputId": "0774ff82-b774-4624-fe2e-16514982e6a8"
      },
      "outputs": [
        {
          "execution_count": 26,
          "output_type": "execute_result",
          "data": {
            "text/plain": "\"Your current implementation shows a good effort in structuring your code with functions, but there are some areas where further refinement is necessary to meet the problem requirements. First, consider how you're capturing the relationships between birth years and heights. While you are correctly gathering names, birthdates, and heights into a dictionary, think about how you can aggregate heights by decade instead of year. This will streamline the calculation of average heights. It’s crucial to loop through your input list once to comprehend and process the data before beginning any calculations for averaging—possibly consolidating this logic in your `calculate_average_height` function. Also, ensure that you are converting heights to the correct data type before performing any arithmetic operations. Additionally, take a closer look at how you’re determining the range of decades; right now it seems like you may be focusing on unique years instead of decades. Consider creating a systematic structure that easily categorizes each height into its corresponding decade bucket. Furthermore, as you develop your code, remember to monitor your program's flow and adjust accordingly—this is especially important when it comes to function calls and data structure manipulations. Establishing a plan before implementation can significantly enhance your problem-solving process and avoid errors stemming from assumptions. Overall, maintain momentum and continue refining your approach by checking each component against the problem's requirements, thus ensuring coherence and completeness in your solution.\""
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:43.893784Z",
          "iopub.execute_input": "2025-01-10T08:41:43.894085Z",
          "iopub.status.idle": "2025-01-10T08:41:43.913757Z",
          "shell.execute_reply.started": "2025-01-10T08:41:43.894058Z",
          "shell.execute_reply": "2025-01-10T08:41:43.913083Z"
        },
        "id": "t_EBOaYQa7Iv",
        "outputId": "652a85b4-a545-430f-dfb8-46bc47684d23"
      },
      "outputs": [
        {
          "execution_count": 27,
          "output_type": "execute_result",
          "data": {
            "text/plain": "                                             Problem  \\\n0  Develop a Python program that takes the name o...   \n1  Develop a Python program that takes the name o...   \n2  Develop a Python program that takes the name o...   \n3  Develop a Python program that takes the name o...   \n4  Develop a Python program that takes the name o...   \n\n                                        Student_code  \\\n0  file_input = input()      file_open = open(fil...   \n1  file_input = input()      file_open = open(fil...   \n2  file_input = input()      file_open = open(fil...   \n3  file_input = input()      file_open = open(fil...   \n4  file_input = input()      file_open = open(fil...   \n\n                                       Expected_code        Q01  \\\n0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n3  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n4  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n\n             Q02               Q03        Q04            Q05            Q06  \\\n0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n3  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n4  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n\n                Q07  ...            Q12            Q13        Q14        Q15  \\\n0  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  3 : Often  3 : Often   \n1  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  3 : Often  3 : Often   \n2  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  3 : Often  3 : Often   \n3  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  3 : Often  3 : Often   \n4  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  3 : Often  3 : Often   \n\n                Q16                               metacognitive_vector  \\\n0  1 : Almost Never  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n1  1 : Almost Never  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n2  1 : Almost Never  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n3  1 : Almost Never  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n4  1 : Almost Never  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n\n                              metacognitive_feedback  \\\n0  Your initial code serves as a starting point, ...   \n1  Your code exhibits a solid attempt at reading ...   \n2  It looks like you're in a good place with some...   \n3  Your approach to reading the file and splittin...   \n4  Your initial approach to the problem is a good...   \n\n                            combined_problem_student  \\\n0  This is the combination of the problem desccri...   \n1  This is the combination of the problem desccri...   \n2  This is the combination of the problem desccri...   \n3  This is the combination of the problem desccri...   \n4  This is the combination of the problem desccri...   \n\n                           combined_problem_expected  \\\n0  This is the combination of the problem descrip...   \n1  This is the combination of the problem descrip...   \n2  This is the combination of the problem descrip...   \n3  This is the combination of the problem descrip...   \n4  This is the combination of the problem descrip...   \n\n                        combined_metacogntion_prompt  \n0  Metacognitive feedback helps students reflect ...  \n1  Metacognitive feedback helps students reflect ...  \n2  Metacognitive feedback helps students reflect ...  \n3  Metacognitive feedback helps students reflect ...  \n4  Metacognitive feedback helps students reflect ...  \n\n[5 rows x 24 columns]",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Problem</th>\n      <th>Student_code</th>\n      <th>Expected_code</th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>...</th>\n      <th>Q12</th>\n      <th>Q13</th>\n      <th>Q14</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n      <th>combined_problem_student</th>\n      <th>combined_problem_expected</th>\n      <th>combined_metacogntion_prompt</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial code serves as a starting point, ...</td>\n      <td>This is the combination of the problem desccri...</td>\n      <td>This is the combination of the problem descrip...</td>\n      <td>Metacognitive feedback helps students reflect ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your code exhibits a solid attempt at reading ...</td>\n      <td>This is the combination of the problem desccri...</td>\n      <td>This is the combination of the problem descrip...</td>\n      <td>Metacognitive feedback helps students reflect ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>It looks like you're in a good place with some...</td>\n      <td>This is the combination of the problem desccri...</td>\n      <td>This is the combination of the problem descrip...</td>\n      <td>Metacognitive feedback helps students reflect ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your approach to reading the file and splittin...</td>\n      <td>This is the combination of the problem desccri...</td>\n      <td>This is the combination of the problem descrip...</td>\n      <td>Metacognitive feedback helps students reflect ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial approach to the problem is a good...</td>\n      <td>This is the combination of the problem desccri...</td>\n      <td>This is the combination of the problem descrip...</td>\n      <td>Metacognitive feedback helps students reflect ...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import ast\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataset, t5_tokenizer,gpt2_tokenizer, max_length=512):\n",
        "        self.t5_tokenizer = t5_tokenizer\n",
        "        self.gpt2_tokenizer = gpt2_tokenizer\n",
        "        self.data = dataset\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        metacognitive_prompt = self.data['combined_metacogntion_prompt'][idx]\n",
        "        problem_student_code = self.data['combined_problem_student'][idx]\n",
        "        problem_expected_code = self.data['combined_problem_expected'][idx]\n",
        "        student_code = self.data['Student_code'][idx]\n",
        "        target = self.data['metacognitive_feedback'][idx]\n",
        "\n",
        "        # metacognitive_vector_float = [\n",
        "        # float(item.strip()) for item in ast.literal_eval(metacognitive_vector)]\n",
        "        # metacognition_vector_ids = torch.tensor(metacognitive_vector_float, dtype=torch.float)\n",
        "        metacognition_prompt_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(metacognitive_prompt, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "\n",
        "        problem_student_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(problem_student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "        problem_expected_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(problem_expected_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "\n",
        "        student_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "        target_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(target, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "\n",
        "        return metacognition_prompt_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:45.509256Z",
          "iopub.execute_input": "2025-01-10T08:41:45.509599Z",
          "iopub.status.idle": "2025-01-10T08:41:45.516411Z",
          "shell.execute_reply.started": "2025-01-10T08:41:45.509574Z",
          "shell.execute_reply": "2025-01-10T08:41:45.515643Z"
        },
        "id": "nNEuM_O3a7Iv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(df, t5_tokenizer, gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:47.343624Z",
          "iopub.execute_input": "2025-01-10T08:41:47.343928Z",
          "iopub.status.idle": "2025-01-10T08:41:47.347988Z",
          "shell.execute_reply.started": "2025-01-10T08:41:47.3439Z",
          "shell.execute_reply": "2025-01-10T08:41:47.347087Z"
        },
        "id": "Xjf6vXzJa7Iv"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:47.654027Z",
          "iopub.execute_input": "2025-01-10T08:41:47.654333Z",
          "iopub.status.idle": "2025-01-10T08:41:47.659039Z",
          "shell.execute_reply.started": "2025-01-10T08:41:47.654269Z",
          "shell.execute_reply": "2025-01-10T08:41:47.658178Z"
        },
        "id": "qmSPRdvNa7Iw",
        "outputId": "00ea4518-49d9-441f-a485-b54e674a307e"
      },
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "16803"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "metacognition_prompt_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids = dataset[4000]\n",
        "print(f\"Metacognition vector IDs: {metacognition_prompt_ids}\")\n",
        "print(f\"Expected feedback IDs: {problem_student_code_ids}\")\n",
        "print(f\"Expected encoded feedback IDs: {problem_expected_code_ids}\")\n",
        "print(f\"Student Answer IDs: {student_code_ids.shape}\")\n",
        "print(f\"Target IDs: {target_ids.shape}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:47.993602Z",
          "iopub.execute_input": "2025-01-10T08:41:47.99382Z",
          "iopub.status.idle": "2025-01-10T08:41:48.052453Z",
          "shell.execute_reply.started": "2025-01-10T08:41:47.993801Z",
          "shell.execute_reply": "2025-01-10T08:41:48.051712Z"
        },
        "id": "n5JGeIpza7Ix",
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "outputId": "ce2db312-8de3-4a8e-cd7b-b1e1fa68d4ac"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Metacognition vector IDs: tensor([14204,    75, 12905,  3268,  3160,  1691,   481,  3548,    30,    70,\n        12628,    18,  6065,    53,  3266,     5,    37,  2804, 10531,    75,\n        12905,  3268, 12938,    19,     3,     9,   898,    18, 11619, 12938,\n            3, 16012,     8,  1236,    31,     7, 10531,    75, 12905,  1575,\n         3278,    10,   213,   284,  9340,  5475,    80,    13,   898, 10531,\n           75, 12905,  3268,  3379,     6,     3,  4094,    38,   209,    41,\n        13283,   470,   201,   204,    41, 19055,   715,     7,   201,    42,\n          220,    41, 10084,   137,   506,  3379,   560,    10,  3403,     6,\n            3, 23393,     6,   419, 27111,     6, 19119,     6, 11429,  3035,\n            6, 23621,    15,     6,  2926,     6,  6342,   159,    15,     6,\n          781,  4921,     6, 15856,   329,   159,  4914,     7,     6, 15192,\n        14337,   102,     7,     6, 15192,  3174,  2319,     7,     6, 23545,\n          342,  4302,     7,  9719,    17,     7,     6,  1193,  7001,     6,\n         1972,  1649,  1169,    60,  4128,     6, 23966,     5, 12636,    15,\n           19,     8,  1236,    31,     7, 10531,    75, 12905,  1575, 12938,\n           10,   784,    31,   519,     3,    31,     6,     3,    31,   519,\n            3,    31,     6,     3,    31,   357,     3,    31,     6,     3,\n           31,   519,     3,    31,     6,     3,    31,   519,     3,    31,\n            6,     3,    31,   519,     3,    31,     6,     3,    31,   536,\n            3,    31,     6,     3,    31,   536,     3,    31,     6,     3,\n           31,   519,     3,    31,     6,     3,    31,   357,     3,    31,\n            6,     3,    31,   519,     3,    31,     6,     3,    31,   519,\n            3,    31,     6,     3,    31,   519,     3,    31,     6,     3,\n           31,   519,     3,    31,     6,     3,    31,   519,     3,    31,\n            6,     3,    31,   519,     3,    31,   908,     1,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\nExpected feedback IDs: tensor([  100,    19,     8,  2711,    13,     8,   682,    93,    75, 29771,\n           23,   106,    11,     8,  1236,   937,  1081,     5,  5289,    10,\n        24305,     3,     9, 20737,   478,    24,  1217,  1236,  3056,    11,\n           70,  7586,    16,  1317,  7404,    38,  3785,    45,     3,     9,\n         1042,    11,  3911,     7,   284,  1236,    31,     7,  1348,  2604,\n           12,     8,  8990,    41, 10475,  5595,   137,  5433,     6,     8,\n          478,   398,  3911,     8,   564,   599,     7,    61,    13,     8,\n         1236,   599,     7,    61,    28,     8,  2030,    11,  7402,  1348,\n         7586,     5,   696,   478,   398,  6634,    11,   169,    44,   709,\n           80,  1681,     5,    27,  9082,  6675,  5652, 18169,    10,  1429,\n           71,  1499,  1042,   213,   284,   689,  2579,     3,     9,  1236,\n           31,     7,   564,  2348,    57,    70,  7586,    16,  1317,  7404,\n            6,    66, 12494,    57,  4856,     5,    37,   381,    13,  7404,\n           54,  5215,   344,   481,     6,    68,   284,  1236,    56,    43,\n           44,   709,   220,  7404,     5,    37,   689,  1910,    19,    10,\n         6341, 23954, 17763,   536, 17763,   357,     3,   233, 17763,   567,\n            5,  1698,  2604,    19,    46, 30278,    16,     8,   620,     3,\n         9498,  2915,     5,   290,    56,    36,    44,   709,    80,  1236,\n           11,   112,    87,   760,  7586,    16,     8,  1042,     5,     3,\n         9744,   345,  6675,  5652, 18169,    10,  1429,    37,   478,   225,\n          166,  3911,     8,   564,    11,  1348,  2604,     3, 12279,    12,\n          192,  7908,  1982,  1747,    13,   334,  1236,    30,    80,   689,\n            6,    16,     8,   455,    79,  4283,    16,     8,  3785,     5,\n         1429,    37,   478,   225,   416,  3911,     8,   564,   599,     7,\n           61,    13,     8,  1236,   599,     7,    61,    28,     8,  2030,\n           11,  7402,  1348,  7586,     6,   590,    28,    70,  1348,  7586,\n            5,   156,   132,    19,   163,    80,  1236,     6,    24,  1236,\n          225,    36,  2008,    21,   321,     8,  2030,    11,  7402,  1348,\n            5,   156,   132,    33,  1317,   481,    28,     8,   337,  2030,\n           42,  7402,  1348,     6,   258,   570,    66,   224,   481,    16,\n            8,   455,    79,  4283,    16,     8,  3785,     5,   262,     4,\n        15837,  3765,   209,    10,    27,  9082,  6675,    41, 17752, 17779,\n         4578,  3347,   377, 20129,    61,    10, 13390, 11989,  2777,     3,\n         3940,  5762,  2861,  6374,  2775, 11989, 12707,     3,  4060, 11989,\n         2777,     3,  4271,     3,  4508,     3,  9744,   345,  6675,    10,\n        13390,    10,     3,  4608,     5,  4201,  5762,    10,     3,  4013,\n            5,  1752, 12707,    10,     3,  3914,     5,  3328,  1592,   222,\n        23836,    10, 12707,     6,     3,  3914,     5,  3328,  5586,   222,\n        23836,    10,  5762,     6,     3,  4013,     5,  1752,   262,     4,\n        15837,  3765,   204,    10,    27,  9082,  6675,    41, 17752, 17779,\n         4578,  3347,   377, 20129,    61,    10, 13390, 11989,  2777, 11923,\n         5762,  6374,  2775, 11989, 12707, 11923,  2777, 11989, 18821, 11923,\n         2777, 11989, 11566,  1640,  7123,  2861,     3,  9744,   345,  6675,\n           10, 13390,    10,   668, 10667,  5762,    10,   505, 10667, 12707,\n           10,   668, 10667, 18821,    10,   668, 10667, 11566,    10,   431,\n        23577,  1592,   222, 23836,    10, 13390,     6, 12707,     6, 18821,\n            6,   668, 10667,  5586,   222, 23836,    10, 11566,     6,   431,\n        23577,     5,  6341,   937,  1081,    10,  3785,   834, 11966,  2423,\n           77,  2562,  9960,     3,   226,    32,  2423,  8751,   599,    77,\n         2562,   834, 11966,     6,    31,    52,    31,    61,  1713,  8751,\n            8,  1042,   608,   834, 11966,  2423,   226,    32,     5,  5236,\n         9960,     1])\nExpected encoded feedback IDs: tensor([  100,    19,     8,  2711,    13,     8,   682,  4210,    11,     8,\n         1644,  2024,  1525,    21,    24, 12628,   408,   822,     5,  5289,\n           10, 24305,     3,     9, 20737,   478,    24,  1217,  1236,  3056,\n           11,    70,  7586,    16,  1317,  7404,    38,  3785,    45,     3,\n            9,  1042,    11,  3911,     7,   284,  1236,    31,     7,  1348,\n         2604,    12,     8,  8990,    41, 10475,  5595,   137,  5433,     6,\n            8,   478,   398,  3911,     8,   564,   599,     7,    61,    13,\n            8,  1236,   599,     7,    61,    28,     8,  2030,    11,  7402,\n         1348,  7586,     5,   696,   478,   398,  6634,    11,   169,    44,\n          709,    80,  1681,     5,    27,  9082,  6675,  5652, 18169,    10,\n         1429,    71,  1499,  1042,   213,   284,   689,  2579,     3,     9,\n         1236,    31,     7,   564,  2348,    57,    70,  7586,    16,  1317,\n         7404,     6,    66, 12494,    57,  4856,     5,    37,   381,    13,\n         7404,    54,  5215,   344,   481,     6,    68,   284,  1236,    56,\n           43,    44,   709,   220,  7404,     5,    37,   689,  1910,    19,\n           10,  6341, 23954, 17763,   536, 17763,   357,     3,   233, 17763,\n          567,     5,  1698,  2604,    19,    46, 30278,    16,     8,   620,\n            3,  9498,  2915,     5,   290,    56,    36,    44,   709,    80,\n         1236,    11,   112,    87,   760,  7586,    16,     8,  1042,     5,\n            3,  9744,   345,  6675,  5652, 18169,    10,  1429,    37,   478,\n          225,   166,  3911,     8,   564,    11,  1348,  2604,     3, 12279,\n           12,   192,  7908,  1982,  1747,    13,   334,  1236,    30,    80,\n          689,     6,    16,     8,   455,    79,  4283,    16,     8,  3785,\n            5,  1429,    37,   478,   225,   416,  3911,     8,   564,   599,\n            7,    61,    13,     8,  1236,   599,     7,    61,    28,     8,\n         2030,    11,  7402,  1348,  7586,     6,   590,    28,    70,  1348,\n         7586,     5,   156,   132,    19,   163,    80,  1236,     6,    24,\n         1236,   225,    36,  2008,    21,   321,     8,  2030,    11,  7402,\n         1348,     5,   156,   132,    33,  1317,   481,    28,     8,   337,\n         2030,    42,  7402,  1348,     6,   258,   570,    66,   224,   481,\n           16,     8,   455,    79,  4283,    16,     8,  3785,     5,   262,\n            4, 15837,  3765,   209,    10,    27,  9082,  6675,    41, 17752,\n        17779,  4578,  3347,   377, 20129,    61,    10, 13390, 11989,  2777,\n            3,  3940,  5762,  2861,  6374,  2775, 11989, 12707,     3,  4060,\n        11989,  2777,     3,  4271,     3,  4508,     3,  9744,   345,  6675,\n           10, 13390,    10,     3,  4608,     5,  4201,  5762,    10,     3,\n         4013,     5,  1752, 12707,    10,     3,  3914,     5,  3328,  1592,\n          222, 23836,    10, 12707,     6,     3,  3914,     5,  3328,  5586,\n          222, 23836,    10,  5762,     6,     3,  4013,     5,  1752,   262,\n            4, 15837,  3765,   204,    10,    27,  9082,  6675,    41, 17752,\n        17779,  4578,  3347,   377, 20129,    61,    10, 13390, 11989,  2777,\n        11923,  5762,  6374,  2775, 11989, 12707, 11923,  2777, 11989, 18821,\n        11923,  2777, 11989, 11566,  1640,  7123,  2861,     3,  9744,   345,\n         6675,    10, 13390,    10,   668, 10667,  5762,    10,   505, 10667,\n        12707,    10,   668, 10667, 18821,    10,   668, 10667, 11566,    10,\n          431, 23577,  1592,   222, 23836,    10, 13390,     6, 12707,     6,\n        18821,     6,   668, 10667,  5586,   222, 23836,    10, 11566,     6,\n          431, 23577,     5, 19539,    15,    26,  2024,    46,     7,     7,\n         3321,    21,     8,   682,    10,    20,    89, 11837,   834, 28951,\n          599,     7,  9022,     7,    61,    10,  1205,  4505,   599,     7,\n         9022,     7,    61,     3,    87,    90,    29,   599,     7,  9022,\n            7,     1])\nStudent Answer IDs: torch.Size([512])\nTarget IDs: torch.Size([512])\n\n\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.pad_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:53.09477Z",
          "iopub.execute_input": "2025-01-10T08:41:53.095046Z",
          "iopub.status.idle": "2025-01-10T08:41:53.100209Z",
          "shell.execute_reply.started": "2025-01-10T08:41:53.095024Z",
          "shell.execute_reply": "2025-01-10T08:41:53.099494Z"
        },
        "id": "6Wlser8Ba7Iy",
        "outputId": "9449bdcd-5a2b-4110-8d7b-4f3274614baa"
      },
      "outputs": [
        {
          "execution_count": 32,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<|endoftext|>'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_pad_token_id = gpt2_tokenizer.pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:53.466804Z",
          "iopub.execute_input": "2025-01-10T08:41:53.467132Z",
          "iopub.status.idle": "2025-01-10T08:41:53.470971Z",
          "shell.execute_reply.started": "2025-01-10T08:41:53.467103Z",
          "shell.execute_reply": "2025-01-10T08:41:53.470078Z"
        },
        "id": "cnDxXCGxa7Iy"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:55.194021Z",
          "iopub.execute_input": "2025-01-10T08:41:55.194438Z",
          "iopub.status.idle": "2025-01-10T08:41:55.200131Z",
          "shell.execute_reply.started": "2025-01-10T08:41:55.194402Z",
          "shell.execute_reply": "2025-01-10T08:41:55.199362Z"
        },
        "id": "5LAI9-sZa7Iy",
        "outputId": "dab0bd00-e89f-4b8f-e9fe-7cd62203d455"
      },
      "outputs": [
        {
          "execution_count": 34,
          "output_type": "execute_result",
          "data": {
            "text/plain": "50256"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer.pad_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:55.513927Z",
          "iopub.execute_input": "2025-01-10T08:41:55.514243Z",
          "iopub.status.idle": "2025-01-10T08:41:55.519055Z",
          "shell.execute_reply.started": "2025-01-10T08:41:55.514208Z",
          "shell.execute_reply": "2025-01-10T08:41:55.518189Z"
        },
        "id": "hEyynFuNa7Iz",
        "outputId": "4b6ae006-aa6e-4644-8d0b-58dff1b3f5bf"
      },
      "outputs": [
        {
          "execution_count": 35,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'<pad>'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_pad_token_id = t5_tokenizer.pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:55.723608Z",
          "iopub.execute_input": "2025-01-10T08:41:55.723931Z",
          "iopub.status.idle": "2025-01-10T08:41:55.727867Z",
          "shell.execute_reply.started": "2025-01-10T08:41:55.723902Z",
          "shell.execute_reply": "2025-01-10T08:41:55.726868Z"
        },
        "id": "sGPK7f0ba7Iz"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "t5_pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:41:55.908651Z",
          "iopub.execute_input": "2025-01-10T08:41:55.908949Z",
          "iopub.status.idle": "2025-01-10T08:41:55.914619Z",
          "shell.execute_reply.started": "2025-01-10T08:41:55.908927Z",
          "shell.execute_reply": "2025-01-10T08:41:55.913572Z"
        },
        "id": "nWn7op96a7I0",
        "outputId": "55c55a0c-44cd-429f-94b2-b126a19d35a4"
      },
      "outputs": [
        {
          "execution_count": 37,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Enocder"
      ],
      "metadata": {
        "id": "HK7ybN62a7I0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# class ContextEncoder(nn.Module):\n",
        "#     def __init__(self, t5_model_name='t5-base', output_dim=768 , max_length = 512):\n",
        "#         super(ContextEncoder, self).__init__()\n",
        "\n",
        "#         self.max_length = max_length\n",
        "\n",
        "#         self.t5_encoder = T5Model.from_pretrained(t5_model_name).encoder\n",
        "#         self.t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "#         self.fc = nn.Linear(self.t5_encoder.config.d_model, output_dim)\n",
        "\n",
        "#     def forward(self, problem_code_ids, attention_masks=None, prompt=\"\"):\n",
        "\n",
        "#         prompt_ids = torch.tensor(\n",
        "#             self.t5_tokenizer.encode(prompt, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "#         )\n",
        "\n",
        "#         problem_code = [self.t5_tokenizer.decode(ids, skip_special_tokens=True) for ids in problem_code_ids]\n",
        "\n",
        "#         combined_text = prompt + \" \" + \" \".join(problem_code)\n",
        "\n",
        "#         encoded = self.t5_tokenizer(\n",
        "#             combined_text,\n",
        "#             max_length=self.max_length,\n",
        "#             truncation=True,\n",
        "#             padding=\"max_length\",\n",
        "#             return_tensors=\"pt\"\n",
        "#         ).to(problem_code_ids.device)\n",
        "\n",
        "#         encoder_outputs = self.t5_encoder(\n",
        "#             input_ids=encoded[\"input_ids\"],\n",
        "#             attention_mask=encoded[\"attention_mask\"]\n",
        "#         )\n",
        "\n",
        "#         context_hidden_states = encoder_outputs.last_hidden_state\n",
        "\n",
        "#         context_rep = context_hidden_states.mean(dim=1)\n",
        "\n",
        "#         # decoded_combined = [\n",
        "#         # self.t5_tokenizer.decode(ids, skip_special_tokens=True)\n",
        "#         # for ids in encoded_outputs]\n",
        "\n",
        "#         context_rep = self.fc(context_rep)\n",
        "#         final_rep = context_rep.unsqueeze(1)\n",
        "\n",
        "#         return final_rep"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:09.352192Z",
          "iopub.execute_input": "2025-01-10T07:42:09.35248Z",
          "iopub.status.idle": "2025-01-10T07:42:09.356085Z",
          "shell.execute_reply.started": "2025-01-10T07:42:09.352458Z",
          "shell.execute_reply": "2025-01-10T07:42:09.355317Z"
        },
        "id": "epmjfCO_a7I2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# context_encoder = ContextEncoder().to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:10.516269Z",
          "iopub.execute_input": "2025-01-10T07:42:10.516554Z",
          "iopub.status.idle": "2025-01-10T07:42:10.519945Z",
          "shell.execute_reply.started": "2025-01-10T07:42:10.516531Z",
          "shell.execute_reply": "2025-01-10T07:42:10.519153Z"
        },
        "id": "Fnjz8vrra7I2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# context_encoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:10.833751Z",
          "iopub.execute_input": "2025-01-10T07:42:10.834074Z",
          "iopub.status.idle": "2025-01-10T07:42:10.837366Z",
          "shell.execute_reply.started": "2025-01-10T07:42:10.834049Z",
          "shell.execute_reply": "2025-01-10T07:42:10.836531Z"
        },
        "id": "GCZmPBnSa7I2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# class MetacognitionLayer(nn.Module):\n",
        "#     def __init__(self, metacognitive_dim=16, output_dim=768):\n",
        "#         super(MetacognitionLayer, self).__init__()\n",
        "#         #16 to 768 mapping\n",
        "#         self.metacognitive_fc = nn.Linear(metacognitive_dim, output_dim)\n",
        "#         self.final_fc = nn.Linear(output_dim, output_dim)\n",
        "\n",
        "#         self.tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "#         self.t5_pad_token_id = self.tokenizer.pad_token_id\n",
        "#         self.encoder = T5Model.from_pretrained(\"t5-base\").encoder\n",
        "\n",
        "\n",
        "\n",
        "#         for param in self.encoder.parameters():\n",
        "#             param.requires_grad = False\n",
        "\n",
        "#     def forward(self, metacognitive_vector):\n",
        "\n",
        "#         metacognitive_components = [\n",
        "#                 \"Read\", \"Identify\", \"Rephrase\", \"Examples\", \"Breakdown\", \"Estimate\", \"Plan\",\n",
        "#                 \"Revise\", \"Verify\", \"AvoidMistakes\", \"MonitorSteps\", \"MonitorProcess\",\n",
        "#                 \"ValidateConstraints\", \"Confirm\", \"CheckRequirements\", \"Reflect\"\n",
        "#             ]\n",
        "\n",
        "#         prompt_text = (\n",
        "#             f\"Metacognitive feedback helps students reflect on their algorithm-solving strategies. \"\n",
        "#             f\"The passed metacognitive vector is a 16-dimensional vector describing the student's metacognition profile, \"\n",
        "#             f\"where each dimension represents one of 16 metacognitive components, rated as 1 (Almost never), \"\n",
        "#             f\"2 (Sometimes), or 3 (Often). These components include: {', '.join(metacognitive_components)}.\"\n",
        "#         )\n",
        "\n",
        "\n",
        "#         input_prompt = self.tokenizer(\n",
        "#         prompt_text,\n",
        "#         return_tensors=\"pt\",\n",
        "#         padding=True,\n",
        "#         truncation=True,\n",
        "#         max_length=512-16\n",
        "#         )\n",
        "#         input_prompt = {key: value.to(metacognitive_vector.device) for key, value in input_prompt.items()}\n",
        "\n",
        "#         outputs = self.encoder(input_ids=input_prompt[\"input_ids\"], attention_mask=input_prompt[\"attention_mask\"])\n",
        "#         prompt_embedding = outputs.last_hidden_state.mean(dim=1)\n",
        "#         prompt_embedding = prompt_embedding.to(metacognitive_vector.device)\n",
        "\n",
        "#         metacognitive_rep = self.metacognitive_fc(metacognitive_vector)\n",
        "#         final_rep = self.final_fc(metacognitive_rep)\n",
        "#         persona_rep = final_rep.unsqueeze(1)\n",
        "\n",
        "#         final_persona = persona_rep + prompt_embedding\n",
        "\n",
        "#         return final_persona"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:11.101146Z",
          "iopub.execute_input": "2025-01-10T07:42:11.101428Z",
          "iopub.status.idle": "2025-01-10T07:42:11.105145Z",
          "shell.execute_reply.started": "2025-01-10T07:42:11.101402Z",
          "shell.execute_reply": "2025-01-10T07:42:11.104305Z"
        },
        "id": "ZX97CJgLa7I2"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# metacognitive_emb = MetacognitionLayer().to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:12.661334Z",
          "iopub.execute_input": "2025-01-10T07:42:12.66162Z",
          "iopub.status.idle": "2025-01-10T07:42:12.664928Z",
          "shell.execute_reply.started": "2025-01-10T07:42:12.661597Z",
          "shell.execute_reply": "2025-01-10T07:42:12.66408Z"
        },
        "id": "x5pQ-96_a7JA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# metacognitive_emb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:42:12.982547Z",
          "iopub.execute_input": "2025-01-10T07:42:12.982828Z",
          "iopub.status.idle": "2025-01-10T07:42:12.986083Z",
          "shell.execute_reply.started": "2025-01-10T07:42:12.982805Z",
          "shell.execute_reply": "2025-01-10T07:42:12.985264Z"
        },
        "id": "BQMfinGKa7JA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class PAALayer(nn.Module):\n",
        "    def __init__(self, hidden_dimension = 512 , tau=0.8,dropout_rate=0.1):\n",
        "        super(PAALayer, self).__init__()\n",
        "        self.hidden_dimenstion = hidden_dimension\n",
        "        self.tau = tau\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(2 * hidden_dimension, hidden_dimension)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc_out = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, hR , oP, oC):\n",
        "\n",
        "        Mp_input  = torch.cat([hR,oP], dim=-1)\n",
        "        Mp = self.fc(Mp_input)\n",
        "        Wp = self.sigmoid(Mp)\n",
        "\n",
        "        Mpersona = Wp\n",
        "        Mcontext = 1 - Wp\n",
        "\n",
        "        oP_weighted = Mcontext * oP\n",
        "        oC_weighted = Mpersona * oC\n",
        "\n",
        "        HPAA = oP_weighted + oC_weighted\n",
        "\n",
        "        output = self.fc_out(HPAA)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:00.435152Z",
          "iopub.execute_input": "2025-01-10T08:42:00.435503Z",
          "iopub.status.idle": "2025-01-10T08:42:00.440912Z",
          "shell.execute_reply.started": "2025-01-10T08:42:00.435479Z",
          "shell.execute_reply": "2025-01-10T08:42:00.440023Z"
        },
        "id": "2Z_xRbhNa7JA"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "paa = PAALayer()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:02.31491Z",
          "iopub.execute_input": "2025-01-10T08:42:02.315226Z",
          "iopub.status.idle": "2025-01-10T08:42:02.332172Z",
          "shell.execute_reply.started": "2025-01-10T08:42:02.315199Z",
          "shell.execute_reply": "2025-01-10T08:42:02.331378Z"
        },
        "id": "E6kRw4dea7JB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "paa"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:02.543186Z",
          "iopub.execute_input": "2025-01-10T08:42:02.543531Z",
          "iopub.status.idle": "2025-01-10T08:42:02.54827Z",
          "shell.execute_reply.started": "2025-01-10T08:42:02.543506Z",
          "shell.execute_reply": "2025-01-10T08:42:02.547595Z"
        },
        "id": "T3pInXDya7JB",
        "outputId": "66ad94da-6b56-4525-e2b2-459d4aa68c9d"
      },
      "outputs": [
        {
          "execution_count": 40,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PAALayer(\n  (fc): Linear(in_features=1024, out_features=512, bias=True)\n  (sigmoid): Sigmoid()\n  (fc_out): Linear(in_features=512, out_features=512, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformerBlock(nn.Module):\n",
        "    def __init__(self, hidden_size, tau , dropout_rate=0.1):\n",
        "        super(CustomTransformerBlock, self).__init__()\n",
        "\n",
        "        self.input_self_attention = nn.MultiheadAttention(hidden_size, num_heads=8, batch_first=True)\n",
        "        self.context_attn = nn.MultiheadAttention(hidden_size, num_heads=8, batch_first=True)\n",
        "        self.persona_attn = nn.MultiheadAttention(hidden_size, num_heads=8, batch_first=True)\n",
        "        self.persona_proj = nn.Linear(768, hidden_size)\n",
        "        self.context_proj = nn.Linear(768, hidden_size)\n",
        "\n",
        "        self.paa_layer = PAALayer(hidden_dimension=hidden_size, tau=tau)\n",
        "\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(2048, hidden_size),\n",
        "            nn.LayerNorm(hidden_size)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, student_initial_state, encoded_persona, encoded_context):\n",
        "\n",
        "        hR, _ = self.input_self_attention(student_initial_state, student_initial_state, student_initial_state) #query\n",
        "        encoded_persona = self.persona_proj(encoded_persona)\n",
        "        encoded_context = self.context_proj(encoded_context)\n",
        "        # print(\"hr shape\",hR.shape)\n",
        "        # print(\"encoded persona shape\", encoded_persona.shape)\n",
        "        # print(\"encoded context shape\", encoded_context.shape)\n",
        "        oP, _ = self.persona_attn(hR, encoded_persona, encoded_persona )\n",
        "\n",
        "        # encoded_context = encoded_context.repeat(hR.size(0), hR.size(1), 1)\n",
        "\n",
        "        oC, _ = self.context_attn(hR, encoded_context, encoded_context )\n",
        "\n",
        "        HPAA = self.paa_layer(hR, oP, oC)\n",
        "\n",
        "        mlp_output = self.mlp(HPAA)\n",
        "        output = self.layer_norm2(mlp_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:27.249628Z",
          "iopub.execute_input": "2025-01-10T08:42:27.249903Z",
          "iopub.status.idle": "2025-01-10T08:42:27.256391Z",
          "shell.execute_reply.started": "2025-01-10T08:42:27.24988Z",
          "shell.execute_reply": "2025-01-10T08:42:27.255685Z"
        },
        "id": "wDhvR6Goa7JB"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "custom_layer = CustomTransformerBlock(768,0.5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:27.562936Z",
          "iopub.execute_input": "2025-01-10T08:42:27.56322Z",
          "iopub.status.idle": "2025-01-10T08:42:27.680843Z",
          "shell.execute_reply.started": "2025-01-10T08:42:27.563194Z",
          "shell.execute_reply": "2025-01-10T08:42:27.680169Z"
        },
        "id": "v_D6juUna7JC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "custom_layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:29.54694Z",
          "iopub.execute_input": "2025-01-10T08:42:29.547237Z",
          "iopub.status.idle": "2025-01-10T08:42:29.552427Z",
          "shell.execute_reply.started": "2025-01-10T08:42:29.547215Z",
          "shell.execute_reply": "2025-01-10T08:42:29.551456Z"
        },
        "id": "nwq9pZy6a7JC",
        "outputId": "6fbb8e91-749a-4ef8-a24e-c2313f8dea45"
      },
      "outputs": [
        {
          "execution_count": 48,
          "output_type": "execute_result",
          "data": {
            "text/plain": "CustomTransformerBlock(\n  (input_self_attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (context_attn): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (persona_attn): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (persona_proj): Linear(in_features=768, out_features=768, bias=True)\n  (context_proj): Linear(in_features=768, out_features=768, bias=True)\n  (paa_layer): PAALayer(\n    (fc): Linear(in_features=1536, out_features=768, bias=True)\n    (sigmoid): Sigmoid()\n    (fc_out): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (mlp): Sequential(\n    (0): Linear(in_features=768, out_features=2048, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=2048, out_features=768, bias=True)\n    (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "class PAAModel(nn.Module):\n",
        "    def __init__(self, hidden_size=512, vocab_size = 32100 ,tau=0.5, max_length=512, num_transformer_blocks=4):\n",
        "        super(PAAModel , self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_length = max_length\n",
        "        self.num_transformer_blocks = num_transformer_blocks\n",
        "\n",
        "        self.t5_encoder = T5Model.from_pretrained(\"t5-base\").encoder\n",
        "        for param in self.t5_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, hidden_size)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        self.transformer_blocks = nn.ModuleList([CustomTransformerBlock(hidden_size, tau) for _ in range(num_transformer_blocks)])\n",
        "        self.final_fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,  metacognition_prompt_ids,\n",
        "                       problem_student_code_ids ,\n",
        "                       problem_expected_code_ids,\n",
        "                       metacognition_attention_mask,\n",
        "                       expected_attention_mask):\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            metacognition_prompt_encoded = self.t5_encoder(\n",
        "                                                        input_ids=metacognition_prompt_ids,\n",
        "                                                        attention_mask=metacognition_attention_mask).last_hidden_state\n",
        "\n",
        "            problem_expected_code_encoded = self.t5_encoder(\n",
        "                                                        input_ids=problem_expected_code_ids,\n",
        "                                                        attention_mask=expected_attention_mask).last_hidden_state\n",
        "\n",
        "\n",
        "        token_embeds = self.token_embedding(problem_student_code_ids)\n",
        "        position_ids = torch.arange(0, 1, device=problem_student_code_ids.device).unsqueeze(0)\n",
        "        position_ids = position_ids % self.max_length\n",
        "        position_embeds = self.position_embedding(position_ids)\n",
        "\n",
        "        inputs_embeds = token_embeds + position_embeds\n",
        "        inputs_embeds = self.dropout(inputs_embeds)\n",
        "\n",
        "        student_initial_state = inputs_embeds\n",
        "        transformer_output = student_initial_state\n",
        "\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            transformer_output = transformer_block(transformer_output, metacognition_prompt_encoded, problem_expected_code_encoded)\n",
        "\n",
        "        logits = self.final_fc(transformer_output)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:29.824501Z",
          "iopub.execute_input": "2025-01-10T08:42:29.824782Z",
          "iopub.status.idle": "2025-01-10T08:42:29.832217Z",
          "shell.execute_reply.started": "2025-01-10T08:42:29.824761Z",
          "shell.execute_reply": "2025-01-10T08:42:29.831265Z"
        },
        "id": "YSUMxJOYa7JC"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = PAAModel()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:32.133562Z",
          "iopub.execute_input": "2025-01-10T08:42:32.133843Z",
          "iopub.status.idle": "2025-01-10T08:42:37.091607Z",
          "shell.execute_reply.started": "2025-01-10T08:42:32.133822Z",
          "shell.execute_reply": "2025-01-10T08:42:37.090665Z"
        },
        "id": "AROFcsBVa7JD",
        "outputId": "b5a332ee-6669-4c21-b985-2a73bf40fdbd",
        "colab": {
          "referenced_widgets": [
            "13855595319c4a60a5603beae91d6ec9"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "13855595319c4a60a5603beae91d6ec9"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:37.092739Z",
          "iopub.execute_input": "2025-01-10T08:42:37.092972Z",
          "iopub.status.idle": "2025-01-10T08:42:37.789388Z",
          "shell.execute_reply.started": "2025-01-10T08:42:37.092951Z",
          "shell.execute_reply": "2025-01-10T08:42:37.788633Z"
        },
        "id": "ukrbmnT1a7JD",
        "outputId": "6e88007a-2a1a-4a99-b9e0-a11441cfa0f1"
      },
      "outputs": [
        {
          "execution_count": 51,
          "output_type": "execute_result",
          "data": {
            "text/plain": "PAAModel(\n  (t5_encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (token_embedding): Embedding(32100, 512)\n  (position_embedding): Embedding(512, 512)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (transformer_blocks): ModuleList(\n    (0-3): 4 x CustomTransformerBlock(\n      (input_self_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n      )\n      (context_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n      )\n      (persona_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n      )\n      (persona_proj): Linear(in_features=768, out_features=512, bias=True)\n      (context_proj): Linear(in_features=768, out_features=512, bias=True)\n      (paa_layer): PAALayer(\n        (fc): Linear(in_features=1024, out_features=512, bias=True)\n        (sigmoid): Sigmoid()\n        (fc_out): Linear(in_features=512, out_features=512, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=512, out_features=2048, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.1, inplace=False)\n        (3): Linear(in_features=2048, out_features=512, bias=True)\n        (4): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (final_fc): Linear(in_features=512, out_features=32100, bias=True)\n  (layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:38.329005Z",
          "iopub.execute_input": "2025-01-10T08:42:38.329332Z",
          "iopub.status.idle": "2025-01-10T08:42:38.33307Z",
          "shell.execute_reply.started": "2025-01-10T08:42:38.329306Z",
          "shell.execute_reply": "2025-01-10T08:42:38.332049Z"
        },
        "id": "w-YM7dxRa7JD"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:38.934044Z",
          "iopub.execute_input": "2025-01-10T08:42:38.934396Z",
          "iopub.status.idle": "2025-01-10T08:42:39.519943Z",
          "shell.execute_reply.started": "2025-01-10T08:42:38.934367Z",
          "shell.execute_reply": "2025-01-10T08:42:39.519233Z"
        },
        "id": "sCrMz7qra7JE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "LOSS = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:42.862634Z",
          "iopub.execute_input": "2025-01-10T08:42:42.86315Z",
          "iopub.status.idle": "2025-01-10T08:42:42.867001Z",
          "shell.execute_reply.started": "2025-01-10T08:42:42.863125Z",
          "shell.execute_reply": "2025-01-10T08:42:42.865993Z"
        },
        "id": "kNNiPR_ja7JE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:43.112687Z",
          "iopub.execute_input": "2025-01-10T08:42:43.112967Z",
          "iopub.status.idle": "2025-01-10T08:42:43.116528Z",
          "shell.execute_reply.started": "2025-01-10T08:42:43.112946Z",
          "shell.execute_reply": "2025-01-10T08:42:43.115628Z"
        },
        "id": "gMr9Wd8_a7JE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[0:5000]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:43.382611Z",
          "iopub.execute_input": "2025-01-10T08:42:43.383017Z",
          "iopub.status.idle": "2025-01-10T08:42:43.386992Z",
          "shell.execute_reply.started": "2025-01-10T08:42:43.382985Z",
          "shell.execute_reply": "2025-01-10T08:42:43.386094Z"
        },
        "id": "U5UW8SVga7JE"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:43.668141Z",
          "iopub.execute_input": "2025-01-10T08:42:43.668501Z",
          "iopub.status.idle": "2025-01-10T08:42:43.673696Z",
          "shell.execute_reply.started": "2025-01-10T08:42:43.66847Z",
          "shell.execute_reply": "2025-01-10T08:42:43.67274Z"
        },
        "id": "FADAr7rsa7JF",
        "outputId": "2bc20724-bbfe-4263-c10d-0b4469249df3"
      },
      "outputs": [
        {
          "execution_count": 57,
          "output_type": "execute_result",
          "data": {
            "text/plain": "5000"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:43.968489Z",
          "iopub.execute_input": "2025-01-10T08:42:43.968773Z",
          "iopub.status.idle": "2025-01-10T08:42:43.983176Z",
          "shell.execute_reply.started": "2025-01-10T08:42:43.968751Z",
          "shell.execute_reply": "2025-01-10T08:42:43.982245Z"
        },
        "id": "V_g5jqJQa7JF",
        "outputId": "d4a9adb3-2204-412b-ea78-d71c8bfcb8fe"
      },
      "outputs": [
        {
          "execution_count": 58,
          "output_type": "execute_result",
          "data": {
            "text/plain": "Problem                         0\nStudent_code                    0\nExpected_code                   0\nQ01                             0\nQ02                             0\nQ03                             0\nQ04                             0\nQ05                             0\nQ06                             0\nQ07                             0\nQ08                             0\nQ09                             0\nQ10                             0\nQ11                             0\nQ12                             0\nQ13                             0\nQ14                             0\nQ15                             0\nQ16                             0\nmetacognitive_vector            0\nmetacognitive_feedback          0\ncombined_problem_student        0\ncombined_problem_expected       0\ncombined_metacogntion_prompt    0\ndtype: int64"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataset = CustomDataset(df_train, t5_tokenizer , gpt2_tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset , batch_size = 4 ,shuffle = True )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:46.952228Z",
          "iopub.execute_input": "2025-01-10T08:42:46.952593Z",
          "iopub.status.idle": "2025-01-10T08:42:46.956875Z",
          "shell.execute_reply.started": "2025-01-10T08:42:46.952567Z",
          "shell.execute_reply": "2025-01-10T08:42:46.956024Z"
        },
        "id": "GqHiiAc1a7JF"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "# writer = SummaryWriter()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:47.303071Z",
          "iopub.execute_input": "2025-01-10T08:42:47.303391Z",
          "iopub.status.idle": "2025-01-10T08:42:47.306743Z",
          "shell.execute_reply.started": "2025-01-10T08:42:47.303366Z",
          "shell.execute_reply": "2025-01-10T08:42:47.305793Z"
        },
        "id": "pvWMI-1La7JG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:47.542136Z",
          "iopub.execute_input": "2025-01-10T08:42:47.542728Z",
          "iopub.status.idle": "2025-01-10T08:42:47.546185Z",
          "shell.execute_reply.started": "2025-01-10T08:42:47.542697Z",
          "shell.execute_reply": "2025-01-10T08:42:47.545353Z"
        },
        "id": "1e_7q9CGbiJN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"./checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:47.829589Z",
          "iopub.execute_input": "2025-01-10T08:42:47.829872Z",
          "iopub.status.idle": "2025-01-10T08:42:47.83369Z",
          "shell.execute_reply.started": "2025-01-10T08:42:47.82985Z",
          "shell.execute_reply": "2025-01-10T08:42:47.832928Z"
        },
        "id": "_G2DGEL_a7JG"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# t5_encoder = T5Model.from_pretrained(checkpoint).encoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:53:09.111864Z",
          "iopub.execute_input": "2025-01-10T07:53:09.112148Z",
          "iopub.status.idle": "2025-01-10T07:53:13.560189Z",
          "shell.execute_reply.started": "2025-01-10T07:53:09.112125Z",
          "shell.execute_reply": "2025-01-10T07:53:13.559466Z"
        },
        "id": "rdi0-tmhbiJN",
        "outputId": "7e1a4a0e-9b25-4f54-dc93-a6976317ec8e",
        "colab": {
          "referenced_widgets": [
            "36193b687f064d6e868bd8d8bb3ffb7b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "36193b687f064d6e868bd8d8bb3ffb7b"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# t5_encoder.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:46:30.86035Z",
          "iopub.execute_input": "2025-01-10T07:46:30.860703Z",
          "iopub.status.idle": "2025-01-10T07:46:31.018914Z",
          "shell.execute_reply.started": "2025-01-10T07:46:30.860675Z",
          "shell.execute_reply": "2025-01-10T07:46:31.018041Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "kPmaThAlbiJN",
        "outputId": "ba1f8a23-59ae-48b9-c91e-a8e449f7db28"
      },
      "outputs": [
        {
          "execution_count": 68,
          "output_type": "execute_result",
          "data": {
            "text/plain": "T5Stack(\n  (embed_tokens): Embedding(32128, 768)\n  (block): ModuleList(\n    (0): T5Block(\n      (layer): ModuleList(\n        (0): T5LayerSelfAttention(\n          (SelfAttention): T5Attention(\n            (q): Linear(in_features=768, out_features=768, bias=False)\n            (k): Linear(in_features=768, out_features=768, bias=False)\n            (v): Linear(in_features=768, out_features=768, bias=False)\n            (o): Linear(in_features=768, out_features=768, bias=False)\n            (relative_attention_bias): Embedding(32, 12)\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (1): T5LayerFF(\n          (DenseReluDense): T5DenseActDense(\n            (wi): Linear(in_features=768, out_features=3072, bias=False)\n            (wo): Linear(in_features=3072, out_features=768, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (act): ReLU()\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n    (1-11): 11 x T5Block(\n      (layer): ModuleList(\n        (0): T5LayerSelfAttention(\n          (SelfAttention): T5Attention(\n            (q): Linear(in_features=768, out_features=768, bias=False)\n            (k): Linear(in_features=768, out_features=768, bias=False)\n            (v): Linear(in_features=768, out_features=768, bias=False)\n            (o): Linear(in_features=768, out_features=768, bias=False)\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n        (1): T5LayerFF(\n          (DenseReluDense): T5DenseActDense(\n            (wi): Linear(in_features=768, out_features=3072, bias=False)\n            (wo): Linear(in_features=3072, out_features=768, bias=False)\n            (dropout): Dropout(p=0.1, inplace=False)\n            (act): ReLU()\n          )\n          (layer_norm): T5LayerNorm()\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (final_layer_norm): T5LayerNorm()\n  (dropout): Dropout(p=0.1, inplace=False)\n)"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Training started for epoch {epoch + 1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for idx, (metacognition_prompt_ids,\n",
        "              problem_student_code_ids,\n",
        "              problem_expected_code_ids,\n",
        "              student_code_ids,\n",
        "              target_ids) in enumerate(train_dataloader):\n",
        "\n",
        "\n",
        "        metacognition_prompt_ids = metacognition_prompt_ids.to(device)\n",
        "        problem_student_code_ids = problem_student_code_ids.to(device)\n",
        "        problem_expected_code_ids = problem_expected_code_ids.to(device)\n",
        "        student_code_ids = student_code_ids.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "\n",
        "        #attention masking\n",
        "        student_attention_mask = (problem_student_code_ids != t5_pad_token_id).long().to(device)\n",
        "        expected_attention_mask = (problem_expected_code_ids != t5_pad_token_id).long().to(device)\n",
        "        metacognition_attention_mask = (metacognition_prompt_ids != t5_pad_token_id).long().to(device)\n",
        "\n",
        "        #encoding the decoder inputs for cross attention\n",
        "        # metacognition_prompt_encoded = t5_encoder(\n",
        "        #                                             input_ids=metacognition_prompt_ids,\n",
        "        #                                             attention_mask=metacognition_attention_mask).last_hidden_state\n",
        "\n",
        "        # problem_expected_code_encoded = t5_encoder(\n",
        "        #                                             input_ids=problem_expected_code_ids,\n",
        "        #                                             attention_mask=expected_attention_mask).last_hidden_state\n",
        "\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(metacognition_prompt_ids,\n",
        "                       problem_student_code_ids ,\n",
        "                       problem_expected_code_ids,\n",
        "                      metacognition_attention_mask,\n",
        "                      expected_attention_mask)\n",
        "\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "\n",
        "        target_ids = target_ids.view(-1)\n",
        "        # print(logits.shape)\n",
        "        # print(target_ids.shape)\n",
        "\n",
        "\n",
        "        loss = LOSS(logits, target_ids)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        # for name, param in model.named_parameters():\n",
        "        #     if 'context_encoder' in name:\n",
        "        #         assert param.grad is None, f\"Gradients found in frozen encoder {name}\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Batch {idx + 1}/{len(train_dataloader)} | Loss: {loss.item():.4f}\" , end='\\r')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if epoch % 5 ==0 :\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.requires_grad and param.grad is not None:\n",
        "                    print(f\"Layer: {name} | Grad Norm: {param.grad.norm().item()}\")\n",
        "                elif param.requires_grad:\n",
        "                    print(f\"Layer: {name} | Grad: None\")\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch + 1}.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': total_loss / max(len(train_dataloader), 1),\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / max(len(train_dataloader), 1)\n",
        "    #writer.add_scalar(\"Loss/train\", avg_loss, epoch + 1)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed | Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T08:42:52.072512Z",
          "iopub.execute_input": "2025-01-10T08:42:52.072807Z"
        },
        "id": "qBooPbJNa7JG",
        "outputId": "c278d4f2-d0f6-408d-9237-2ae0a600ab95"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Training started for epoch 1/200\nLayer: token_embedding.weight | Grad Norm: 3.9925669107626627e-13\nLayer: position_embedding.weight | Grad Norm: 2.451501241590437e-12\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad Norm: 7.675216712188515e-11\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad Norm: 3.4575411110571164e-12\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad Norm: 9.322762700714193e-11\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad Norm: 6.135561243097998e-12\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad Norm: 6.447607447945813e-10\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad Norm: 4.4577869173778595e-10\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad Norm: 8.173368093444822e-10\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad Norm: 7.921868716564973e-10\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad Norm: 7.620996611557018e-10\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad Norm: 4.531779118632784e-10\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad Norm: 9.622820318355707e-10\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad Norm: 7.864074391683573e-10\nLayer: transformer_blocks.0.persona_proj.weight | Grad Norm: 1.1131973121081273e-09\nLayer: transformer_blocks.0.persona_proj.bias | Grad Norm: 3.2748001532745263e-10\nLayer: transformer_blocks.0.context_proj.weight | Grad Norm: 8.658035399733421e-10\nLayer: transformer_blocks.0.context_proj.bias | Grad Norm: 3.1178970516521076e-10\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad Norm: 1.3490381034486632e-10\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad Norm: 1.5892462693067877e-11\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad Norm: 1.2696619311469703e-09\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad Norm: 2.613546712382231e-09\nLayer: transformer_blocks.0.mlp.0.weight | Grad Norm: 2.8369409044159966e-09\nLayer: transformer_blocks.0.mlp.0.bias | Grad Norm: 4.422197719122778e-09\nLayer: transformer_blocks.0.mlp.3.weight | Grad Norm: 1.0532056116119293e-08\nLayer: transformer_blocks.0.mlp.3.bias | Grad Norm: 1.1320850923368653e-08\nLayer: transformer_blocks.0.mlp.4.weight | Grad Norm: 2.0524963673107521e-10\nLayer: transformer_blocks.0.mlp.4.bias | Grad Norm: 2.132410220623271e-10\nLayer: transformer_blocks.0.layer_norm2.weight | Grad Norm: 2.060235593237536e-10\nLayer: transformer_blocks.0.layer_norm2.bias | Grad Norm: 2.1065506283779456e-10\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad Norm: 6.4528333787450265e-09\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad Norm: 2.920244324133847e-10\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad Norm: 8.100255577403459e-09\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad Norm: 5.197558494707266e-10\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad Norm: 4.422870603093543e-08\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad Norm: 3.0990836563660196e-08\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad Norm: 5.79625520913396e-08\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad Norm: 5.535439839832179e-08\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad Norm: 5.5271460297490194e-08\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad Norm: 3.124877423488215e-08\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad Norm: 7.476741359369043e-08\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad Norm: 5.488733023639725e-08\nLayer: transformer_blocks.1.persona_proj.weight | Grad Norm: 7.596324991254733e-08\nLayer: transformer_blocks.1.persona_proj.bias | Grad Norm: 2.2348340067424033e-08\nLayer: transformer_blocks.1.context_proj.weight | Grad Norm: 6.12164967606077e-08\nLayer: transformer_blocks.1.context_proj.bias | Grad Norm: 2.1857935905700288e-08\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad Norm: 1.1909711439272996e-08\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad Norm: 1.2657308534613776e-09\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad Norm: 1.276185201959379e-07\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad Norm: 1.9481207402805012e-07\nLayer: transformer_blocks.1.mlp.0.weight | Grad Norm: 2.6533567165643035e-07\nLayer: transformer_blocks.1.mlp.0.bias | Grad Norm: 3.4539749549367116e-07\nLayer: transformer_blocks.1.mlp.3.weight | Grad Norm: 1.0047784826383577e-06\nLayer: transformer_blocks.1.mlp.3.bias | Grad Norm: 9.045862725542975e-07\nLayer: transformer_blocks.1.mlp.4.weight | Grad Norm: 3.04897405101201e-08\nLayer: transformer_blocks.1.mlp.4.bias | Grad Norm: 3.115440705414585e-08\nLayer: transformer_blocks.1.layer_norm2.weight | Grad Norm: 3.144697302559507e-08\nLayer: transformer_blocks.1.layer_norm2.bias | Grad Norm: 3.1587170212787896e-08\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad Norm: 1.016569513012655e-06\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad Norm: 4.537228193157716e-08\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad Norm: 1.718176122267323e-06\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad Norm: 7.987459582636802e-08\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad Norm: 8.815725777822081e-06\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad Norm: 6.886350547574693e-06\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad Norm: 1.2476341908040922e-05\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad Norm: 1.1792338227678556e-05\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad Norm: 1.0296680557075888e-05\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad Norm: 6.72124815537245e-06\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad Norm: 1.4210783774615265e-05\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad Norm: 1.090110163204372e-05\nLayer: transformer_blocks.2.persona_proj.weight | Grad Norm: 1.5439667549799196e-05\nLayer: transformer_blocks.2.persona_proj.bias | Grad Norm: 4.981299298378872e-06\nLayer: transformer_blocks.2.context_proj.weight | Grad Norm: 1.4502535123028792e-05\nLayer: transformer_blocks.2.context_proj.bias | Grad Norm: 5.223592324909987e-06\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad Norm: 3.4345478070463287e-06\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad Norm: 1.9155048391894525e-07\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad Norm: 3.803509389399551e-05\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad Norm: 3.818125696852803e-05\nLayer: transformer_blocks.2.mlp.0.weight | Grad Norm: 8.777955372352153e-05\nLayer: transformer_blocks.2.mlp.0.bias | Grad Norm: 7.2567789175082e-05\nLayer: transformer_blocks.2.mlp.3.weight | Grad Norm: 0.00038803115603514016\nLayer: transformer_blocks.2.mlp.3.bias | Grad Norm: 0.00021356312208808959\nLayer: transformer_blocks.2.mlp.4.weight | Grad Norm: 1.83030770131154e-05\nLayer: transformer_blocks.2.mlp.4.bias | Grad Norm: 1.7174133972730488e-05\nLayer: transformer_blocks.2.layer_norm2.weight | Grad Norm: 9.76058654487133e-05\nLayer: transformer_blocks.2.layer_norm2.bias | Grad Norm: 6.363260035868734e-05\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.0009972654515877366\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 4.4087682908866554e-05\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.0017533344216644764\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 4.575944331008941e-05\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.019632553681731224\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.006117801181972027\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.025333089753985405\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.008006904274225235\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.001890667830593884\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.0017418137285858393\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.0025373208336532116\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.003058755537495017\nLayer: transformer_blocks.3.persona_proj.weight | Grad Norm: 0.0031701447442173958\nLayer: transformer_blocks.3.persona_proj.bias | Grad Norm: 0.0012364538852125406\nLayer: transformer_blocks.3.context_proj.weight | Grad Norm: 0.033401671797037125\nLayer: transformer_blocks.3.context_proj.bias | Grad Norm: 0.006007760297507048\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.00459847180172801\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 8.065978181548417e-05\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.036069355905056\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.013696100562810898\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.0609150156378746\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.025796953588724136\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.39509597420692444\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.15852777659893036\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.016827289015054703\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.01956862211227417\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.019466660916805267\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.021531669422984123\nLayer: final_fc.weight | Grad Norm: 0.8985642790794373\nLayer: final_fc.bias | Grad Norm: 0.04045197740197182\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [1/200] completed | Average Loss: 4.9447\nTraining started for epoch 2/200\nEpoch [2/200] completed | Average Loss: 4.7380\nTraining started for epoch 3/200\nBatch 201/1250 | Loss: 4.3461\r",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.memory_summary(device='cuda', abbreviated=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-10T07:49:46.167024Z",
          "iopub.execute_input": "2025-01-10T07:49:46.167397Z",
          "iopub.status.idle": "2025-01-10T07:49:46.173875Z",
          "shell.execute_reply.started": "2025-01-10T07:49:46.167365Z",
          "shell.execute_reply": "2025-01-10T07:49:46.172871Z"
        },
        "id": "dsIqmVWgbiJO",
        "outputId": "afa44a27-3128-44f9-c72b-143505f8fbe9"
      },
      "outputs": [
        {
          "execution_count": 74,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'|===========================================================================|\\n|                  PyTorch CUDA memory summary, device ID 0                 |\\n|---------------------------------------------------------------------------|\\n|            CUDA OOMs: 2            |        cudaMalloc retries: 2         |\\n|===========================================================================|\\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\\n|---------------------------------------------------------------------------|\\n| Allocated memory      |   7929 MiB |   7972 MiB |  14364 MiB |   6434 MiB |\\n|       from large pool |   7927 MiB |   7970 MiB |  14332 MiB |   6405 MiB |\\n|       from small pool |      1 MiB |      3 MiB |     31 MiB |     29 MiB |\\n|---------------------------------------------------------------------------|\\n| Active memory         |   7929 MiB |   7972 MiB |  14364 MiB |   6434 MiB |\\n|       from large pool |   7927 MiB |   7970 MiB |  14332 MiB |   6405 MiB |\\n|       from small pool |      1 MiB |      3 MiB |     31 MiB |     29 MiB |\\n|---------------------------------------------------------------------------|\\n| Requested memory      |   7926 MiB |   7968 MiB |  14360 MiB |   6433 MiB |\\n|       from large pool |   7924 MiB |   7966 MiB |  14328 MiB |   6404 MiB |\\n|       from small pool |      1 MiB |      3 MiB |     31 MiB |     29 MiB |\\n|---------------------------------------------------------------------------|\\n| GPU reserved memory   |   8202 MiB |   8252 MiB |   8302 MiB | 102400 KiB |\\n|       from large pool |   8200 MiB |   8248 MiB |   8296 MiB |  98304 KiB |\\n|       from small pool |      2 MiB |      4 MiB |      6 MiB |   4096 KiB |\\n|---------------------------------------------------------------------------|\\n| Non-releasable memory | 279286 KiB | 297210 KiB |   6963 MiB |   6690 MiB |\\n|       from large pool | 279080 KiB | 297000 KiB |   6931 MiB |   6659 MiB |\\n|       from small pool |    206 KiB |   2132 KiB |     31 MiB |     31 MiB |\\n|---------------------------------------------------------------------------|\\n| Allocations           |    1023    |    1025    |    1854    |     831    |\\n|       from large pool |     774    |     776    |    1320    |     546    |\\n|       from small pool |     249    |     250    |     534    |     285    |\\n|---------------------------------------------------------------------------|\\n| Active allocs         |    1023    |    1025    |    1854    |     831    |\\n|       from large pool |     774    |     776    |    1320    |     546    |\\n|       from small pool |     249    |     250    |     534    |     285    |\\n|---------------------------------------------------------------------------|\\n| GPU reserved segments |     244    |     246    |     248    |       4    |\\n|       from large pool |     243    |     244    |     245    |       2    |\\n|       from small pool |       1    |       2    |       3    |       2    |\\n|---------------------------------------------------------------------------|\\n| Non-releasable allocs |     135    |     136    |     666    |     531    |\\n|       from large pool |     129    |     130    |     509    |     380    |\\n|       from small pool |       6    |       7    |     157    |     151    |\\n|---------------------------------------------------------------------------|\\n| Oversize allocations  |       0    |       0    |       0    |       0    |\\n|---------------------------------------------------------------------------|\\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\\n|===========================================================================|\\n'"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-08T14:16:16.118335Z",
          "iopub.execute_input": "2025-01-08T14:16:16.118626Z",
          "iopub.status.idle": "2025-01-08T14:16:16.123946Z",
          "shell.execute_reply.started": "2025-01-08T14:16:16.118603Z",
          "shell.execute_reply": "2025-01-08T14:16:16.122821Z"
        },
        "id": "7WNDInhvbiJO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'paamodel.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:35.127979Z",
          "iopub.execute_input": "2025-01-02T09:15:35.1283Z",
          "iopub.status.idle": "2025-01-02T09:15:38.043298Z",
          "shell.execute_reply.started": "2025-01-02T09:15:35.128272Z",
          "shell.execute_reply": "2025-01-02T09:15:38.042319Z"
        },
        "id": "wkDGQ4eRa7JH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "model = PAAModel()\n",
        "\n",
        "# Load the saved state dict\n",
        "model.load_state_dict(torch.load('paamodel.pth'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:38.044438Z",
          "iopub.execute_input": "2025-01-02T09:15:38.044677Z",
          "iopub.status.idle": "2025-01-02T09:15:43.200276Z",
          "shell.execute_reply.started": "2025-01-02T09:15:38.044656Z",
          "shell.execute_reply": "2025-01-02T09:15:43.199391Z"
        },
        "id": "7TcPgRsja7JH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = df[9999:10000].reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:31.90417Z",
          "iopub.execute_input": "2025-01-02T09:13:31.904508Z",
          "iopub.status.idle": "2025-01-02T09:13:31.909558Z",
          "shell.execute_reply.started": "2025-01-02T09:13:31.904481Z",
          "shell.execute_reply": "2025-01-02T09:13:31.908551Z"
        },
        "id": "K1MXJesua7JI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:33.152773Z",
          "iopub.execute_input": "2025-01-02T09:13:33.153078Z",
          "iopub.status.idle": "2025-01-02T09:13:33.167906Z",
          "shell.execute_reply.started": "2025-01-02T09:13:33.153052Z",
          "shell.execute_reply": "2025-01-02T09:13:33.166951Z"
        },
        "id": "9D4sb3pxa7JI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = CustomDataset(df_eval, t5_tokenizer,gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:36.045686Z",
          "iopub.execute_input": "2025-01-02T09:13:36.046004Z",
          "iopub.status.idle": "2025-01-02T09:13:36.049807Z",
          "shell.execute_reply.started": "2025-01-02T09:13:36.045976Z",
          "shell.execute_reply": "2025-01-02T09:13:36.048902Z"
        },
        "id": "p0goTw6Da7JI"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def inference(model,gpt2_tokenizer, t5_tokenizer, eval_dataset, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    metacognitive_vector_ids, problem_student_code_ids, problem_expected_code_ids,student_code_ids, target_ids = eval_dataset[0]\n",
        "\n",
        "    metacognitive_tensor = metacognitive_vector_ids.unsqueeze(0).to(device)\n",
        "    problem_student_code_tensor = problem_student_code_ids.unsqueeze(0).to(device)\n",
        "    problem_expected_code_tensor = problem_expected_code_ids.unsqueeze(0).to(device)\n",
        "    target_tensor = target_ids.unsqueeze(0).to(device)\n",
        "\n",
        "    student_attention_mask = (problem_student_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n",
        "    expected_attention_mask = (problem_expected_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        logits = model(\n",
        "            metacognitive_vector_ids=metacognitive_tensor,\n",
        "            problem_student_code_ids=problem_student_code_tensor,\n",
        "            problem_expected_code_ids=problem_expected_code_tensor,\n",
        "            expected_attention_mask=expected_attention_mask,\n",
        "            student_attention_mask=student_attention_mask\n",
        "        )\n",
        "\n",
        "        predictions = logits.argmax(dim=-1).squeeze().tolist()\n",
        "        filtered_tokens = [token for token in predictions if token != 0]\n",
        "        #decoded_text = t5_tokenizer.decode(filtered_tokens, skip_special_tokens=False)\n",
        "        decoded_text = t5_tokenizer.decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "        return filtered_tokens, decoded_text\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:25.839368Z",
          "iopub.execute_input": "2025-01-02T09:42:25.839702Z",
          "iopub.status.idle": "2025-01-02T09:42:25.84611Z",
          "shell.execute_reply.started": "2025-01-02T09:42:25.839676Z",
          "shell.execute_reply": "2025-01-02T09:42:25.845101Z"
        },
        "id": "GGKQrOYQa7JJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:26.462145Z",
          "iopub.execute_input": "2025-01-02T09:42:26.462503Z",
          "iopub.status.idle": "2025-01-02T09:42:26.555247Z",
          "shell.execute_reply.started": "2025-01-02T09:42:26.462473Z",
          "shell.execute_reply": "2025-01-02T09:42:26.554554Z"
        },
        "id": "Nk1Ua-_va7JJ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted Tokens:\", predictions)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:26.833831Z",
          "iopub.execute_input": "2025-01-02T09:42:26.834114Z",
          "iopub.status.idle": "2025-01-02T09:42:26.838824Z",
          "shell.execute_reply.started": "2025-01-02T09:42:26.834092Z",
          "shell.execute_reply": "2025-01-02T09:42:26.837971Z"
        },
        "id": "0i90o8Nfa7JK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded Text:\", decoded_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:27.089445Z",
          "iopub.execute_input": "2025-01-02T09:42:27.089745Z",
          "iopub.status.idle": "2025-01-02T09:42:27.094494Z",
          "shell.execute_reply.started": "2025-01-02T09:42:27.089722Z",
          "shell.execute_reply": "2025-01-02T09:42:27.093656Z"
        },
        "id": "Mv7lQhaFa7JK"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer=None):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"Checkpoint loaded: Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    return model, optimizer, epoch, loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:56.480065Z",
          "iopub.execute_input": "2025-01-02T09:14:56.480394Z",
          "iopub.status.idle": "2025-01-02T09:14:56.484822Z",
          "shell.execute_reply.started": "2025-01-02T09:14:56.480367Z",
          "shell.execute_reply": "2025-01-02T09:14:56.483857Z"
        },
        "id": "XRItYXvQa7JN"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/model_epoch_20.pth\"\n",
        "model, optimizer, start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:20.031344Z",
          "iopub.execute_input": "2025-01-02T09:14:20.031652Z",
          "iopub.status.idle": "2025-01-02T09:14:21.532472Z",
          "shell.execute_reply.started": "2025-01-02T09:14:20.031628Z",
          "shell.execute_reply": "2025-01-02T09:14:21.531698Z"
        },
        "id": "iJ7FRM_wa7JO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/model_epoch_10.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Use GPU if available: 'cuda'\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:55.653477Z",
          "iopub.execute_input": "2025-01-02T09:13:55.653715Z",
          "iopub.status.idle": "2025-01-02T09:13:55.676084Z",
          "shell.execute_reply.started": "2025-01-02T09:13:55.653693Z",
          "shell.execute_reply": "2025-01-02T09:13:55.674979Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "tBk9w-l_a7JO"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:26.196139Z",
          "iopub.execute_input": "2025-01-02T09:14:26.19651Z",
          "iopub.status.idle": "2025-01-02T09:14:26.201901Z",
          "shell.execute_reply.started": "2025-01-02T09:14:26.196481Z",
          "shell.execute_reply": "2025-01-02T09:14:26.200956Z"
        },
        "id": "b9Shapm3a7JP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval1 = df[449:450].reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:21.71876Z",
          "iopub.execute_input": "2025-01-02T09:15:21.719058Z",
          "iopub.status.idle": "2025-01-02T09:15:21.723418Z",
          "shell.execute_reply.started": "2025-01-02T09:15:21.719035Z",
          "shell.execute_reply": "2025-01-02T09:15:21.722544Z"
        },
        "id": "QznZNXd2a7JP"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset1 = CustomDataset(df_eval1, t5_tokenizer,gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:22.79416Z",
          "iopub.execute_input": "2025-01-02T09:15:22.794471Z",
          "iopub.status.idle": "2025-01-02T09:15:22.798035Z",
          "shell.execute_reply.started": "2025-01-02T09:15:22.794449Z",
          "shell.execute_reply": "2025-01-02T09:15:22.79709Z"
        },
        "id": "JuJQTbuma7JQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset1, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:44.516595Z",
          "iopub.execute_input": "2025-01-02T09:15:44.516895Z",
          "iopub.status.idle": "2025-01-02T09:15:44.999499Z",
          "shell.execute_reply.started": "2025-01-02T09:15:44.516872Z",
          "shell.execute_reply": "2025-01-02T09:15:44.998792Z"
        },
        "id": "450TkAAMa7JQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded Text:\", decoded_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:47.030509Z",
          "iopub.execute_input": "2025-01-02T09:15:47.030805Z",
          "iopub.status.idle": "2025-01-02T09:15:47.035393Z",
          "shell.execute_reply.started": "2025-01-02T09:15:47.030783Z",
          "shell.execute_reply": "2025-01-02T09:15:47.034606Z"
        },
        "id": "wOV8HjGSa7JQ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "YVP6ZYJXa7JQ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}