{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 10048507,
          "sourceType": "datasetVersion",
          "datasetId": 6190931
        },
        {
          "sourceId": 10242967,
          "sourceType": "datasetVersion",
          "datasetId": 6334477
        },
        {
          "sourceId": 10316683,
          "sourceType": "datasetVersion",
          "datasetId": 6386966
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "cross attentive adaptaion-1",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2542de9970fc4940b9d84a554163e2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eb3104f9cf604bd9a9d4dd535ccdc0f6",
              "IPY_MODEL_0e575c035aac40109d9b2273afe1d032",
              "IPY_MODEL_5a33b36e67e74be1b38ac833b436dd27"
            ],
            "layout": "IPY_MODEL_638c4117bed54f97bec2d66f50d89693"
          }
        },
        "eb3104f9cf604bd9a9d4dd535ccdc0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_caa1ae4a24ba425b918da86992efea74",
            "placeholder": "​",
            "style": "IPY_MODEL_8d3f733dce80451d848f7676ac8855d1",
            "value": "config.json: 100%"
          }
        },
        "0e575c035aac40109d9b2273afe1d032": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c48a809cf8a42a8ad2550c450264ec1",
            "max": 1208,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_86f33163d0d94c74a75cebfab0e2b343",
            "value": 1208
          }
        },
        "5a33b36e67e74be1b38ac833b436dd27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86e7a913d90a4f6bb8c10cda9631e98e",
            "placeholder": "​",
            "style": "IPY_MODEL_1c3911c9bdb14e5f9ba2508d568227a0",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 56.6kB/s]"
          }
        },
        "638c4117bed54f97bec2d66f50d89693": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caa1ae4a24ba425b918da86992efea74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d3f733dce80451d848f7676ac8855d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c48a809cf8a42a8ad2550c450264ec1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f33163d0d94c74a75cebfab0e2b343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86e7a913d90a4f6bb8c10cda9631e98e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c3911c9bdb14e5f9ba2508d568227a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6708efcabf6f4ef4b14c183a5c2e7405": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d0c1bb2fe5984a379577246a05182062",
              "IPY_MODEL_49204f09546d4d6f9738b6cf8656d0a6",
              "IPY_MODEL_1c01494cacf44effabf60b1cbcb6f232"
            ],
            "layout": "IPY_MODEL_fed6ccf45ad44c9bbea2ab573eb61961"
          }
        },
        "d0c1bb2fe5984a379577246a05182062": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ea01d57c1634c088b919928349a5503",
            "placeholder": "​",
            "style": "IPY_MODEL_f3a59e8c50d84fed84e2a1fcd0553da4",
            "value": "spiece.model: 100%"
          }
        },
        "49204f09546d4d6f9738b6cf8656d0a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b9ec0647057d451a929e7d87510fd3dc",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_50d0c84e5c4248c9b1d4a01d31bb4621",
            "value": 791656
          }
        },
        "1c01494cacf44effabf60b1cbcb6f232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4db22735de904e8da3e56519520129ff",
            "placeholder": "​",
            "style": "IPY_MODEL_d7cf8a25040f480fbfd54e6ea2b5480d",
            "value": " 792k/792k [00:00&lt;00:00, 3.07MB/s]"
          }
        },
        "fed6ccf45ad44c9bbea2ab573eb61961": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ea01d57c1634c088b919928349a5503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a59e8c50d84fed84e2a1fcd0553da4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b9ec0647057d451a929e7d87510fd3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d0c84e5c4248c9b1d4a01d31bb4621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4db22735de904e8da3e56519520129ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7cf8a25040f480fbfd54e6ea2b5480d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d541590b10944842840dd587a44e7ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ca8acdf0f324b2e9c819db60f0516d7",
              "IPY_MODEL_72dda08340fa4b90a70b793f0a3e480c",
              "IPY_MODEL_1d6841c1ab414395befc5d0b087cd279"
            ],
            "layout": "IPY_MODEL_ba6a6a3d37f047d885504cebe153a858"
          }
        },
        "3ca8acdf0f324b2e9c819db60f0516d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e62fdc7b90384efdad270c1814715e9e",
            "placeholder": "​",
            "style": "IPY_MODEL_4037ec613fa14ff2837d2d61fcf55008",
            "value": "tokenizer.json: 100%"
          }
        },
        "72dda08340fa4b90a70b793f0a3e480c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f64dc7cfaf54d5fb5c109db3a3958f9",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3bd3957a0ef740a7a458d6f68e952857",
            "value": 1389353
          }
        },
        "1d6841c1ab414395befc5d0b087cd279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df7b8f239fa24759a687b9bd494c8cce",
            "placeholder": "​",
            "style": "IPY_MODEL_a22a1d1214c94f7bb6f64eb7efe62df5",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "ba6a6a3d37f047d885504cebe153a858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e62fdc7b90384efdad270c1814715e9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4037ec613fa14ff2837d2d61fcf55008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f64dc7cfaf54d5fb5c109db3a3958f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3bd3957a0ef740a7a458d6f68e952857": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "df7b8f239fa24759a687b9bd494c8cce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a22a1d1214c94f7bb6f64eb7efe62df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cfc66145f65744c0939753662217e8ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_939dbda990bc4f6d84dec480f80d826d",
              "IPY_MODEL_1932d06865d741e7983b8e221d427420",
              "IPY_MODEL_02e840646ee04dd5a8dd0bbfa3f2f30f"
            ],
            "layout": "IPY_MODEL_bedf57b3fd644d9997bd30bf519c4d22"
          }
        },
        "939dbda990bc4f6d84dec480f80d826d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ea7f0ce8fdd4cb9baa9885b8f4768d2",
            "placeholder": "​",
            "style": "IPY_MODEL_7586d40dc3a8483c9646e8db732c2e84",
            "value": "model.safetensors: 100%"
          }
        },
        "1932d06865d741e7983b8e221d427420": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5033ea2c0cbe45e5a18deab176e1afd5",
            "max": 891646390,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a840667d149a474cb2440c0e43c8a942",
            "value": 891646390
          }
        },
        "02e840646ee04dd5a8dd0bbfa3f2f30f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef1ee3a19c3b4774b850b11343de9b3b",
            "placeholder": "​",
            "style": "IPY_MODEL_2686a578e27d4c4089c8b05a381bcc5b",
            "value": " 892M/892M [00:19&lt;00:00, 61.0MB/s]"
          }
        },
        "bedf57b3fd644d9997bd30bf519c4d22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ea7f0ce8fdd4cb9baa9885b8f4768d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7586d40dc3a8483c9646e8db732c2e84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5033ea2c0cbe45e5a18deab176e1afd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a840667d149a474cb2440c0e43c8a942": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef1ee3a19c3b4774b850b11343de9b3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2686a578e27d4c4089c8b05a381bcc5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/24-FYP-Automated-Feedback-Generation/Adaptive-attention/blob/main/cross_attentive_adaptaion_1-1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "uom200407h_modified_dataset_path = kagglehub.dataset_download('uom200407h/modified-dataset')\n",
        "uom200644f_metacognitive_dataset_path = kagglehub.dataset_download('uom200644f/metacognitive-dataset')\n",
        "bashadithennakoon_metacognitive_feedback_for_algorithm_solving_path = kagglehub.dataset_download('bashadithennakoon/metacognitive-feedback-for-algorithm-solving')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "LNcuswuWpjwD"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "KMnd25oUpjwE"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers torch"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:24.967009Z",
          "iopub.execute_input": "2025-01-02T06:08:24.967421Z",
          "iopub.status.idle": "2025-01-02T06:08:29.244538Z",
          "shell.execute_reply.started": "2025-01-02T06:08:24.967392Z",
          "shell.execute_reply": "2025-01-02T06:08:29.243357Z"
        },
        "id": "hVhUJQM9pjwE",
        "outputId": "cff5655f-d245-4b13-f3c6-5a8a4990d037",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.47.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.27.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.12.14)\n"
          ]
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from transformers import AutoModel, AutoTokenizer, GPT2Model,GPT2Tokenizer,GPT2LMHeadModel\n",
        "from transformers import AutoTokenizer, T5ForConditionalGeneration , T5Tokenizer , T5Model\n",
        "import pandas as pd"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:29.245896Z",
          "iopub.execute_input": "2025-01-02T06:08:29.246143Z",
          "iopub.status.idle": "2025-01-02T06:08:33.952771Z",
          "shell.execute_reply.started": "2025-01-02T06:08:29.246123Z",
          "shell.execute_reply": "2025-01-02T06:08:33.952103Z"
        },
        "id": "1TS1Tes0pjwF"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:33.953928Z",
          "iopub.execute_input": "2025-01-02T06:08:33.954362Z",
          "iopub.status.idle": "2025-01-02T06:08:33.996954Z",
          "shell.execute_reply.started": "2025-01-02T06:08:33.95434Z",
          "shell.execute_reply": "2025-01-02T06:08:33.996229Z"
        },
        "id": "_Dl9_6YPpjwF"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:33.99866Z",
          "iopub.execute_input": "2025-01-02T06:08:33.998937Z",
          "iopub.status.idle": "2025-01-02T06:08:34.012451Z",
          "shell.execute_reply.started": "2025-01-02T06:08:33.998915Z",
          "shell.execute_reply": "2025-01-02T06:08:34.011685Z"
        },
        "id": "GcU138QapjwF",
        "outputId": "2a5a9681-5e11-4539-d65e-91206859a3fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = \"t5-base\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:34.013194Z",
          "iopub.execute_input": "2025-01-02T06:08:34.013482Z",
          "iopub.status.idle": "2025-01-02T06:08:34.022441Z",
          "shell.execute_reply.started": "2025-01-02T06:08:34.013455Z",
          "shell.execute_reply": "2025-01-02T06:08:34.021756Z"
        },
        "id": "2ioIaiA7pjwG"
      },
      "outputs": [],
      "execution_count": 147
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:34.023211Z",
          "iopub.execute_input": "2025-01-02T06:08:34.023468Z",
          "iopub.status.idle": "2025-01-02T06:08:37.429111Z",
          "shell.execute_reply.started": "2025-01-02T06:08:34.023443Z",
          "shell.execute_reply": "2025-01-02T06:08:37.428117Z"
        },
        "id": "kXHpFFKzpjwG",
        "outputId": "839af846-df47-47c5-ea8c-c02b945aacd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "2542de9970fc4940b9d84a554163e2e8",
            "eb3104f9cf604bd9a9d4dd535ccdc0f6",
            "0e575c035aac40109d9b2273afe1d032",
            "5a33b36e67e74be1b38ac833b436dd27",
            "638c4117bed54f97bec2d66f50d89693",
            "caa1ae4a24ba425b918da86992efea74",
            "8d3f733dce80451d848f7676ac8855d1",
            "2c48a809cf8a42a8ad2550c450264ec1",
            "86f33163d0d94c74a75cebfab0e2b343",
            "86e7a913d90a4f6bb8c10cda9631e98e",
            "1c3911c9bdb14e5f9ba2508d568227a0",
            "6708efcabf6f4ef4b14c183a5c2e7405",
            "d0c1bb2fe5984a379577246a05182062",
            "49204f09546d4d6f9738b6cf8656d0a6",
            "1c01494cacf44effabf60b1cbcb6f232",
            "fed6ccf45ad44c9bbea2ab573eb61961",
            "5ea01d57c1634c088b919928349a5503",
            "f3a59e8c50d84fed84e2a1fcd0553da4",
            "b9ec0647057d451a929e7d87510fd3dc",
            "50d0c84e5c4248c9b1d4a01d31bb4621",
            "4db22735de904e8da3e56519520129ff",
            "d7cf8a25040f480fbfd54e6ea2b5480d",
            "d541590b10944842840dd587a44e7ca9",
            "3ca8acdf0f324b2e9c819db60f0516d7",
            "72dda08340fa4b90a70b793f0a3e480c",
            "1d6841c1ab414395befc5d0b087cd279",
            "ba6a6a3d37f047d885504cebe153a858",
            "e62fdc7b90384efdad270c1814715e9e",
            "4037ec613fa14ff2837d2d61fcf55008",
            "7f64dc7cfaf54d5fb5c109db3a3958f9",
            "3bd3957a0ef740a7a458d6f68e952857",
            "df7b8f239fa24759a687b9bd494c8cce",
            "a22a1d1214c94f7bb6f64eb7efe62df5"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2542de9970fc4940b9d84a554163e2e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6708efcabf6f4ef4b14c183a5c2e7405"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d541590b10944842840dd587a44e7ca9"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 148
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer.vocab_size"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:37.429996Z",
          "iopub.execute_input": "2025-01-02T06:08:37.43031Z",
          "iopub.status.idle": "2025-01-02T06:08:37.43526Z",
          "shell.execute_reply.started": "2025-01-02T06:08:37.430282Z",
          "shell.execute_reply": "2025-01-02T06:08:37.434517Z"
        },
        "id": "cCH5LvfOpjwG",
        "outputId": "d0b0d6a7-3df3-43a8-e2ee-d8f8de5eaa7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "32100"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ],
      "execution_count": 149
    },
    {
      "cell_type": "code",
      "source": [
        "#set the max length to model's default present max length\n",
        "t5_tokenizer.model_max_length = t5_tokenizer.model_max_length"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:37.437709Z",
          "iopub.execute_input": "2025-01-02T06:08:37.437914Z",
          "iopub.status.idle": "2025-01-02T06:08:37.447464Z",
          "shell.execute_reply.started": "2025-01-02T06:08:37.437896Z",
          "shell.execute_reply": "2025-01-02T06:08:37.446699Z"
        },
        "id": "Hrfz8HGopjwH"
      },
      "outputs": [],
      "execution_count": 150
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:37.448905Z",
          "iopub.execute_input": "2025-01-02T06:08:37.449171Z",
          "iopub.status.idle": "2025-01-02T06:08:41.670328Z",
          "shell.execute_reply.started": "2025-01-02T06:08:37.449151Z",
          "shell.execute_reply": "2025-01-02T06:08:41.669618Z"
        },
        "id": "zQFO6p83pjwH"
      },
      "outputs": [],
      "execution_count": 151
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:41.671129Z",
          "iopub.execute_input": "2025-01-02T06:08:41.671369Z",
          "iopub.status.idle": "2025-01-02T06:08:41.674927Z",
          "shell.execute_reply.started": "2025-01-02T06:08:41.671348Z",
          "shell.execute_reply": "2025-01-02T06:08:41.674209Z"
        },
        "id": "8nLCTblZpjwH"
      },
      "outputs": [],
      "execution_count": 152
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DdttEVw8sHOp",
        "outputId": "755235e9-ba98-47e7-ebc0-a62138f93716",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/drive/MyDrive/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\"\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "cMOGnyWssNQ4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# file_path = \"/kaggle/input/metacognitive-feedback-for-algorithm-solving/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\"\n",
        "# df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:41.675634Z",
          "iopub.execute_input": "2025-01-02T06:08:41.675875Z",
          "iopub.status.idle": "2025-01-02T06:08:43.381036Z",
          "shell.execute_reply.started": "2025-01-02T06:08:41.675854Z",
          "shell.execute_reply": "2025-01-02T06:08:43.380398Z"
        },
        "id": "TYr5YqKgpjwH"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.381832Z",
          "iopub.execute_input": "2025-01-02T06:08:43.382085Z",
          "iopub.status.idle": "2025-01-02T06:08:43.388103Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.382061Z",
          "shell.execute_reply": "2025-01-02T06:08:43.387309Z"
        },
        "id": "gt84edc9pjwI",
        "outputId": "7a0b7251-1ac1-42ac-e0df-390220f8a354",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Question 1', 'Response 1', 'Right answer 1', 'Q01', 'Q02', 'Q03',\n",
              "       'Q04', 'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13',\n",
              "       'Q14', 'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "df.rename(\n",
        "    columns={\n",
        "        'Question 1': 'Problem',\n",
        "        'Response 1': 'Student_code',\n",
        "        'Right answer 1': 'Expected_code'\n",
        "    },\n",
        "    inplace=True\n",
        ")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.389038Z",
          "iopub.execute_input": "2025-01-02T06:08:43.389367Z",
          "iopub.status.idle": "2025-01-02T06:08:43.401594Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.389333Z",
          "shell.execute_reply": "2025-01-02T06:08:43.400882Z"
        },
        "id": "c2tlAVuUpjwI"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.402395Z",
          "iopub.execute_input": "2025-01-02T06:08:43.402598Z",
          "iopub.status.idle": "2025-01-02T06:08:43.43044Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.40258Z",
          "shell.execute_reply": "2025-01-02T06:08:43.429779Z"
        },
        "id": "QfHS1Ix7pjwI",
        "outputId": "df83c683-f5c0-43e4-8f19-879f3ff9933d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 609
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Problem  \\\n",
              "0  Develop a Python program that takes the name o...   \n",
              "1  Develop a Python program that takes the name o...   \n",
              "2  Develop a Python program that takes the name o...   \n",
              "\n",
              "                                        Student_code  \\\n",
              "0  file_input = input()      file_open = open(fil...   \n",
              "1  file_input = input()      file_open = open(fil...   \n",
              "2  file_input = input()      file_open = open(fil...   \n",
              "\n",
              "                                       Expected_code        Q01  \\\n",
              "0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "\n",
              "             Q02               Q03        Q04            Q05            Q06  \\\n",
              "0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "\n",
              "                Q07  ...        Q09        Q10            Q11            Q12  \\\n",
              "0  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "1  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "2  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "\n",
              "             Q13        Q14        Q15               Q16  \\\n",
              "0  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n",
              "1  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n",
              "2  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n",
              "\n",
              "                                metacognitive_vector  \\\n",
              "0  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "1  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "2  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "\n",
              "                              metacognitive_feedback  \n",
              "0  Your initial code serves as a starting point, ...  \n",
              "1  Your code exhibits a solid attempt at reading ...  \n",
              "2  It looks like you're in a good place with some...  \n",
              "\n",
              "[3 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32dfb058-3f58-402d-a7d2-4150b18a8003\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Problem</th>\n",
              "      <th>Student_code</th>\n",
              "      <th>Expected_code</th>\n",
              "      <th>Q01</th>\n",
              "      <th>Q02</th>\n",
              "      <th>Q03</th>\n",
              "      <th>Q04</th>\n",
              "      <th>Q05</th>\n",
              "      <th>Q06</th>\n",
              "      <th>Q07</th>\n",
              "      <th>...</th>\n",
              "      <th>Q09</th>\n",
              "      <th>Q10</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>metacognitive_vector</th>\n",
              "      <th>metacognitive_feedback</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your initial code serves as a starting point, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your code exhibits a solid attempt at reading ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>It looks like you're in a good place with some...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 21 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32dfb058-3f58-402d-a7d2-4150b18a8003')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-32dfb058-3f58-402d-a7d2-4150b18a8003 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-32dfb058-3f58-402d-a7d2-4150b18a8003');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b368f987-63f6-49e5-a42c-32b0898ed112\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b368f987-63f6-49e5-a42c-32b0898ed112')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b368f987-63f6-49e5-a42c-32b0898ed112 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_problem_student'] = df['Problem'] + \" \" + df['Student_code']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.431162Z",
          "iopub.execute_input": "2025-01-02T06:08:43.431426Z",
          "iopub.status.idle": "2025-01-02T06:08:43.573074Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.431394Z",
          "shell.execute_reply": "2025-01-02T06:08:43.572147Z"
        },
        "id": "aysUh8WipjwI"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "df['combined_problem_expected'] = df['Problem'] + \" \" + df['Expected_code']"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.573919Z",
          "iopub.execute_input": "2025-01-02T06:08:43.574218Z",
          "iopub.status.idle": "2025-01-02T06:08:43.648285Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.574194Z",
          "shell.execute_reply": "2025-01-02T06:08:43.647329Z"
        },
        "id": "UPFyPX7UpjwI"
      },
      "outputs": [],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.649226Z",
          "iopub.execute_input": "2025-01-02T06:08:43.64951Z",
          "iopub.status.idle": "2025-01-02T06:08:43.661546Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.649489Z",
          "shell.execute_reply": "2025-01-02T06:08:43.660871Z"
        },
        "id": "A1S8JsQIpjwI",
        "outputId": "e5a758aa-da5a-4270-cc82-9ce5bb094ade",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Problem', 'Student_code', 'Expected_code', 'Q01', 'Q02', 'Q03', 'Q04',\n",
              "       'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14',\n",
              "       'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback',\n",
              "       'combined_problem_student', 'combined_problem_expected'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "df.dropna(subset=['Problem', 'metacognitive_feedback', 'combined_problem_student'], inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.662315Z",
          "iopub.execute_input": "2025-01-02T06:08:43.662559Z",
          "iopub.status.idle": "2025-01-02T06:08:43.687747Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.662539Z",
          "shell.execute_reply": "2025-01-02T06:08:43.687121Z"
        },
        "id": "Mm2xIDvYpjwI"
      },
      "outputs": [],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": [
        "df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.688699Z",
          "iopub.execute_input": "2025-01-02T06:08:43.688899Z",
          "iopub.status.idle": "2025-01-02T06:08:43.692403Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.688881Z",
          "shell.execute_reply": "2025-01-02T06:08:43.691693Z"
        },
        "id": "c9GE6fswpjwJ"
      },
      "outputs": [],
      "execution_count": 23
    },
    {
      "cell_type": "code",
      "source": [
        "df.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.693122Z",
          "iopub.execute_input": "2025-01-02T06:08:43.693419Z",
          "iopub.status.idle": "2025-01-02T06:08:43.723279Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.693388Z",
          "shell.execute_reply": "2025-01-02T06:08:43.722556Z"
        },
        "id": "J5n_pnThpjwJ",
        "outputId": "3641d5b1-d0e9-410a-8df0-7cc95dcb9ca5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Problem                      0\n",
              "Student_code                 0\n",
              "Expected_code                0\n",
              "Q01                          0\n",
              "Q02                          0\n",
              "Q03                          0\n",
              "Q04                          0\n",
              "Q05                          0\n",
              "Q06                          0\n",
              "Q07                          0\n",
              "Q08                          0\n",
              "Q09                          0\n",
              "Q10                          0\n",
              "Q11                          0\n",
              "Q12                          0\n",
              "Q13                          0\n",
              "Q14                          0\n",
              "Q15                          0\n",
              "Q16                          0\n",
              "metacognitive_vector         0\n",
              "metacognitive_feedback       0\n",
              "combined_problem_student     0\n",
              "combined_problem_expected    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Problem</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Student_code</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Expected_code</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q01</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q02</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q03</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q04</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q05</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q06</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q07</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q08</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q09</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q11</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q12</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q13</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q14</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metacognitive_vector</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metacognitive_feedback</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>combined_problem_student</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>combined_problem_expected</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": [
        "df['metacognitive_feedback'][100]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.725525Z",
          "iopub.execute_input": "2025-01-02T06:08:43.725755Z",
          "iopub.status.idle": "2025-01-02T06:08:43.734798Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.725726Z",
          "shell.execute_reply": "2025-01-02T06:08:43.734166Z"
        },
        "id": "qfX8XegZpjwJ",
        "outputId": "8a6a7844-d1f3-41a9-8f08-2c6a56310e0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Your current implementation shows a good effort in structuring your code with functions, but there are some areas where further refinement is necessary to meet the problem requirements. First, consider how you're capturing the relationships between birth years and heights. While you are correctly gathering names, birthdates, and heights into a dictionary, think about how you can aggregate heights by decade instead of year. This will streamline the calculation of average heights. It’s crucial to loop through your input list once to comprehend and process the data before beginning any calculations for averaging—possibly consolidating this logic in your `calculate_average_height` function. Also, ensure that you are converting heights to the correct data type before performing any arithmetic operations. Additionally, take a closer look at how you’re determining the range of decades; right now it seems like you may be focusing on unique years instead of decades. Consider creating a systematic structure that easily categorizes each height into its corresponding decade bucket. Furthermore, as you develop your code, remember to monitor your program's flow and adjust accordingly—this is especially important when it comes to function calls and data structure manipulations. Establishing a plan before implementation can significantly enhance your problem-solving process and avoid errors stemming from assumptions. Overall, maintain momentum and continue refining your approach by checking each component against the problem's requirements, thus ensuring coherence and completeness in your solution.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:08:43.735932Z",
          "iopub.execute_input": "2025-01-02T06:08:43.736168Z",
          "iopub.status.idle": "2025-01-02T06:08:43.760916Z",
          "shell.execute_reply.started": "2025-01-02T06:08:43.736148Z",
          "shell.execute_reply": "2025-01-02T06:08:43.760029Z"
        },
        "id": "3NZSSQHHpjwJ",
        "outputId": "e9ecd4fd-8588-4090-87d9-d17b23855f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 949
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Problem  \\\n",
              "0  Develop a Python program that takes the name o...   \n",
              "1  Develop a Python program that takes the name o...   \n",
              "2  Develop a Python program that takes the name o...   \n",
              "3  Develop a Python program that takes the name o...   \n",
              "4  Develop a Python program that takes the name o...   \n",
              "\n",
              "                                        Student_code  \\\n",
              "0  file_input = input()      file_open = open(fil...   \n",
              "1  file_input = input()      file_open = open(fil...   \n",
              "2  file_input = input()      file_open = open(fil...   \n",
              "3  file_input = input()      file_open = open(fil...   \n",
              "4  file_input = input()      file_open = open(fil...   \n",
              "\n",
              "                                       Expected_code        Q01  \\\n",
              "0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "3  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "4  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n",
              "\n",
              "             Q02               Q03        Q04            Q05            Q06  \\\n",
              "0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "3  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "4  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n",
              "\n",
              "                Q07  ...            Q11            Q12            Q13  \\\n",
              "0  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n",
              "1  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n",
              "2  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n",
              "3  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n",
              "4  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n",
              "\n",
              "         Q14        Q15               Q16  \\\n",
              "0  3 : Often  3 : Often  1 : Almost Never   \n",
              "1  3 : Often  3 : Often  1 : Almost Never   \n",
              "2  3 : Often  3 : Often  1 : Almost Never   \n",
              "3  3 : Often  3 : Often  1 : Almost Never   \n",
              "4  3 : Often  3 : Often  1 : Almost Never   \n",
              "\n",
              "                                metacognitive_vector  \\\n",
              "0  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "1  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "2  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "3  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "4  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n",
              "\n",
              "                              metacognitive_feedback  \\\n",
              "0  Your initial code serves as a starting point, ...   \n",
              "1  Your code exhibits a solid attempt at reading ...   \n",
              "2  It looks like you're in a good place with some...   \n",
              "3  Your approach to reading the file and splittin...   \n",
              "4  Your initial approach to the problem is a good...   \n",
              "\n",
              "                            combined_problem_student  \\\n",
              "0  Develop a Python program that takes the name o...   \n",
              "1  Develop a Python program that takes the name o...   \n",
              "2  Develop a Python program that takes the name o...   \n",
              "3  Develop a Python program that takes the name o...   \n",
              "4  Develop a Python program that takes the name o...   \n",
              "\n",
              "                           combined_problem_expected  \n",
              "0  Develop a Python program that takes the name o...  \n",
              "1  Develop a Python program that takes the name o...  \n",
              "2  Develop a Python program that takes the name o...  \n",
              "3  Develop a Python program that takes the name o...  \n",
              "4  Develop a Python program that takes the name o...  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-689fe8e8-c6e1-498a-86ba-82cbfbcc0684\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Problem</th>\n",
              "      <th>Student_code</th>\n",
              "      <th>Expected_code</th>\n",
              "      <th>Q01</th>\n",
              "      <th>Q02</th>\n",
              "      <th>Q03</th>\n",
              "      <th>Q04</th>\n",
              "      <th>Q05</th>\n",
              "      <th>Q06</th>\n",
              "      <th>Q07</th>\n",
              "      <th>...</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>metacognitive_vector</th>\n",
              "      <th>metacognitive_feedback</th>\n",
              "      <th>combined_problem_student</th>\n",
              "      <th>combined_problem_expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your initial code serves as a starting point, ...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your code exhibits a solid attempt at reading ...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>It looks like you're in a good place with some...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your approach to reading the file and splittin...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>file_input = input()      file_open = open(fil...</td>\n",
              "      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n",
              "      <td>Your initial approach to the problem is a good...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "      <td>Develop a Python program that takes the name o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-689fe8e8-c6e1-498a-86ba-82cbfbcc0684')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-689fe8e8-c6e1-498a-86ba-82cbfbcc0684 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-689fe8e8-c6e1-498a-86ba-82cbfbcc0684');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-4cbd9aad-0dfe-4e39-ae68-13551fffdbcb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-4cbd9aad-0dfe-4e39-ae68-13551fffdbcb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-4cbd9aad-0dfe-4e39-ae68-13551fffdbcb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import ast\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, dataset, t5_tokenizer,gpt2_tokenizer, max_length=512):\n",
        "        self.t5_tokenizer = t5_tokenizer\n",
        "        self.gpt2_tokenizer = gpt2_tokenizer\n",
        "        self.data = dataset\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        metacognitive_vector = self.data['metacognitive_vector'][idx]\n",
        "        problem_student_code = self.data['combined_problem_student'][idx]\n",
        "        problem_expected_code = self.data['combined_problem_expected'][idx]\n",
        "        student_code = self.data['Student_code'][idx]\n",
        "        target = self.data['metacognitive_feedback'][idx]\n",
        "\n",
        "        metacognitive_vector_float = [\n",
        "        float(item.strip()) for item in ast.literal_eval(metacognitive_vector)]\n",
        "        metacognition_vector_ids = torch.tensor(metacognitive_vector_float, dtype=torch.float)\n",
        "\n",
        "        problem_student_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(problem_student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "        problem_expected_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(problem_expected_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "\n",
        "        student_code_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "        target_ids = torch.tensor(\n",
        "            self.t5_tokenizer.encode(target, max_length=self.max_length, truncation=True, padding=\"max_length\")\n",
        "        )\n",
        "\n",
        "        return metacognition_vector_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:18.488069Z",
          "iopub.execute_input": "2025-01-02T06:09:18.488419Z",
          "iopub.status.idle": "2025-01-02T06:09:18.495303Z",
          "shell.execute_reply.started": "2025-01-02T06:09:18.488387Z",
          "shell.execute_reply": "2025-01-02T06:09:18.494412Z"
        },
        "id": "QFezmmtLpjwJ"
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CustomDataset(df, t5_tokenizer, gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:22.87387Z",
          "iopub.execute_input": "2025-01-02T06:09:22.874172Z",
          "iopub.status.idle": "2025-01-02T06:09:22.877948Z",
          "shell.execute_reply.started": "2025-01-02T06:09:22.874148Z",
          "shell.execute_reply": "2025-01-02T06:09:22.877016Z"
        },
        "id": "fppCewFppjwJ"
      },
      "outputs": [],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:22.899381Z",
          "iopub.execute_input": "2025-01-02T06:09:22.899623Z",
          "iopub.status.idle": "2025-01-02T06:09:22.904257Z",
          "shell.execute_reply.started": "2025-01-02T06:09:22.899602Z",
          "shell.execute_reply": "2025-01-02T06:09:22.903407Z"
        },
        "id": "76aVmn1EpjwJ",
        "outputId": "f42e97ee-e300-4182-8bcb-de8e35f5de6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16803"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": [
        "metacognition_vector_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids = dataset[100]\n",
        "print(f\"Metacognition vector IDs: {metacognition_vector_ids}\")\n",
        "print(f\"Expected feedback IDs: {problem_student_code_ids.shape}\")\n",
        "print(f\"Expected encoded feedback IDs: {problem_expected_code_ids.shape}\")\n",
        "print(f\"Student Answer IDs: {student_code_ids}\")\n",
        "print(f\"Target IDs: {target_ids}\")\n",
        "print(\"\\n\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:34:44.49701Z",
          "iopub.execute_input": "2025-01-02T09:34:44.497368Z",
          "iopub.status.idle": "2025-01-02T09:34:44.517188Z",
          "shell.execute_reply.started": "2025-01-02T09:34:44.497338Z",
          "shell.execute_reply": "2025-01-02T09:34:44.516513Z"
        },
        "id": "Xbdi9RZzpjwJ",
        "outputId": "268f95b1-9e25-4c76-9d01-b7b2f2c0ea1c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metacognition vector IDs: tensor([2., 3., 1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 2.])\n",
            "Expected feedback IDs: torch.Size([512])\n",
            "Expected encoded feedback IDs: torch.Size([512])\n",
            "Student Answer IDs: tensor([ 3785,   834, 11966,  4350,  2423,    77,  2562,  9960,  1713,   188,\n",
            "         2176,    15,     6,  2122, 31911,  2294,  2394,     6,  2938, 27436,\n",
            "         1713,   279,    32,   115,     6,  4928, 20223, 13523,  4433,     6,\n",
            "        27640,     5,   357,  1713, 18610,   760,   630,     6,  2884, 31497,\n",
            "         2294,  3072,     6,  2938, 19419,  1713,   308,     9,  6961,     6,\n",
            "         1714,    87,  4305, 13523,  3301,     6,  2606, 16029,  1713,   427,\n",
            "          162,     6,  2517,    87,  5176, 13523,  2079,     6,  2517, 12100,\n",
            "           20,    89,   608,   834, 11966,   599,    77,  2562,   834, 11966,\n",
            "         4350,    61,    10,    28,   539,   599,    77,  2562,   834, 11966,\n",
            "         4350,   976,    52,  8512,    38,  1042,    10, 10223,  2423, 11966,\n",
            "            5,  5236,  6972,  9960,  3785,   834,  3350,  2423,  6306,   908,\n",
            "           21,   331,    16, 10223,    10,  3785,   834,  3350,     5,  3096,\n",
            "          989,   599,  6757,     5,     7, 14192,  9960,     5,     7,  5900,\n",
            "           17,   599,  1686,  8512,    61,  1205,  3785,   834,  3350,    20,\n",
            "           89, 11837,   834, 28951,   834,    88,  2632,   599,  1201,  4347,\n",
            "         1201,  7318,    10,  1903,  3785,   834,  3350,  2423,  5236,   834,\n",
            "        11966,   599,    77,  2562,   834, 11966,  4350,    61,   331,   834,\n",
            "         4370,  2423,     2,   215,   834,  3350,  2423,  6306,   908,    21,\n",
            "            3,    23,    16,   620,   599,    40,    35,   599,    77,  2562,\n",
            "          834,  3350,    61,    61,    10,   331,   834,  4370,  6306,    77,\n",
            "         2562,   834,  3350,  6306,    23,   908,  6306,   536,  4275,     7,\n",
            "         5900,    17,   599,   121,    87,  8512,  6306,   357,   908,   908,\n",
            "         2423,    77,  2562,   834,  3350,  6306,    23,   908,  6306,   357,\n",
            "          908,  2281,   599,  6757,   834,  4370,    61,    20,    89,  3519,\n",
            "          834,  1201,   599,  4370,    61,    10,  3519,   834,  1201,  2423,\n",
            "          567,   782,    21,   843,    16,     3,  4370,    10,     3,    99,\n",
            "         3519,   834,  1201,  2423,  2423,   567,   782,    10,  3519,   834,\n",
            "         1201,  2423,  4397,     3,    15,    40,    99,  3519,   834,  1201,\n",
            "         3155,  4397,    10,  3519,   834,  1201,  2423,  4397,  1205,  3519,\n",
            "          834,  1201,    20,    89,  9858,   834,  1201,   599,  4370,    61,\n",
            "           10,  9858,   834,  1201,  2423,   567,   782,    21,   843,    16,\n",
            "            3,  4370,    10,     3,    99,  9858,   834,  1201,  2423,  2423,\n",
            "          567,   782,    10,  9858,   834,  1201,  2423,  4397,     3,    15,\n",
            "           40,    99,  9858,   834,  1201,     1,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "Target IDs: tensor([  696,   750,  4432,  1267,     3,     9,   207,  1941,    16, 21055,\n",
            "         1725,    39,  1081,    28,  3621,     6,    68,   132,    33,   128,\n",
            "          844,   213,   856, 15489,   297,    19,  1316,    12,   942,     8,\n",
            "          682,  1502,     5,  1485,     6,  1099,   149,    25,    31,    60,\n",
            "            3, 18147,     8,  3079,   344,  3879,   203,    11,  3902,     7,\n",
            "            5,   818,    25,    33,  6549,  7241,  3056,     6,  3879,  5522,\n",
            "            7,     6,    11,  3902,     7,   139,     3,     9, 24297,     6,\n",
            "          317,    81,   149,    25,    54, 12955,  3902,     7,    57,  5112,\n",
            "         1446,    13,   215,     5,   100,    56, 24104,     8, 18643,    13,\n",
            "         1348,  3902,     7,     5,    94,    22,     7,  4462,    12,  6494,\n",
            "          190,    39,  3785,   570,   728,    12, 21494,    11,   433,     8,\n",
            "          331,   274,  1849,   136, 19868,    21,     3,     9, 23980,   318,\n",
            "         2748,     7, 15596, 13250,  1014,    48,  9769,    16,    39,     3,\n",
            "            2, 10379, 14270,   834, 28951,   834,    88,  2632,     2,  1681,\n",
            "            5,  1203,     6,   766,    24,    25,    33,     3, 21049,  3902,\n",
            "            7,    12,     8,  2024,   331,   686,   274,  5505,   136,     3,\n",
            "            9, 30922,    51,  7578,  2673,     5,  5433,     6,   240,     3,\n",
            "            9,  4645,   320,    44,   149,    25,    22,    60,     3, 11682,\n",
            "            8,   620,    13,  4160,   117,   269,   230,    34,  1330,   114,\n",
            "           25,   164,    36,     3,  7388,    30,   775,   203,  1446,    13,\n",
            "         4160,     5,  9151,  1577,     3,     9, 20036,  1809,    24,  1153,\n",
            "         9624, 11498,   776,     7,   284,  3902,   139,   165,     3,  9921,\n",
            "         5112, 11325,     5,  7053,     6,    38,    25,  1344,    39,  1081,\n",
            "            6,  1423,    12,  3393,    39,   478,    31,     7,  2537,    11,\n",
            "         6142, 14031,   318,  8048,    19,   902,   359,   116,    34,   639,\n",
            "           12,  1681,  3088,    11,   331,  1809, 18175,     7,     5, 26550,\n",
            "           53,     3,     9,   515,   274,  4432,    54,  4019,  3391,    39,\n",
            "          682,    18,  6065,    53,   433,    11,  1792,  6854,  6269,    51,\n",
            "           53,    45, 20298,     5,  9126,     6,  1961, 15290,    11,   916,\n",
            "         6273,    77,    53,    39,  1295,    57,  6450,   284,  3876,   581,\n",
            "            8,   682,    31,     7,  1502,     6,  2932,     3,  5833,   576,\n",
            "          760,  1433,    11,   743,   655,    16,    39,  1127,     5,     1,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_tokenizer.pad_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:27.472859Z",
          "iopub.execute_input": "2025-01-02T06:09:27.473144Z",
          "iopub.status.idle": "2025-01-02T06:09:27.477979Z",
          "shell.execute_reply.started": "2025-01-02T06:09:27.473121Z",
          "shell.execute_reply": "2025-01-02T06:09:27.477211Z"
        },
        "id": "dWjDfstJpjwK",
        "outputId": "d96e6719-ef06-40ab-d891-4eba358226a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<|endoftext|>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 154
        }
      ],
      "execution_count": 154
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_pad_token_id = gpt2_tokenizer.pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:27.788216Z",
          "iopub.execute_input": "2025-01-02T06:09:27.788596Z",
          "iopub.status.idle": "2025-01-02T06:09:27.792307Z",
          "shell.execute_reply.started": "2025-01-02T06:09:27.788569Z",
          "shell.execute_reply": "2025-01-02T06:09:27.79144Z"
        },
        "id": "unDS9GICpjwK"
      },
      "outputs": [],
      "execution_count": 155
    },
    {
      "cell_type": "code",
      "source": [
        "gpt2_pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:28.305081Z",
          "iopub.execute_input": "2025-01-02T06:09:28.305435Z",
          "iopub.status.idle": "2025-01-02T06:09:28.310274Z",
          "shell.execute_reply.started": "2025-01-02T06:09:28.305405Z",
          "shell.execute_reply": "2025-01-02T06:09:28.309497Z"
        },
        "id": "AaN3qBkapjwK",
        "outputId": "e5227569-b0f3-427d-804f-e20e1c0bda7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50256"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ],
      "execution_count": 156
    },
    {
      "cell_type": "code",
      "source": [
        "t5_tokenizer.pad_token"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:29.264041Z",
          "iopub.execute_input": "2025-01-02T06:09:29.264377Z",
          "iopub.status.idle": "2025-01-02T06:09:29.269088Z",
          "shell.execute_reply.started": "2025-01-02T06:09:29.264347Z",
          "shell.execute_reply": "2025-01-02T06:09:29.268386Z"
        },
        "id": "vUKOiUHzpjwK",
        "outputId": "aa459d91-7e0f-4c64-b1fc-5d5023745363",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<pad>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "execution_count": 157
    },
    {
      "cell_type": "code",
      "source": [
        "t5_pad_token_id = t5_tokenizer.pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:29.560678Z",
          "iopub.execute_input": "2025-01-02T06:09:29.56095Z",
          "iopub.status.idle": "2025-01-02T06:09:29.564472Z",
          "shell.execute_reply.started": "2025-01-02T06:09:29.560924Z",
          "shell.execute_reply": "2025-01-02T06:09:29.563523Z"
        },
        "id": "bLd7Fx9-pjwK"
      },
      "outputs": [],
      "execution_count": 158
    },
    {
      "cell_type": "code",
      "source": [
        "t5_pad_token_id"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:30.396428Z",
          "iopub.execute_input": "2025-01-02T06:09:30.396744Z",
          "iopub.status.idle": "2025-01-02T06:09:30.401572Z",
          "shell.execute_reply.started": "2025-01-02T06:09:30.396716Z",
          "shell.execute_reply": "2025-01-02T06:09:30.40074Z"
        },
        "id": "ksVTrtIqpjwK",
        "outputId": "3541f610-49d1-4304-c54a-f464f2e825cf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 159
        }
      ],
      "execution_count": 159
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Context Enocder"
      ],
      "metadata": {
        "id": "adATLtNJpjwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ContextEncoder(nn.Module):\n",
        "    def __init__(self, t5_model_name='t5-base', output_dim=768 , max_length = 512):\n",
        "        super(ContextEncoder, self).__init__()\n",
        "\n",
        "        self.max_length = max_length\n",
        "\n",
        "        self.t5_encoder = T5Model.from_pretrained(t5_model_name).encoder\n",
        "        self.t5_tokenizer = T5Tokenizer.from_pretrained(t5_model_name)\n",
        "        self.fc = nn.Linear(self.t5_encoder.config.d_model, output_dim)\n",
        "\n",
        "    def forward(self, problem_code_ids, attention_masks=None, prompt=\"\"):\n",
        "\n",
        "        problem_code = [self.t5_tokenizer.decode(ids, skip_special_tokens=True) for ids in problem_code_ids]\n",
        "\n",
        "        # prompt_encoded = self.t5_tokenizer(\n",
        "        #     prompt,\n",
        "        #     max_length=self.max_length,\n",
        "        #     truncation=True,\n",
        "        #     padding=\"max_length\",\n",
        "        #     return_tensors=\"pt\"\n",
        "        # ).to(problem_code_ids.device)\n",
        "\n",
        "        # batch_size = problem_code_ids.size(0)\n",
        "        # prompt_input_ids = prompt_encoded[\"input_ids\"].expand(batch_size, -1)\n",
        "        # prompt_attention_mask = prompt_encoded[\"attention_mask\"].expand(batch_size, -1)\n",
        "\n",
        "        # combined_input_ids = torch.cat([prompt_input_ids, problem_code_ids], dim=1)\n",
        "        # combined_attention_mask = torch.cat([prompt_attention_mask, attention_masks], dim=1)\n",
        "\n",
        "        # combined_input_ids = combined_input_ids[:, :self.max_length]\n",
        "        # combined_attention_mask = combined_attention_mask[:, :self.max_length]\n",
        "\n",
        "        combined_text = prompt + \" \" + \" \".join(problem_code)\n",
        "\n",
        "        encoded = self.t5_tokenizer(\n",
        "            combined_text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding=\"max_length\",\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(problem_code_ids.device)\n",
        "\n",
        "        batch_size = problem_code_ids.size(0)\n",
        "        input_ids = encoded[\"input_ids\"].expand(batch_size, -1)\n",
        "        attention_mask = encoded[\"attention_mask\"].expand(batch_size, -1)\n",
        "\n",
        "        encoder_outputs = self.t5_encoder(\n",
        "              input_ids=input_ids,\n",
        "              attention_mask=attention_mask\n",
        "          )\n",
        "        decoded_context = self.t5_tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
        "        #print(\"decoded problem prompt code:\",decoded_context)\n",
        "\n",
        "        context_hidden_states = encoder_outputs.last_hidden_state\n",
        "\n",
        "        context_rep = context_hidden_states.mean(dim=1)\n",
        "\n",
        "        # decoded_combined = [\n",
        "        #         self.t5_tokenizer.decode(ids, skip_special_tokens=True)\n",
        "        #         for ids in encoder_outputs.decoder_input_ids[0]]\n",
        "\n",
        "        context_rep = self.fc(context_rep)\n",
        "        final_rep = context_rep.unsqueeze(1)\n",
        "\n",
        "        return final_rep"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:15.206221Z",
          "iopub.execute_input": "2025-01-02T10:52:15.206605Z",
          "iopub.status.idle": "2025-01-02T10:52:15.213439Z",
          "shell.execute_reply.started": "2025-01-02T10:52:15.206575Z",
          "shell.execute_reply": "2025-01-02T10:52:15.212431Z"
        },
        "id": "NUwpXc1rpjwL"
      },
      "outputs": [],
      "execution_count": 160
    },
    {
      "cell_type": "code",
      "source": [
        "context_encoder = ContextEncoder().to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:17.148663Z",
          "iopub.execute_input": "2025-01-02T10:52:17.148965Z",
          "iopub.status.idle": "2025-01-02T10:52:18.69595Z",
          "shell.execute_reply.started": "2025-01-02T10:52:17.148935Z",
          "shell.execute_reply": "2025-01-02T10:52:18.694726Z"
        },
        "id": "IhoVCKCIpjwL",
        "outputId": "cf79cb82-aa21-42c5-a75b-c031b7d8f505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cfc66145f65744c0939753662217e8ba",
            "939dbda990bc4f6d84dec480f80d826d",
            "1932d06865d741e7983b8e221d427420",
            "02e840646ee04dd5a8dd0bbfa3f2f30f",
            "bedf57b3fd644d9997bd30bf519c4d22",
            "4ea7f0ce8fdd4cb9baa9885b8f4768d2",
            "7586d40dc3a8483c9646e8db732c2e84",
            "5033ea2c0cbe45e5a18deab176e1afd5",
            "a840667d149a474cb2440c0e43c8a942",
            "ef1ee3a19c3b4774b850b11343de9b3b",
            "2686a578e27d4c4089c8b05a381bcc5b"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cfc66145f65744c0939753662217e8ba"
            }
          },
          "metadata": {}
        }
      ],
      "execution_count": 161
    },
    {
      "cell_type": "code",
      "source": [
        "context_encoder"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:18.696491Z",
          "iopub.status.idle": "2025-01-02T10:52:18.696788Z",
          "shell.execute_reply": "2025-01-02T10:52:18.696667Z"
        },
        "id": "3JMiHX_vpjwL",
        "outputId": "02fa19ea-4fdd-4fb9-8fcb-dc3d40f33dc9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ContextEncoder(\n",
              "  (t5_encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (fc): Linear(in_features=768, out_features=768, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "execution_count": 162
    },
    {
      "cell_type": "code",
      "source": [
        "class MetacognitionLayer(nn.Module):\n",
        "    def __init__(self, metacognitive_dim=16, output_dim=768 ,\n",
        "                prompt_text=\"Metacognitive feedback helps students reflect on their problem-solving strategies, identify gaps in their understanding, and refine their approach to coding challenges. By focusing on self-awareness and iterative improvement, students can enhance their learning process and achieve better outcomes in programming.\"):\n",
        "        super(MetacognitionLayer, self).__init__()\n",
        "        #16 to 768 mapping\n",
        "        self.metacognitive_fc = nn.Linear(metacognitive_dim, output_dim)\n",
        "        self.final_fc = nn.Linear(output_dim, output_dim)\n",
        "\n",
        "        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n",
        "        self.t5_pad_token_id = self.tokenizer.pad_token_id\n",
        "        self.encoder = T5Model.from_pretrained(\"t5-base\").encoder\n",
        "\n",
        "        self.prompt = prompt_text\n",
        "\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, metacognitive_vector):\n",
        "\n",
        "        input_prompt = self.tokenizer(\n",
        "        self.prompt,\n",
        "        return_tensors=\"pt\",\n",
        "        padding=True,\n",
        "        truncation=True,\n",
        "        max_length=512-16\n",
        "        )\n",
        "        input_prompt = {key: value.to(metacognitive_vector.device) for key, value in input_prompt.items()}\n",
        "        # prompt_attention_mask = (input_prompt != self.t5_pad_token_id).long().to(device)\n",
        "        outputs = self.encoder(input_ids=input_prompt[\"input_ids\"], attention_mask=input_prompt[\"attention_mask\"])\n",
        "        prompt_embedding = outputs.last_hidden_state.mean(dim=1)\n",
        "        prompt_embedding = prompt_embedding.to(metacognitive_vector.device)\n",
        "\n",
        "        metacognitive_rep = self.metacognitive_fc(metacognitive_vector)\n",
        "        final_rep = self.final_fc(metacognitive_rep)\n",
        "        persona_rep = final_rep.unsqueeze(1)\n",
        "        #print(\"persona_rep\",persona_rep.shape)\n",
        "        final_persona = persona_rep + prompt_embedding\n",
        "        print\n",
        "\n",
        "        return final_persona"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:38.89679Z",
          "iopub.execute_input": "2025-01-02T06:09:38.896997Z",
          "iopub.status.idle": "2025-01-02T06:09:38.911581Z",
          "shell.execute_reply.started": "2025-01-02T06:09:38.896978Z",
          "shell.execute_reply": "2025-01-02T06:09:38.910789Z"
        },
        "id": "OYGccXCwpjwM"
      },
      "outputs": [],
      "execution_count": 163
    },
    {
      "cell_type": "code",
      "source": [
        "metacognitive_emb = MetacognitionLayer().to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:38.912762Z",
          "iopub.execute_input": "2025-01-02T06:09:38.91302Z",
          "iopub.status.idle": "2025-01-02T06:09:40.71199Z",
          "shell.execute_reply.started": "2025-01-02T06:09:38.913Z",
          "shell.execute_reply": "2025-01-02T06:09:40.711314Z"
        },
        "id": "3AdOdSUnpjwR"
      },
      "outputs": [],
      "execution_count": 164
    },
    {
      "cell_type": "code",
      "source": [
        "metacognitive_emb"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.712665Z",
          "iopub.execute_input": "2025-01-02T06:09:40.712863Z",
          "iopub.status.idle": "2025-01-02T06:09:40.71886Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.712846Z",
          "shell.execute_reply": "2025-01-02T06:09:40.718129Z"
        },
        "id": "NxvjcZTFpjwR",
        "outputId": "2c2cc203-5c3a-4bad-eb6f-0c42e08d3573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MetacognitionLayer(\n",
              "  (metacognitive_fc): Linear(in_features=16, out_features=768, bias=True)\n",
              "  (final_fc): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "execution_count": 165
    },
    {
      "cell_type": "code",
      "source": [
        "class PAALayer(nn.Module):\n",
        "    def __init__(self, hidden_dimension = 768 , tau=0.8,dropout_rate=0.1):\n",
        "        super(PAALayer, self).__init__()\n",
        "        self.hidden_dimenstion = hidden_dimension\n",
        "        self.tau = tau\n",
        "\n",
        "\n",
        "        self.fc = nn.Linear(2 * hidden_dimension, hidden_dimension)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.fc_out = nn.Linear(hidden_dimension, hidden_dimension)\n",
        "        self.dropout = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "\n",
        "    def forward(self, hR , oP, oC):\n",
        "\n",
        "        Mp_input  = torch.cat([hR,oP], dim=-1)\n",
        "        Mp = self.fc(Mp_input)\n",
        "        Wp = self.sigmoid(Mp)\n",
        "\n",
        "        Mpersona = Wp\n",
        "        Mcontext = 1 - Wp\n",
        "\n",
        "        oP_weighted = Mpersona * oP\n",
        "        oC_weighted = Mcontext * oC\n",
        "\n",
        "        HPAA = oP_weighted + oC_weighted\n",
        "\n",
        "        output = self.fc_out(HPAA)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.719592Z",
          "iopub.execute_input": "2025-01-02T06:09:40.719811Z",
          "iopub.status.idle": "2025-01-02T06:09:40.762911Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.719792Z",
          "shell.execute_reply": "2025-01-02T06:09:40.762187Z"
        },
        "id": "zLEiZTeXpjwR"
      },
      "outputs": [],
      "execution_count": 166
    },
    {
      "cell_type": "code",
      "source": [
        "paa = PAALayer()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.763744Z",
          "iopub.execute_input": "2025-01-02T06:09:40.763978Z",
          "iopub.status.idle": "2025-01-02T06:09:40.78669Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.763958Z",
          "shell.execute_reply": "2025-01-02T06:09:40.785834Z"
        },
        "id": "f1pftFiCpjwR"
      },
      "outputs": [],
      "execution_count": 167
    },
    {
      "cell_type": "code",
      "source": [
        "paa"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.788386Z",
          "iopub.execute_input": "2025-01-02T06:09:40.788602Z",
          "iopub.status.idle": "2025-01-02T06:09:40.793324Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.788584Z",
          "shell.execute_reply": "2025-01-02T06:09:40.792556Z"
        },
        "id": "UpwX-hr4pjwS",
        "outputId": "41af38d9-b585-4492-a583-b0b7ae21fca5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PAALayer(\n",
              "  (fc): Linear(in_features=1536, out_features=768, bias=True)\n",
              "  (sigmoid): Sigmoid()\n",
              "  (fc_out): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "execution_count": 168
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformerBlock(nn.Module):\n",
        "    def __init__(self, hidden_size, tau , dropout_rate=0.1):\n",
        "        super(CustomTransformerBlock, self).__init__()\n",
        "\n",
        "        self.input_self_attention = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n",
        "        self.context_attn = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n",
        "        self.persona_attn = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n",
        "        #self.output_attn = nn.MultiheadAttention(hidden_size, num_head = 12, batch_first = True)\n",
        "\n",
        "        #self.output_self_attention = nn.MultiheadAttention(hidden_size, num_heads=12 , batch_first = True)\n",
        "\n",
        "        self.paa_layer = PAALayer(hidden_dimension=hidden_size, tau=tau)\n",
        "\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_size, 2048),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.1),\n",
        "            nn.Linear(2048, hidden_size),\n",
        "            nn.LayerNorm(hidden_size)\n",
        "        )\n",
        "        self.layer_norm2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, student_initial_state, encoded_persona, encoded_context, current_state):\n",
        "\n",
        "        hR, _ = self.input_self_attention(student_initial_state, student_initial_state, student_initial_state) #query\n",
        "        #print(\"encoded_persona\",encoded_persona.shape)\n",
        "        oP, _ = self.persona_attn(hR, encoded_persona, encoded_persona)\n",
        "        #print(\"attention persona\",oP.shape)\n",
        "        #print(\"hr\",hR.shape)\n",
        "        #print(\"encoded context\",encoded_context.shape)\n",
        "        oC, _ = self.context_attn(hR, encoded_context, encoded_context)\n",
        "\n",
        "\n",
        "        HPAA = self.paa_layer(hR, oP, oC)\n",
        "\n",
        "        mlp_output = self.mlp(HPAA)\n",
        "        output = self.layer_norm2(mlp_output)\n",
        "\n",
        "        return output\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.794354Z",
          "iopub.execute_input": "2025-01-02T06:09:40.794639Z",
          "iopub.status.idle": "2025-01-02T06:09:40.805076Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.794611Z",
          "shell.execute_reply": "2025-01-02T06:09:40.804309Z"
        },
        "id": "kFC2fsbTpjwS"
      },
      "outputs": [],
      "execution_count": 169
    },
    {
      "cell_type": "code",
      "source": [
        "custom_layer = CustomTransformerBlock(768,0.5)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.805955Z",
          "iopub.execute_input": "2025-01-02T06:09:40.806259Z",
          "iopub.status.idle": "2025-01-02T06:09:40.915412Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.806212Z",
          "shell.execute_reply": "2025-01-02T06:09:40.914732Z"
        },
        "id": "cdF6snM4pjwS"
      },
      "outputs": [],
      "execution_count": 170
    },
    {
      "cell_type": "code",
      "source": [
        "custom_layer"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:40.916359Z",
          "iopub.execute_input": "2025-01-02T06:09:40.916685Z",
          "iopub.status.idle": "2025-01-02T06:09:40.921999Z",
          "shell.execute_reply.started": "2025-01-02T06:09:40.916653Z",
          "shell.execute_reply": "2025-01-02T06:09:40.921254Z"
        },
        "id": "I64Ctx16pjwS",
        "outputId": "d06892c3-4bfc-45ab-881c-d586cea12568",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomTransformerBlock(\n",
              "  (input_self_attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (context_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (persona_attn): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (paa_layer): PAALayer(\n",
              "    (fc): Linear(in_features=1536, out_features=768, bias=True)\n",
              "    (sigmoid): Sigmoid()\n",
              "    (fc_out): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (mlp): Sequential(\n",
              "    (0): Linear(in_features=768, out_features=2048, bias=True)\n",
              "    (1): ReLU()\n",
              "    (2): Dropout(p=0.1, inplace=False)\n",
              "    (3): Linear(in_features=2048, out_features=768, bias=True)\n",
              "    (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "  )\n",
              "  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ],
      "execution_count": 171
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "dk4NKPN1pjwS"
      },
      "outputs": [],
      "execution_count": 171
    },
    {
      "cell_type": "code",
      "source": [
        "class PAAModel(nn.Module):\n",
        "    def __init__(self, hidden_size=768, vocab_size = 32100 ,tau=0.8, max_length=512, num_transformer_blocks=4):\n",
        "        super(PAAModel , self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.tau = tau\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_length = max_length\n",
        "        self.num_transformer_blocks = num_transformer_blocks\n",
        "\n",
        "        self.context_encoder = ContextEncoder()\n",
        "\n",
        "        self.metacognitive_emb = MetacognitionLayer()\n",
        "\n",
        "        for param in self.context_encoder.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        for param in self.metacognitive_emb.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "        self.token_embedding = nn.Embedding(vocab_size, hidden_size)\n",
        "        self.position_embedding = nn.Embedding(max_length, hidden_size)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "\n",
        "        self.self_attention = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n",
        "        self.transformer_blocks = nn.ModuleList([CustomTransformerBlock(hidden_size, tau) for _ in range(num_transformer_blocks)])\n",
        "        self.final_fc = nn.Linear(hidden_size, vocab_size)\n",
        "        self.layer_norm = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self,  metacognitive_vector_ids,\n",
        "                       problem_student_code_ids ,\n",
        "                       problem_expected_code_ids ,\n",
        "                       expected_attention_mask,\n",
        "                       student_attention_mask):\n",
        "\n",
        "        metacognitive_vector_emb = self.metacognitive_emb(metacognitive_vector_ids)\n",
        "\n",
        "        problem_student_encoded = self.context_encoder(problem_student_code_ids,\n",
        "                                                attention_masks=student_attention_mask,prompt=\"Here this is a combination of the algorithm problem and the student solved answer code.\")\n",
        "        problem_expected_encoded = self.context_encoder(problem_expected_code_ids,\n",
        "                                                       attention_masks = expected_attention_mask,prompt= \"Here this is the combination of the algorithm problem and the expected correct answer code.\")\n",
        "        #print(\"metacognitive_vector_emb\",metacognitive_vector_emb.shape)\n",
        "        #print(\"problem_student_encoded\",problem_student_encoded.shape)\n",
        "        #print(\"problem_expected_encoded\",problem_expected_encoded.shape)\n",
        "\n",
        "        seq_length = problem_student_encoded.size(1)\n",
        "        token_embeds = self.token_embedding(problem_student_code_ids)\n",
        "        position_ids = torch.arange(0, seq_length, device=problem_student_code_ids.device).unsqueeze(0)\n",
        "        position_embeds = self.position_embedding(position_ids)\n",
        "\n",
        "        inputs_embeds = token_embeds + position_embeds\n",
        "        inputs_embeds = self.dropout(inputs_embeds)\n",
        "\n",
        "        student_initial_state = inputs_embeds\n",
        "        transformer_output = student_initial_state\n",
        "        for transformer_block in self.transformer_blocks:\n",
        "            transformer_output = transformer_block(transformer_output, metacognitive_vector_emb, problem_expected_encoded, transformer_output)\n",
        "\n",
        "        logits = self.final_fc(transformer_output)\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:21.800465Z",
          "iopub.execute_input": "2025-01-02T10:52:21.800786Z",
          "iopub.status.idle": "2025-01-02T10:52:21.808981Z",
          "shell.execute_reply.started": "2025-01-02T10:52:21.800757Z",
          "shell.execute_reply": "2025-01-02T10:52:21.808027Z"
        },
        "id": "gYQ1hqTspjwS"
      },
      "outputs": [],
      "execution_count": 172
    },
    {
      "cell_type": "code",
      "source": [
        "model = PAAModel()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:23.027604Z",
          "iopub.execute_input": "2025-01-02T10:52:23.027892Z",
          "iopub.status.idle": "2025-01-02T10:52:26.69086Z",
          "shell.execute_reply.started": "2025-01-02T10:52:23.027871Z",
          "shell.execute_reply": "2025-01-02T10:52:26.690146Z"
        },
        "id": "bFgepGkPpjwT"
      },
      "outputs": [],
      "execution_count": 173
    },
    {
      "cell_type": "code",
      "source": [
        "model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:52:26.691878Z",
          "iopub.execute_input": "2025-01-02T10:52:26.692111Z",
          "iopub.status.idle": "2025-01-02T10:52:26.716418Z",
          "shell.execute_reply.started": "2025-01-02T10:52:26.692091Z",
          "shell.execute_reply": "2025-01-02T10:52:26.715393Z"
        },
        "id": "wxms-YZapjwT",
        "outputId": "7086db02-bf49-40bd-f2dd-fa1f9ced25e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PAAModel(\n",
              "  (context_encoder): ContextEncoder(\n",
              "    (t5_encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (fc): Linear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (metacognitive_emb): MetacognitionLayer(\n",
              "    (metacognitive_fc): Linear(in_features=16, out_features=768, bias=True)\n",
              "    (final_fc): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (encoder): T5Stack(\n",
              "      (embed_tokens): Embedding(32128, 768)\n",
              "      (block): ModuleList(\n",
              "        (0): T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (relative_attention_bias): Embedding(32, 12)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1-11): 11 x T5Block(\n",
              "          (layer): ModuleList(\n",
              "            (0): T5LayerSelfAttention(\n",
              "              (SelfAttention): T5Attention(\n",
              "                (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "                (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (1): T5LayerFF(\n",
              "              (DenseReluDense): T5DenseActDense(\n",
              "                (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "                (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "                (act): ReLU()\n",
              "              )\n",
              "              (layer_norm): T5LayerNorm()\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (final_layer_norm): T5LayerNorm()\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "  )\n",
              "  (token_embedding): Embedding(32100, 768)\n",
              "  (position_embedding): Embedding(512, 768)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (self_attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "  )\n",
              "  (transformer_blocks): ModuleList(\n",
              "    (0-3): 4 x CustomTransformerBlock(\n",
              "      (input_self_attention): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (context_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (persona_attn): MultiheadAttention(\n",
              "        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "      )\n",
              "      (paa_layer): PAALayer(\n",
              "        (fc): Linear(in_features=1536, out_features=768, bias=True)\n",
              "        (sigmoid): Sigmoid()\n",
              "        (fc_out): Linear(in_features=768, out_features=768, bias=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (mlp): Sequential(\n",
              "        (0): Linear(in_features=768, out_features=2048, bias=True)\n",
              "        (1): ReLU()\n",
              "        (2): Dropout(p=0.1, inplace=False)\n",
              "        (3): Linear(in_features=2048, out_features=768, bias=True)\n",
              "        (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (final_fc): Linear(in_features=768, out_features=32100, bias=True)\n",
              "  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 174
        }
      ],
      "execution_count": 174
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:46.456805Z",
          "iopub.execute_input": "2025-01-02T06:09:46.457037Z",
          "iopub.status.idle": "2025-01-02T06:09:48.78486Z",
          "shell.execute_reply.started": "2025-01-02T06:09:46.457016Z",
          "shell.execute_reply": "2025-01-02T06:09:48.784Z"
        },
        "id": "BKRQjaMipjwT"
      },
      "outputs": [],
      "execution_count": 53
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:48.786008Z",
          "iopub.execute_input": "2025-01-02T06:09:48.786323Z",
          "iopub.status.idle": "2025-01-02T06:09:49.181861Z",
          "shell.execute_reply.started": "2025-01-02T06:09:48.786293Z",
          "shell.execute_reply": "2025-01-02T06:09:49.180947Z"
        },
        "id": "nyLZ9ehIpjwT"
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "code",
      "source": [
        "LOSS = torch.nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:51.777965Z",
          "iopub.execute_input": "2025-01-02T06:09:51.778498Z",
          "iopub.status.idle": "2025-01-02T06:09:51.782608Z",
          "shell.execute_reply.started": "2025-01-02T06:09:51.778463Z",
          "shell.execute_reply": "2025-01-02T06:09:51.78152Z"
        },
        "id": "EkMyIL_VpjwU"
      },
      "outputs": [],
      "execution_count": 55
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 200"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:52.119148Z",
          "iopub.execute_input": "2025-01-02T06:09:52.11941Z",
          "iopub.status.idle": "2025-01-02T06:09:52.122917Z",
          "shell.execute_reply.started": "2025-01-02T06:09:52.119387Z",
          "shell.execute_reply": "2025-01-02T06:09:52.122279Z"
        },
        "id": "gpi8XCovpjwU"
      },
      "outputs": [],
      "execution_count": 56
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df[0:5000]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:52.35715Z",
          "iopub.execute_input": "2025-01-02T06:09:52.357426Z",
          "iopub.status.idle": "2025-01-02T06:09:52.360956Z",
          "shell.execute_reply.started": "2025-01-02T06:09:52.357402Z",
          "shell.execute_reply": "2025-01-02T06:09:52.360128Z"
        },
        "id": "j9s8pg2ZpjwU"
      },
      "outputs": [],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": [
        "len(df_train)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:53.481318Z",
          "iopub.execute_input": "2025-01-02T06:09:53.481594Z",
          "iopub.status.idle": "2025-01-02T06:09:53.486502Z",
          "shell.execute_reply.started": "2025-01-02T06:09:53.481574Z",
          "shell.execute_reply": "2025-01-02T06:09:53.485756Z"
        },
        "id": "nliiGAp9pjwU",
        "outputId": "8e6e8fb7-7fe0-45ad-a575-9451ba60259c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isnull().sum()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:53.528468Z",
          "iopub.execute_input": "2025-01-02T06:09:53.528682Z",
          "iopub.status.idle": "2025-01-02T06:09:53.541472Z",
          "shell.execute_reply.started": "2025-01-02T06:09:53.528664Z",
          "shell.execute_reply": "2025-01-02T06:09:53.540777Z"
        },
        "id": "sc-MV2qJpjwU",
        "outputId": "513fc0d9-4025-434b-e9c4-741a4da91aad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 805
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Problem                      0\n",
              "Student_code                 0\n",
              "Expected_code                0\n",
              "Q01                          0\n",
              "Q02                          0\n",
              "Q03                          0\n",
              "Q04                          0\n",
              "Q05                          0\n",
              "Q06                          0\n",
              "Q07                          0\n",
              "Q08                          0\n",
              "Q09                          0\n",
              "Q10                          0\n",
              "Q11                          0\n",
              "Q12                          0\n",
              "Q13                          0\n",
              "Q14                          0\n",
              "Q15                          0\n",
              "Q16                          0\n",
              "metacognitive_vector         0\n",
              "metacognitive_feedback       0\n",
              "combined_problem_student     0\n",
              "combined_problem_expected    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Problem</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Student_code</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Expected_code</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q01</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q02</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q03</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q04</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q05</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q06</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q07</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q08</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q09</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q10</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q11</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q12</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q13</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q14</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Q16</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metacognitive_vector</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>metacognitive_feedback</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>combined_problem_student</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>combined_problem_expected</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "execution_count": 59
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dataset = CustomDataset(df_train, t5_tokenizer , gpt2_tokenizer)\n",
        "train_dataloader = DataLoader(train_dataset , batch_size = 4 ,shuffle = True )"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:58.598583Z",
          "iopub.execute_input": "2025-01-02T06:09:58.598871Z",
          "iopub.status.idle": "2025-01-02T06:09:58.603138Z",
          "shell.execute_reply.started": "2025-01-02T06:09:58.598848Z",
          "shell.execute_reply": "2025-01-02T06:09:58.602116Z"
        },
        "id": "uUAzk4ScpjwV"
      },
      "outputs": [],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:09:59.293952Z",
          "iopub.execute_input": "2025-01-02T06:09:59.29429Z",
          "iopub.status.idle": "2025-01-02T06:10:03.843928Z",
          "shell.execute_reply.started": "2025-01-02T06:09:59.294229Z",
          "shell.execute_reply": "2025-01-02T06:10:03.842727Z"
        },
        "id": "HFkKd5BOpjwV",
        "outputId": "5c2bd573-d8fc-42dd-a14e-df89a9f4e3b9"
      },
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnotf\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'notf' from 'tensorboard.compat' (/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-66-6d8f5c5a9398>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensorboard\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSummaryWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFileWriter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSummaryWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorboard\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_writer\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRecordWriter\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_convert_np\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmake_np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_embedding\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_embedding_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_mat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_sprite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmake_tsv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrite_pbtxt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_onnx_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_onnx_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_pytorch_graph\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/tensorboard/_embedding.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0m_HAS_GFILE_JOIN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"join\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr_name)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mclass\u001b[0m \u001b[0mLazyModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleType\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;32mdef\u001b[0m \u001b[0m__dir__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(arg)\u001b[0m\n\u001b[1;32m     95\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m                     \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/lazy.py\u001b[0m in \u001b[0;36mload_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mload_once\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorboard/compat/__init__.py\u001b[0m in \u001b[0;36mtf\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m             \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbitwise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/_api/v2/compat/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mforward_compatibility_horizon\u001b[0m \u001b[0;31m# line: 125\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap.py\u001b[0m in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/_bootstrap_external.py\u001b[0m in \u001b[0;36mget_data\u001b[0;34m(self, path)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = \"./checkpoints\"\n",
        "os.makedirs(checkpoint_dir, exist_ok=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T06:10:09.074145Z",
          "iopub.execute_input": "2025-01-02T06:10:09.074462Z",
          "iopub.status.idle": "2025-01-02T06:10:09.078716Z",
          "shell.execute_reply.started": "2025-01-02T06:10:09.074435Z",
          "shell.execute_reply": "2025-01-02T06:10:09.077721Z"
        },
        "id": "5dOO7rRBpjwV"
      },
      "outputs": [],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(num_epochs):\n",
        "    print(f\"Training started for epoch {epoch + 1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for idx, (metacognition_vector_ids,\n",
        "              problem_student_code_ids,\n",
        "              problem_expected_code_ids,\n",
        "              student_code_ids,\n",
        "              target_ids) in enumerate(train_dataloader):\n",
        "\n",
        "        metacognition_vector_ids = metacognition_vector_ids.to(device)\n",
        "        problem_student_code_ids = problem_student_code_ids.to(device)\n",
        "        problem_expected_code_ids = problem_expected_code_ids.to(device)\n",
        "        student_code_ids = student_code_ids.to(device)\n",
        "        target_ids = target_ids.to(device)\n",
        "\n",
        "        #attention masking\n",
        "        student_attention_mask = (problem_student_code_ids != t5_pad_token_id).long().to(device)\n",
        "        expected_attention_mask = (problem_expected_code_ids != t5_pad_token_id).long().to(device)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(metacognition_vector_ids,\n",
        "                       problem_student_code_ids ,\n",
        "                       problem_expected_code_ids ,\n",
        "                       expected_attention_mask,\n",
        "                       student_attention_mask)\n",
        "\n",
        "\n",
        "        logits = logits.view(-1, logits.size(-1))\n",
        "        target_ids = target_ids.view(-1)\n",
        "\n",
        "\n",
        "        loss = LOSS(logits, target_ids)\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "        loss.backward()\n",
        "        for name, param in model.named_parameters():\n",
        "            if 'context_encoder' in name:\n",
        "                assert param.grad is None, f\"Gradients found in frozen encoder {name}\"\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Batch {idx + 1}/{len(train_dataloader)} | Loss: {loss.item():.4f}\" , end='...')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    if epoch % 10 ==0 :\n",
        "            for name, param in model.named_parameters():\n",
        "                if param.requires_grad and param.grad is not None:\n",
        "                    print(f\"Layer: {name} | Grad Norm: {param.grad.norm().item()}\")\n",
        "                elif param.requires_grad:\n",
        "                    print(f\"Layer: {name} | Grad: None\")\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch + 1}.pth\")\n",
        "        torch.save({\n",
        "            'epoch': epoch + 1,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': total_loss / max(len(train_dataloader), 1),\n",
        "        }, checkpoint_path)\n",
        "        print(f\"Checkpoint saved at {checkpoint_path}\")\n",
        "\n",
        "\n",
        "    avg_loss = total_loss / max(len(train_dataloader), 1)\n",
        "    #writer.add_scalar(\"Loss/train\", avg_loss, epoch + 1)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed | Average Loss: {avg_loss:.4f}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T10:48:54.13895Z",
          "iopub.execute_input": "2025-01-02T10:48:54.139256Z",
          "iopub.status.idle": "2025-01-02T10:48:54.224941Z",
          "shell.execute_reply.started": "2025-01-02T10:48:54.139209Z",
          "shell.execute_reply": "2025-01-02T10:48:54.223808Z"
        },
        "id": "HptV-nwRpjwW",
        "outputId": "a5d9e5c5-7aa5-4371-e923-d43adbc87c6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started for epoch 1/200\n",
            "Batch 1/1250 | Loss: 10.5588...Batch 11/1250 | Loss: 10.5565...Batch 21/1250 | Loss: 10.5444...Batch 31/1250 | Loss: 10.5289...Batch 41/1250 | Loss: 10.4944...Batch 51/1250 | Loss: 10.5287...Batch 61/1250 | Loss: 10.5519...Batch 71/1250 | Loss: 10.5991...Batch 81/1250 | Loss: 10.5528...Batch 91/1250 | Loss: 10.5477...Batch 101/1250 | Loss: 10.5033...Batch 111/1250 | Loss: 10.5199...Batch 121/1250 | Loss: 10.5908...Batch 131/1250 | Loss: 10.5355...Batch 141/1250 | Loss: 10.5591...Batch 151/1250 | Loss: 10.5659...Batch 161/1250 | Loss: 10.5293...Batch 171/1250 | Loss: 10.5233...Batch 181/1250 | Loss: 10.5161...Batch 191/1250 | Loss: 10.5375...Batch 201/1250 | Loss: 10.5376...Batch 211/1250 | Loss: 10.5279...Batch 221/1250 | Loss: 10.5417...Batch 231/1250 | Loss: 10.5201...Batch 241/1250 | Loss: 10.5495...Batch 251/1250 | Loss: 10.5136...Batch 261/1250 | Loss: 10.5648...Batch 271/1250 | Loss: 10.5111...Batch 281/1250 | Loss: 10.5314...Batch 291/1250 | Loss: 10.5524..."
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-2e1015e87feb>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         logits = model(metacognition_vector_ids,\n\u001b[0m\u001b[1;32m     25\u001b[0m                        \u001b[0mproblem_student_code_ids\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                        \u001b[0mproblem_expected_code_ids\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-172-a418e141926f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, metacognitive_vector_ids, problem_student_code_ids, problem_expected_code_ids, expected_attention_mask, student_attention_mask)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mmetacognitive_vector_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetacognitive_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetacognitive_vector_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         problem_student_encoded = self.context_encoder(problem_student_code_ids,\n\u001b[0m\u001b[1;32m     38\u001b[0m                                                 attention_masks=student_attention_mask,prompt=\"Here this is a combination of the algorithm problem and the student solved answer code.\")\n\u001b[1;32m     39\u001b[0m         problem_expected_encoded = self.context_encoder(problem_expected_code_ids,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-8cd3a829ffe5>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, problem_code_ids, attention_masks, prompt)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_code_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mproblem_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt5_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem_code_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# prompt_encoded = self.t5_tokenizer(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-160-8cd3a829ffe5>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_code_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_masks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mproblem_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt5_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mids\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mproblem_code_ids\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# prompt_encoded = self.t5_tokenizer(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, **kwargs)\u001b[0m\n\u001b[1;32m   3841\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_py_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3842\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3843\u001b[0;31m         return self._decode(\n\u001b[0m\u001b[1;32m   3844\u001b[0m             \u001b[0mtoken_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3845\u001b[0m             \u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskip_special_tokens\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils.py\u001b[0m in \u001b[0;36m_decode\u001b[0;34m(self, token_ids, skip_special_tokens, clean_up_tokenization_spaces, spaces_between_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m                 \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1118\u001b[0;31m             \u001b[0msub_texts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurrent_sub_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mspaces_between_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/t5/tokenization_t5.py\u001b[0m in \u001b[0;36mconvert_tokens_to_string\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    418\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m             \u001b[0;31m# make sure that special tokens are not decoded using sentencepiece model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprev_is_special\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                     \u001b[0mout_string\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mall_special_tokens\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mConvert\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddedToken\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \"\"\"\n\u001b[0;32m-> 1167\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens_extended\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_toks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1165\u001b[0m         \u001b[0mConvert\u001b[0m \u001b[0mtokens\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtokenizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAddedToken\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mto\u001b[0m \u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \"\"\"\n\u001b[0;32m-> 1167\u001b[0;31m         \u001b[0mall_toks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall_special_tokens_extended\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mall_toks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "execution_count": 175
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), 'paamodel.pth')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:35.127979Z",
          "iopub.execute_input": "2025-01-02T09:15:35.1283Z",
          "iopub.status.idle": "2025-01-02T09:15:38.043298Z",
          "shell.execute_reply.started": "2025-01-02T09:15:35.128272Z",
          "shell.execute_reply": "2025-01-02T09:15:38.042319Z"
        },
        "id": "4GHqfc86pjwW"
      },
      "outputs": [],
      "execution_count": 138
    },
    {
      "cell_type": "code",
      "source": [
        "model = PAAModel()\n",
        "\n",
        "# Load the saved state dict\n",
        "model.load_state_dict(torch.load('paamodel.pth'))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:38.044438Z",
          "iopub.execute_input": "2025-01-02T09:15:38.044677Z",
          "iopub.status.idle": "2025-01-02T09:15:43.200276Z",
          "shell.execute_reply.started": "2025-01-02T09:15:38.044656Z",
          "shell.execute_reply": "2025-01-02T09:15:43.199391Z"
        },
        "id": "oEmYIB8npjwW",
        "outputId": "471fc651-4e5f-431b-c4bb-b92f8bd72391",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-139-576f8403c810>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load('paamodel.pth'))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 139
        }
      ],
      "execution_count": 139
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval = df[9999:10000].reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:31.90417Z",
          "iopub.execute_input": "2025-01-02T09:13:31.904508Z",
          "iopub.status.idle": "2025-01-02T09:13:31.909558Z",
          "shell.execute_reply.started": "2025-01-02T09:13:31.904481Z",
          "shell.execute_reply": "2025-01-02T09:13:31.908551Z"
        },
        "id": "JmOUdxJopjwX"
      },
      "outputs": [],
      "execution_count": 140
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:33.152773Z",
          "iopub.execute_input": "2025-01-02T09:13:33.153078Z",
          "iopub.status.idle": "2025-01-02T09:13:33.167906Z",
          "shell.execute_reply.started": "2025-01-02T09:13:33.153052Z",
          "shell.execute_reply": "2025-01-02T09:13:33.166951Z"
        },
        "id": "q1hnqISwpjwX",
        "outputId": "965a69fa-182e-4044-cd1e-96970b8609ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             Problem  \\\n",
              "0  Amicable numbers are pairs of numbers for whic...   \n",
              "\n",
              "                                        Student_code  \\\n",
              "0  def named_are_amicable():                for n...   \n",
              "\n",
              "                                       Expected_code            Q01  \\\n",
              "0  def sum_of_divisors(number):          divisors...  2 : Sometimes   \n",
              "\n",
              "             Q02            Q03        Q04               Q05            Q06  \\\n",
              "0  2 : Sometimes  2 : Sometimes  3 : Often  1 : Almost Never  2 : Sometimes   \n",
              "\n",
              "             Q07  ...            Q11            Q12               Q13  \\\n",
              "0  2 : Sometimes  ...  2 : Sometimes  2 : Sometimes  1 : Almost Never   \n",
              "\n",
              "             Q14        Q15            Q16  \\\n",
              "0  2 : Sometimes  3 : Often  2 : Sometimes   \n",
              "\n",
              "                                metacognitive_vector  \\\n",
              "0  ['2 ', '2 ', '2 ', '3 ', '1 ', '2 ', '2 ', '2 ...   \n",
              "\n",
              "                              metacognitive_feedback  \\\n",
              "0  Your implementation has a few significant issu...   \n",
              "\n",
              "                            combined_problem_student  \\\n",
              "0  Amicable numbers are pairs of numbers for whic...   \n",
              "\n",
              "                           combined_problem_expected  \n",
              "0  Amicable numbers are pairs of numbers for whic...  \n",
              "\n",
              "[1 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44968b7d-8e8b-4e05-b2ed-ff19878ab414\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Problem</th>\n",
              "      <th>Student_code</th>\n",
              "      <th>Expected_code</th>\n",
              "      <th>Q01</th>\n",
              "      <th>Q02</th>\n",
              "      <th>Q03</th>\n",
              "      <th>Q04</th>\n",
              "      <th>Q05</th>\n",
              "      <th>Q06</th>\n",
              "      <th>Q07</th>\n",
              "      <th>...</th>\n",
              "      <th>Q11</th>\n",
              "      <th>Q12</th>\n",
              "      <th>Q13</th>\n",
              "      <th>Q14</th>\n",
              "      <th>Q15</th>\n",
              "      <th>Q16</th>\n",
              "      <th>metacognitive_vector</th>\n",
              "      <th>metacognitive_feedback</th>\n",
              "      <th>combined_problem_student</th>\n",
              "      <th>combined_problem_expected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amicable numbers are pairs of numbers for whic...</td>\n",
              "      <td>def named_are_amicable():                for n...</td>\n",
              "      <td>def sum_of_divisors(number):          divisors...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>...</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>1 : Almost Never</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>3 : Often</td>\n",
              "      <td>2 : Sometimes</td>\n",
              "      <td>['2 ', '2 ', '2 ', '3 ', '1 ', '2 ', '2 ', '2 ...</td>\n",
              "      <td>Your implementation has a few significant issu...</td>\n",
              "      <td>Amicable numbers are pairs of numbers for whic...</td>\n",
              "      <td>Amicable numbers are pairs of numbers for whic...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 23 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44968b7d-8e8b-4e05-b2ed-ff19878ab414')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-44968b7d-8e8b-4e05-b2ed-ff19878ab414 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-44968b7d-8e8b-4e05-b2ed-ff19878ab414');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "  <div id=\"id_fe1d2ab1-e530-4ce2-b5b2-5e2a328fc8f1\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_eval')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_fe1d2ab1-e530-4ce2-b5b2-5e2a328fc8f1 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_eval');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_eval"
            }
          },
          "metadata": {},
          "execution_count": 141
        }
      ],
      "execution_count": 141
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset = CustomDataset(df_eval, t5_tokenizer,gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:36.045686Z",
          "iopub.execute_input": "2025-01-02T09:13:36.046004Z",
          "iopub.status.idle": "2025-01-02T09:13:36.049807Z",
          "shell.execute_reply.started": "2025-01-02T09:13:36.045976Z",
          "shell.execute_reply": "2025-01-02T09:13:36.048902Z"
        },
        "id": "t0Aar6eGpjwX"
      },
      "outputs": [],
      "execution_count": 142
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def inference(model,gpt2_tokenizer, t5_tokenizer, eval_dataset, device):\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    metacognitive_vector_ids, problem_student_code_ids, problem_expected_code_ids,student_code_ids, target_ids = eval_dataset[0]\n",
        "\n",
        "    metacognitive_tensor = metacognitive_vector_ids.unsqueeze(0).to(device)\n",
        "    problem_student_code_tensor = problem_student_code_ids.unsqueeze(0).to(device)\n",
        "    problem_expected_code_tensor = problem_expected_code_ids.unsqueeze(0).to(device)\n",
        "    target_tensor = target_ids.unsqueeze(0).to(device)\n",
        "\n",
        "    student_attention_mask = (problem_student_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n",
        "    expected_attention_mask = (problem_expected_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        logits = model(\n",
        "            metacognitive_vector_ids=metacognitive_tensor,\n",
        "            problem_student_code_ids=problem_student_code_tensor,\n",
        "            problem_expected_code_ids=problem_expected_code_tensor,\n",
        "            expected_attention_mask=expected_attention_mask,\n",
        "            student_attention_mask=student_attention_mask\n",
        "        )\n",
        "\n",
        "        predictions = logits.argmax(dim=-1).squeeze().tolist()\n",
        "        filtered_tokens = [token for token in predictions if token != 0]\n",
        "        #decoded_text = t5_tokenizer.decode(filtered_tokens, skip_special_tokens=False)\n",
        "        decoded_text = t5_tokenizer.decode(predictions, skip_special_tokens=True)\n",
        "\n",
        "\n",
        "        return filtered_tokens, decoded_text\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:25.839368Z",
          "iopub.execute_input": "2025-01-02T09:42:25.839702Z",
          "iopub.status.idle": "2025-01-02T09:42:25.84611Z",
          "shell.execute_reply.started": "2025-01-02T09:42:25.839676Z",
          "shell.execute_reply": "2025-01-02T09:42:25.845101Z"
        },
        "id": "VAwPV5uWpjwX"
      },
      "outputs": [],
      "execution_count": 143
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:26.462145Z",
          "iopub.execute_input": "2025-01-02T09:42:26.462503Z",
          "iopub.status.idle": "2025-01-02T09:42:26.555247Z",
          "shell.execute_reply.started": "2025-01-02T09:42:26.462473Z",
          "shell.execute_reply": "2025-01-02T09:42:26.554554Z"
        },
        "id": "q_7PtTCMpjwX"
      },
      "outputs": [],
      "execution_count": 144
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Predicted Tokens:\", predictions)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:26.833831Z",
          "iopub.execute_input": "2025-01-02T09:42:26.834114Z",
          "iopub.status.idle": "2025-01-02T09:42:26.838824Z",
          "shell.execute_reply.started": "2025-01-02T09:42:26.834092Z",
          "shell.execute_reply": "2025-01-02T09:42:26.837971Z"
        },
        "id": "_-Hk8vDepjwX",
        "outputId": "678796ae-2adc-47ae-e97d-cd29e9fdd8c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Tokens: [26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504, 26504]\n"
          ]
        }
      ],
      "execution_count": 145
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded Text:\", decoded_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:42:27.089445Z",
          "iopub.execute_input": "2025-01-02T09:42:27.089745Z",
          "iopub.status.idle": "2025-01-02T09:42:27.094494Z",
          "shell.execute_reply.started": "2025-01-02T09:42:27.089722Z",
          "shell.execute_reply": "2025-01-02T09:42:27.093656Z"
        },
        "id": "DjirDKuDpjwY",
        "outputId": "9efcca5c-01a6-4690-cf28-2e699a1e899c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded Text: buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle buckle\n"
          ]
        }
      ],
      "execution_count": 146
    },
    {
      "cell_type": "code",
      "source": [
        "def load_checkpoint(checkpoint_path, model, optimizer=None):\n",
        "    checkpoint = torch.load(checkpoint_path)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    if optimizer:\n",
        "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    epoch = checkpoint['epoch']\n",
        "    loss = checkpoint['loss']\n",
        "    print(f\"Checkpoint loaded: Epoch {epoch}, Loss: {loss:.4f}\")\n",
        "    return model, optimizer, epoch, loss"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:56.480065Z",
          "iopub.execute_input": "2025-01-02T09:14:56.480394Z",
          "iopub.status.idle": "2025-01-02T09:14:56.484822Z",
          "shell.execute_reply.started": "2025-01-02T09:14:56.480367Z",
          "shell.execute_reply": "2025-01-02T09:14:56.483857Z"
        },
        "id": "2PhZ1IxTpjwY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/model_epoch_20.pth\"\n",
        "model, optimizer, start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:20.031344Z",
          "iopub.execute_input": "2025-01-02T09:14:20.031652Z",
          "iopub.status.idle": "2025-01-02T09:14:21.532472Z",
          "shell.execute_reply.started": "2025-01-02T09:14:20.031628Z",
          "shell.execute_reply": "2025-01-02T09:14:21.531698Z"
        },
        "id": "zFdcCTywpjwY",
        "outputId": "a0a5aa31-1a6a-4ca3-9c51-4e6870572c15"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-78-61464e86af1d>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path)\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Checkpoint loaded: Epoch 20, Loss: 4.2463\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/model_epoch_10.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Use GPU if available: 'cuda'\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:13:55.653477Z",
          "iopub.execute_input": "2025-01-02T09:13:55.653715Z",
          "iopub.status.idle": "2025-01-02T09:13:55.676084Z",
          "shell.execute_reply.started": "2025-01-02T09:13:55.653693Z",
          "shell.execute_reply": "2025-01-02T09:13:55.674979Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "Hf1JYLuwpjwY",
        "outputId": "15a2372c-85eb-4e76-ebd0-16b7a5b3b4c1"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "<ipython-input-82-a62cfdc3dc89>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Use GPU if available: 'cuda'\n",
          "output_type": "stream"
        },
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-a62cfdc3dc89>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./checkpoints/model_epoch_10.pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Use GPU if available: 'cuda'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_state_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m   1063\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'encoding'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1064\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1065\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1066\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1067\u001b[0m             \u001b[0;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    447\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    448\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 449\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './checkpoints/model_epoch_10.pth'"
          ],
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './checkpoints/model_epoch_10.pth'",
          "output_type": "error"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:14:26.196139Z",
          "iopub.execute_input": "2025-01-02T09:14:26.19651Z",
          "iopub.status.idle": "2025-01-02T09:14:26.201901Z",
          "shell.execute_reply.started": "2025-01-02T09:14:26.196481Z",
          "shell.execute_reply": "2025-01-02T09:14:26.200956Z"
        },
        "id": "7iggnxZfpjwY",
        "outputId": "a937b8cc-ce3e-405a-b3b9-c094a5ec5943"
      },
      "outputs": [
        {
          "execution_count": 86,
          "output_type": "execute_result",
          "data": {
            "text/plain": "16803"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "df_eval1 = df[449:450].reset_index(drop=True)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:21.71876Z",
          "iopub.execute_input": "2025-01-02T09:15:21.719058Z",
          "iopub.status.idle": "2025-01-02T09:15:21.723418Z",
          "shell.execute_reply.started": "2025-01-02T09:15:21.719035Z",
          "shell.execute_reply": "2025-01-02T09:15:21.722544Z"
        },
        "id": "2qXsvK9ipjwY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset1 = CustomDataset(df_eval1, t5_tokenizer,gpt2_tokenizer)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:22.79416Z",
          "iopub.execute_input": "2025-01-02T09:15:22.794471Z",
          "iopub.status.idle": "2025-01-02T09:15:22.798035Z",
          "shell.execute_reply.started": "2025-01-02T09:15:22.794449Z",
          "shell.execute_reply": "2025-01-02T09:15:22.79709Z"
        },
        "id": "RTvWOxbRpjwZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset1, device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:44.516595Z",
          "iopub.execute_input": "2025-01-02T09:15:44.516895Z",
          "iopub.status.idle": "2025-01-02T09:15:44.999499Z",
          "shell.execute_reply.started": "2025-01-02T09:15:44.516872Z",
          "shell.execute_reply": "2025-01-02T09:15:44.998792Z"
        },
        "id": "mv1XSJ-fpjwZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decoded Text:\", decoded_text)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-02T09:15:47.030509Z",
          "iopub.execute_input": "2025-01-02T09:15:47.030805Z",
          "iopub.status.idle": "2025-01-02T09:15:47.035393Z",
          "shell.execute_reply.started": "2025-01-02T09:15:47.030783Z",
          "shell.execute_reply": "2025-01-02T09:15:47.034606Z"
        },
        "id": "Lkh7nc9upjwZ",
        "outputId": "9e822b69-4342-4783-baf1-a7677b7c9085"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Decoded Text: Your to  the good  understanding to are to are, are areas areas,.,.            the  the the    the,  the  the the . the   the     the the   the the  the, the  the,  the the the to the  the ,,.        the      the the the the the    the the the the the the  the   the the. the the the the the the    the  the. the. the the the  the the the  the the the the   the the your the your the. the the the  the the    the  your. the. your \n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "VGkJqgTupjwZ"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}