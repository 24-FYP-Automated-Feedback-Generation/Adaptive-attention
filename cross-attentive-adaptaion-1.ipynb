{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10048507,"sourceType":"datasetVersion","datasetId":6190931},{"sourceId":10242967,"sourceType":"datasetVersion","datasetId":6334477},{"sourceId":10316683,"sourceType":"datasetVersion","datasetId":6386966}],"dockerImageVersionId":30822,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:12.557209Z","iopub.execute_input":"2025-01-01T05:20:12.557448Z","iopub.status.idle":"2025-01-01T05:20:12.895964Z","shell.execute_reply.started":"2025-01-01T05:20:12.557426Z","shell.execute_reply":"2025-01-01T05:20:12.895039Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/metacognitive-feedback-for-algorithm-solving/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\n/kaggle/input/modified-dataset/modified_dataset.csv\n/kaggle/input/metacognitive-dataset/metacognitive-dataset.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"pip install transformers torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:15.161337Z","iopub.execute_input":"2025-01-01T05:20:15.161671Z","iopub.status.idle":"2025-01-01T05:20:19.785198Z","shell.execute_reply.started":"2025-01-01T05:20:15.161639Z","shell.execute_reply":"2025-01-01T05:20:19.784227Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\nRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom transformers import AutoModel, AutoTokenizer, GPT2Model,GPT2Tokenizer,GPT2LMHeadModel\nfrom transformers import AutoTokenizer, T5ForConditionalGeneration , T5Tokenizer , T5Model\nimport pandas as pd","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:19.786527Z","iopub.execute_input":"2025-01-01T05:20:19.786805Z","iopub.status.idle":"2025-01-01T05:20:24.901289Z","shell.execute_reply.started":"2025-01-01T05:20:19.786783Z","shell.execute_reply":"2025-01-01T05:20:24.900553Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:24.902603Z","iopub.execute_input":"2025-01-01T05:20:24.903003Z","iopub.status.idle":"2025-01-01T05:20:24.956303Z","shell.execute_reply.started":"2025-01-01T05:20:24.902968Z","shell.execute_reply":"2025-01-01T05:20:24.955329Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"device","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:24.957687Z","iopub.execute_input":"2025-01-01T05:20:24.957963Z","iopub.status.idle":"2025-01-01T05:20:24.974380Z","shell.execute_reply.started":"2025-01-01T05:20:24.957942Z","shell.execute_reply":"2025-01-01T05:20:24.973674Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"checkpoint = \"t5-base\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:24.975200Z","iopub.execute_input":"2025-01-01T05:20:24.975487Z","iopub.status.idle":"2025-01-01T05:20:24.988477Z","shell.execute_reply.started":"2025-01-01T05:20:24.975465Z","shell.execute_reply":"2025-01-01T05:20:24.987794Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"t5_tokenizer = AutoTokenizer.from_pretrained(checkpoint)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:24.989243Z","iopub.execute_input":"2025-01-01T05:20:24.989493Z","iopub.status.idle":"2025-01-01T05:20:28.958756Z","shell.execute_reply.started":"2025-01-01T05:20:24.989465Z","shell.execute_reply":"2025-01-01T05:20:28.957831Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7ce96b71ef4649ffa47a11fe90243542"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fee5656bc13a4b25898988a204d25bca"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"adc3e3a46ff34e8da491aeb93f2f9aa5"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"t5_tokenizer.vocab_size","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:28.961235Z","iopub.execute_input":"2025-01-01T05:20:28.961472Z","iopub.status.idle":"2025-01-01T05:20:28.967127Z","shell.execute_reply.started":"2025-01-01T05:20:28.961453Z","shell.execute_reply":"2025-01-01T05:20:28.966322Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"32100"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"#set the max length to model's default present max length\nt5_tokenizer.model_max_length = t5_tokenizer.model_max_length","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:28.970563Z","iopub.execute_input":"2025-01-01T05:20:28.970986Z","iopub.status.idle":"2025-01-01T05:20:28.983000Z","shell.execute_reply.started":"2025-01-01T05:20:28.970950Z","shell.execute_reply":"2025-01-01T05:20:28.981977Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"gpt2_tokenizer = GPT2Tokenizer.from_pretrained('gpt2')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:28.984071Z","iopub.execute_input":"2025-01-01T05:20:28.984436Z","iopub.status.idle":"2025-01-01T05:20:32.237433Z","shell.execute_reply.started":"2025-01-01T05:20:28.984405Z","shell.execute_reply":"2025-01-01T05:20:32.236578Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47df25461aee4df9ac6378d9ffa7dd69"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"817a5f48e3a14dd0abd0a25efa95308b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d9c85ec1714f42ea8db5c197cd3e142e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3270e1b22be348cb84edd876b12f564e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de1077c059dd4ee99ede148c354505c5"}},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"gpt2_tokenizer.pad_token = gpt2_tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:32.238216Z","iopub.execute_input":"2025-01-01T05:20:32.238474Z","iopub.status.idle":"2025-01-01T05:20:32.242015Z","shell.execute_reply.started":"2025-01-01T05:20:32.238454Z","shell.execute_reply":"2025-01-01T05:20:32.241182Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"file_path = \"/kaggle/input/metacognitive-feedback-for-algorithm-solving/final_dataset_with_annotated_metacognitive_feedback_gpt-4o-mini.csv\"\ndf = pd.read_csv(file_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:32.242918Z","iopub.execute_input":"2025-01-01T05:20:32.243191Z","iopub.status.idle":"2025-01-01T05:20:34.289893Z","shell.execute_reply.started":"2025-01-01T05:20:32.243159Z","shell.execute_reply":"2025-01-01T05:20:34.289194Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.290678Z","iopub.execute_input":"2025-01-01T05:20:34.290987Z","iopub.status.idle":"2025-01-01T05:20:34.297190Z","shell.execute_reply.started":"2025-01-01T05:20:34.290956Z","shell.execute_reply":"2025-01-01T05:20:34.296179Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"Index(['Question 1', 'Response 1', 'Right answer 1', 'Q01', 'Q02', 'Q03',\n       'Q04', 'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13',\n       'Q14', 'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback'],\n      dtype='object')"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"df.rename(\n    columns={\n        'Question 1': 'Problem',\n        'Response 1': 'Student_code',\n        'Right answer 1': 'Expected_code'\n    },\n    inplace=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.298201Z","iopub.execute_input":"2025-01-01T05:20:34.298472Z","iopub.status.idle":"2025-01-01T05:20:34.315700Z","shell.execute_reply.started":"2025-01-01T05:20:34.298452Z","shell.execute_reply":"2025-01-01T05:20:34.314863Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.316460Z","iopub.execute_input":"2025-01-01T05:20:34.316709Z","iopub.status.idle":"2025-01-01T05:20:34.349550Z","shell.execute_reply.started":"2025-01-01T05:20:34.316688Z","shell.execute_reply":"2025-01-01T05:20:34.348838Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"                                             Problem  \\\n0  Develop a Python program that takes the name o...   \n1  Develop a Python program that takes the name o...   \n2  Develop a Python program that takes the name o...   \n\n                                        Student_code  \\\n0  file_input = input()      file_open = open(fil...   \n1  file_input = input()      file_open = open(fil...   \n2  file_input = input()      file_open = open(fil...   \n\n                                       Expected_code        Q01  \\\n0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n\n             Q02               Q03        Q04            Q05            Q06  \\\n0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n\n                Q07  ...        Q09        Q10            Q11            Q12  \\\n0  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n1  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n2  1 : Almost Never  ...  3 : Often  3 : Often  2 : Sometimes  2 : Sometimes   \n\n             Q13        Q14        Q15               Q16  \\\n0  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n1  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n2  2 : Sometimes  3 : Often  3 : Often  1 : Almost Never   \n\n                                metacognitive_vector  \\\n0  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n1  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n2  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n\n                              metacognitive_feedback  \n0  Your initial code serves as a starting point, ...  \n1  Your code exhibits a solid attempt at reading ...  \n2  It looks like you're in a good place with some...  \n\n[3 rows x 21 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Problem</th>\n      <th>Student_code</th>\n      <th>Expected_code</th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>...</th>\n      <th>Q09</th>\n      <th>Q10</th>\n      <th>Q11</th>\n      <th>Q12</th>\n      <th>Q13</th>\n      <th>Q14</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial code serves as a starting point, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your code exhibits a solid attempt at reading ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>It looks like you're in a good place with some...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 21 columns</p>\n</div>"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"df['combined_problem_student'] = df['Problem'] + \" \" + df['Student_code']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.350387Z","iopub.execute_input":"2025-01-01T05:20:34.350609Z","iopub.status.idle":"2025-01-01T05:20:34.505118Z","shell.execute_reply.started":"2025-01-01T05:20:34.350591Z","shell.execute_reply":"2025-01-01T05:20:34.504415Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"df['combined_problem_expected'] = df['Problem'] + \" \" + df['Expected_code']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.505772Z","iopub.execute_input":"2025-01-01T05:20:34.505988Z","iopub.status.idle":"2025-01-01T05:20:34.582857Z","shell.execute_reply.started":"2025-01-01T05:20:34.505970Z","shell.execute_reply":"2025-01-01T05:20:34.581871Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.584881Z","iopub.execute_input":"2025-01-01T05:20:34.585129Z","iopub.status.idle":"2025-01-01T05:20:34.598548Z","shell.execute_reply.started":"2025-01-01T05:20:34.585093Z","shell.execute_reply":"2025-01-01T05:20:34.597888Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Index(['Problem', 'Student_code', 'Expected_code', 'Q01', 'Q02', 'Q03', 'Q04',\n       'Q05', 'Q06', 'Q07', 'Q08', 'Q09', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14',\n       'Q15', 'Q16', 'metacognitive_vector', 'metacognitive_feedback',\n       'combined_problem_student', 'combined_problem_expected'],\n      dtype='object')"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"df.dropna(subset=['Problem', 'metacognitive_feedback', 'combined_problem_student'], inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.599611Z","iopub.execute_input":"2025-01-01T05:20:34.599870Z","iopub.status.idle":"2025-01-01T05:20:34.627352Z","shell.execute_reply.started":"2025-01-01T05:20:34.599849Z","shell.execute_reply":"2025-01-01T05:20:34.626558Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"df.reset_index(drop=True, inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.628247Z","iopub.execute_input":"2025-01-01T05:20:34.628554Z","iopub.status.idle":"2025-01-01T05:20:34.632906Z","shell.execute_reply.started":"2025-01-01T05:20:34.628521Z","shell.execute_reply":"2025-01-01T05:20:34.631971Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.633789Z","iopub.execute_input":"2025-01-01T05:20:34.634020Z","iopub.status.idle":"2025-01-01T05:20:34.670548Z","shell.execute_reply.started":"2025-01-01T05:20:34.633999Z","shell.execute_reply":"2025-01-01T05:20:34.669610Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"Problem                      0\nStudent_code                 0\nExpected_code                0\nQ01                          0\nQ02                          0\nQ03                          0\nQ04                          0\nQ05                          0\nQ06                          0\nQ07                          0\nQ08                          0\nQ09                          0\nQ10                          0\nQ11                          0\nQ12                          0\nQ13                          0\nQ14                          0\nQ15                          0\nQ16                          0\nmetacognitive_vector         0\nmetacognitive_feedback       0\ncombined_problem_student     0\ncombined_problem_expected    0\ndtype: int64"},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"df['metacognitive_feedback'][100]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.671442Z","iopub.execute_input":"2025-01-01T05:20:34.671747Z","iopub.status.idle":"2025-01-01T05:20:34.685028Z","shell.execute_reply.started":"2025-01-01T05:20:34.671723Z","shell.execute_reply":"2025-01-01T05:20:34.684316Z"}},"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"\"Your current implementation shows a good effort in structuring your code with functions, but there are some areas where further refinement is necessary to meet the problem requirements. First, consider how you're capturing the relationships between birth years and heights. While you are correctly gathering names, birthdates, and heights into a dictionary, think about how you can aggregate heights by decade instead of year. This will streamline the calculation of average heights. It’s crucial to loop through your input list once to comprehend and process the data before beginning any calculations for averaging—possibly consolidating this logic in your `calculate_average_height` function. Also, ensure that you are converting heights to the correct data type before performing any arithmetic operations. Additionally, take a closer look at how you’re determining the range of decades; right now it seems like you may be focusing on unique years instead of decades. Consider creating a systematic structure that easily categorizes each height into its corresponding decade bucket. Furthermore, as you develop your code, remember to monitor your program's flow and adjust accordingly—this is especially important when it comes to function calls and data structure manipulations. Establishing a plan before implementation can significantly enhance your problem-solving process and avoid errors stemming from assumptions. Overall, maintain momentum and continue refining your approach by checking each component against the problem's requirements, thus ensuring coherence and completeness in your solution.\""},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"df.head(5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.685894Z","iopub.execute_input":"2025-01-01T05:20:34.686209Z","iopub.status.idle":"2025-01-01T05:20:34.713227Z","shell.execute_reply.started":"2025-01-01T05:20:34.686179Z","shell.execute_reply":"2025-01-01T05:20:34.712317Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"                                             Problem  \\\n0  Develop a Python program that takes the name o...   \n1  Develop a Python program that takes the name o...   \n2  Develop a Python program that takes the name o...   \n3  Develop a Python program that takes the name o...   \n4  Develop a Python program that takes the name o...   \n\n                                        Student_code  \\\n0  file_input = input()      file_open = open(fil...   \n1  file_input = input()      file_open = open(fil...   \n2  file_input = input()      file_open = open(fil...   \n3  file_input = input()      file_open = open(fil...   \n4  file_input = input()      file_open = open(fil...   \n\n                                       Expected_code        Q01  \\\n0  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n1  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n2  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n3  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n4  def substitute_vowels(chunk, vowel_substitutes...  3 : Often   \n\n             Q02               Q03        Q04            Q05            Q06  \\\n0  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n1  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n2  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n3  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n4  2 : Sometimes  1 : Almost Never  3 : Often  2 : Sometimes  2 : Sometimes   \n\n                Q07  ...            Q11            Q12            Q13  \\\n0  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n1  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n2  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n3  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n4  1 : Almost Never  ...  2 : Sometimes  2 : Sometimes  2 : Sometimes   \n\n         Q14        Q15               Q16  \\\n0  3 : Often  3 : Often  1 : Almost Never   \n1  3 : Often  3 : Often  1 : Almost Never   \n2  3 : Often  3 : Often  1 : Almost Never   \n3  3 : Often  3 : Often  1 : Almost Never   \n4  3 : Often  3 : Often  1 : Almost Never   \n\n                                metacognitive_vector  \\\n0  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n1  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n2  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n3  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n4  ['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...   \n\n                              metacognitive_feedback  \\\n0  Your initial code serves as a starting point, ...   \n1  Your code exhibits a solid attempt at reading ...   \n2  It looks like you're in a good place with some...   \n3  Your approach to reading the file and splittin...   \n4  Your initial approach to the problem is a good...   \n\n                            combined_problem_student  \\\n0  Develop a Python program that takes the name o...   \n1  Develop a Python program that takes the name o...   \n2  Develop a Python program that takes the name o...   \n3  Develop a Python program that takes the name o...   \n4  Develop a Python program that takes the name o...   \n\n                           combined_problem_expected  \n0  Develop a Python program that takes the name o...  \n1  Develop a Python program that takes the name o...  \n2  Develop a Python program that takes the name o...  \n3  Develop a Python program that takes the name o...  \n4  Develop a Python program that takes the name o...  \n\n[5 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Problem</th>\n      <th>Student_code</th>\n      <th>Expected_code</th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>...</th>\n      <th>Q11</th>\n      <th>Q12</th>\n      <th>Q13</th>\n      <th>Q14</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n      <th>combined_problem_student</th>\n      <th>combined_problem_expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial code serves as a starting point, ...</td>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>Develop a Python program that takes the name o...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your code exhibits a solid attempt at reading ...</td>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>Develop a Python program that takes the name o...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>It looks like you're in a good place with some...</td>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>Develop a Python program that takes the name o...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your approach to reading the file and splittin...</td>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>Develop a Python program that takes the name o...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>file_input = input()      file_open = open(fil...</td>\n      <td>def substitute_vowels(chunk, vowel_substitutes...</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>['3 ', '2 ', '1 ', '3 ', '2 ', '2 ', '1 ', '3 ...</td>\n      <td>Your initial approach to the problem is a good...</td>\n      <td>Develop a Python program that takes the name o...</td>\n      <td>Develop a Python program that takes the name o...</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"from torch.utils.data import Dataset\nimport ast\nclass CustomDataset(Dataset):\n    def __init__(self, dataset, t5_tokenizer,gpt2_tokenizer, max_length=512):\n        self.t5_tokenizer = t5_tokenizer\n        self.gpt2_tokenizer = gpt2_tokenizer\n        self.data = dataset\n        self.max_length = max_length\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        metacognitive_vector = self.data['metacognitive_vector'][idx]\n        problem_student_code = self.data['combined_problem_student'][idx]\n        problem_expected_code = self.data['combined_problem_expected'][idx]\n        student_code = self.data['Student_code'][idx]\n        target = self.data['metacognitive_feedback'][idx]\n\n        metacognitive_vector_float = [\n        float(item.strip()) for item in ast.literal_eval(metacognitive_vector)]\n        metacognition_vector_ids = torch.tensor(metacognitive_vector_float, dtype=torch.float)\n        \n        problem_student_code_ids = torch.tensor(\n            self.t5_tokenizer.encode(problem_student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n        )\n        problem_expected_code_ids = torch.tensor(\n            self.t5_tokenizer.encode(problem_expected_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n        )\n        \n        student_code_ids = torch.tensor(\n            self.t5_tokenizer.encode(student_code, max_length=self.max_length, truncation=True, padding=\"max_length\")\n        )\n        target_ids = torch.tensor(\n            self.t5_tokenizer.encode(target, max_length=self.max_length, truncation=True, padding=\"max_length\")\n        )\n\n        return metacognition_vector_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:34.714184Z","iopub.execute_input":"2025-01-01T05:20:34.714499Z","iopub.status.idle":"2025-01-01T05:20:34.721742Z","shell.execute_reply.started":"2025-01-01T05:20:34.714469Z","shell.execute_reply":"2025-01-01T05:20:34.720863Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"dataset = CustomDataset(df, t5_tokenizer, gpt2_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:35.640473Z","iopub.execute_input":"2025-01-01T05:20:35.640809Z","iopub.status.idle":"2025-01-01T05:20:35.645008Z","shell.execute_reply.started":"2025-01-01T05:20:35.640781Z","shell.execute_reply":"2025-01-01T05:20:35.644231Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"len(dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:35.965378Z","iopub.execute_input":"2025-01-01T05:20:35.965674Z","iopub.status.idle":"2025-01-01T05:20:35.970760Z","shell.execute_reply.started":"2025-01-01T05:20:35.965645Z","shell.execute_reply":"2025-01-01T05:20:35.970013Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"16803"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"metacognition_vector_ids, problem_student_code_ids, problem_expected_code_ids, student_code_ids, target_ids = dataset[100]\nprint(f\"Metacognition vector IDs: {metacognition_vector_ids}\")\nprint(f\"Expected feedback IDs: {problem_student_code_ids.shape}\")\nprint(f\"Expected encoded feedback IDs: {problem_expected_code_ids.shape}\")\nprint(f\"Student Answer IDs: {student_code_ids}\")\nprint(f\"Target IDs: {target_ids}\")\nprint(\"\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:36.331427Z","iopub.execute_input":"2025-01-01T05:20:36.331813Z","iopub.status.idle":"2025-01-01T05:20:36.433314Z","shell.execute_reply.started":"2025-01-01T05:20:36.331779Z","shell.execute_reply":"2025-01-01T05:20:36.432359Z"}},"outputs":[{"name":"stdout","text":"Metacognition vector IDs: tensor([2., 3., 1., 3., 3., 2., 2., 2., 3., 3., 3., 3., 3., 3., 3., 2.])\nExpected feedback IDs: torch.Size([512])\nExpected encoded feedback IDs: torch.Size([512])\nStudent Answer IDs: tensor([ 3785,   834, 11966,  4350,  2423,    77,  2562,  9960,  1713,   188,\n         2176,    15,     6,  2122, 31911,  2294,  2394,     6,  2938, 27436,\n         1713,   279,    32,   115,     6,  4928, 20223, 13523,  4433,     6,\n        27640,     5,   357,  1713, 18610,   760,   630,     6,  2884, 31497,\n         2294,  3072,     6,  2938, 19419,  1713,   308,     9,  6961,     6,\n         1714,    87,  4305, 13523,  3301,     6,  2606, 16029,  1713,   427,\n          162,     6,  2517,    87,  5176, 13523,  2079,     6,  2517, 12100,\n           20,    89,   608,   834, 11966,   599,    77,  2562,   834, 11966,\n         4350,    61,    10,    28,   539,   599,    77,  2562,   834, 11966,\n         4350,   976,    52,  8512,    38,  1042,    10, 10223,  2423, 11966,\n            5,  5236,  6972,  9960,  3785,   834,  3350,  2423,  6306,   908,\n           21,   331,    16, 10223,    10,  3785,   834,  3350,     5,  3096,\n          989,   599,  6757,     5,     7, 14192,  9960,     5,     7,  5900,\n           17,   599,  1686,  8512,    61,  1205,  3785,   834,  3350,    20,\n           89, 11837,   834, 28951,   834,    88,  2632,   599,  1201,  4347,\n         1201,  7318,    10,  1903,  3785,   834,  3350,  2423,  5236,   834,\n        11966,   599,    77,  2562,   834, 11966,  4350,    61,   331,   834,\n         4370,  2423,     2,   215,   834,  3350,  2423,  6306,   908,    21,\n            3,    23,    16,   620,   599,    40,    35,   599,    77,  2562,\n          834,  3350,    61,    61,    10,   331,   834,  4370,  6306,    77,\n         2562,   834,  3350,  6306,    23,   908,  6306,   536,  4275,     7,\n         5900,    17,   599,   121,    87,  8512,  6306,   357,   908,   908,\n         2423,    77,  2562,   834,  3350,  6306,    23,   908,  6306,   357,\n          908,  2281,   599,  6757,   834,  4370,    61,    20,    89,  3519,\n          834,  1201,   599,  4370,    61,    10,  3519,   834,  1201,  2423,\n          567,   782,    21,   843,    16,     3,  4370,    10,     3,    99,\n         3519,   834,  1201,  2423,  2423,   567,   782,    10,  3519,   834,\n         1201,  2423,  4397,     3,    15,    40,    99,  3519,   834,  1201,\n         3155,  4397,    10,  3519,   834,  1201,  2423,  4397,  1205,  3519,\n          834,  1201,    20,    89,  9858,   834,  1201,   599,  4370,    61,\n           10,  9858,   834,  1201,  2423,   567,   782,    21,   843,    16,\n            3,  4370,    10,     3,    99,  9858,   834,  1201,  2423,  2423,\n          567,   782,    10,  9858,   834,  1201,  2423,  4397,     3,    15,\n           40,    99,  9858,   834,  1201,     1,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\nTarget IDs: tensor([  696,   750,  4432,  1267,     3,     9,   207,  1941,    16, 21055,\n         1725,    39,  1081,    28,  3621,     6,    68,   132,    33,   128,\n          844,   213,   856, 15489,   297,    19,  1316,    12,   942,     8,\n          682,  1502,     5,  1485,     6,  1099,   149,    25,    31,    60,\n            3, 18147,     8,  3079,   344,  3879,   203,    11,  3902,     7,\n            5,   818,    25,    33,  6549,  7241,  3056,     6,  3879,  5522,\n            7,     6,    11,  3902,     7,   139,     3,     9, 24297,     6,\n          317,    81,   149,    25,    54, 12955,  3902,     7,    57,  5112,\n         1446,    13,   215,     5,   100,    56, 24104,     8, 18643,    13,\n         1348,  3902,     7,     5,    94,    22,     7,  4462,    12,  6494,\n          190,    39,  3785,   570,   728,    12, 21494,    11,   433,     8,\n          331,   274,  1849,   136, 19868,    21,     3,     9, 23980,   318,\n         2748,     7, 15596, 13250,  1014,    48,  9769,    16,    39,     3,\n            2, 10379, 14270,   834, 28951,   834,    88,  2632,     2,  1681,\n            5,  1203,     6,   766,    24,    25,    33,     3, 21049,  3902,\n            7,    12,     8,  2024,   331,   686,   274,  5505,   136,     3,\n            9, 30922,    51,  7578,  2673,     5,  5433,     6,   240,     3,\n            9,  4645,   320,    44,   149,    25,    22,    60,     3, 11682,\n            8,   620,    13,  4160,   117,   269,   230,    34,  1330,   114,\n           25,   164,    36,     3,  7388,    30,   775,   203,  1446,    13,\n         4160,     5,  9151,  1577,     3,     9, 20036,  1809,    24,  1153,\n         9624, 11498,   776,     7,   284,  3902,   139,   165,     3,  9921,\n         5112, 11325,     5,  7053,     6,    38,    25,  1344,    39,  1081,\n            6,  1423,    12,  3393,    39,   478,    31,     7,  2537,    11,\n         6142, 14031,   318,  8048,    19,   902,   359,   116,    34,   639,\n           12,  1681,  3088,    11,   331,  1809, 18175,     7,     5, 26550,\n           53,     3,     9,   515,   274,  4432,    54,  4019,  3391,    39,\n          682,    18,  6065,    53,   433,    11,  1792,  6854,  6269,    51,\n           53,    45, 20298,     5,  9126,     6,  1961, 15290,    11,   916,\n         6273,    77,    53,    39,  1295,    57,  6450,   284,  3876,   581,\n            8,   682,    31,     7,  1502,     6,  2932,     3,  5833,   576,\n          760,  1433,    11,   743,   655,    16,    39,  1127,     5,     1,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n            0,     0])\n\n\n","output_type":"stream"}],"execution_count":27},{"cell_type":"code","source":"gpt2_tokenizer.pad_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:38.781507Z","iopub.execute_input":"2025-01-01T05:20:38.781812Z","iopub.status.idle":"2025-01-01T05:20:38.787070Z","shell.execute_reply.started":"2025-01-01T05:20:38.781790Z","shell.execute_reply":"2025-01-01T05:20:38.786030Z"}},"outputs":[{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"'<|endoftext|>'"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"gpt2_pad_token_id = gpt2_tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:39.036709Z","iopub.execute_input":"2025-01-01T05:20:39.037024Z","iopub.status.idle":"2025-01-01T05:20:39.040935Z","shell.execute_reply.started":"2025-01-01T05:20:39.037000Z","shell.execute_reply":"2025-01-01T05:20:39.039920Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"gpt2_pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:39.423313Z","iopub.execute_input":"2025-01-01T05:20:39.423605Z","iopub.status.idle":"2025-01-01T05:20:39.428445Z","shell.execute_reply.started":"2025-01-01T05:20:39.423584Z","shell.execute_reply":"2025-01-01T05:20:39.427564Z"}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"50256"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"t5_tokenizer.pad_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:40.209791Z","iopub.execute_input":"2025-01-01T05:20:40.210252Z","iopub.status.idle":"2025-01-01T05:20:40.215214Z","shell.execute_reply.started":"2025-01-01T05:20:40.210215Z","shell.execute_reply":"2025-01-01T05:20:40.214482Z"}},"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'<pad>'"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"t5_pad_token_id = t5_tokenizer.pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:40.547986Z","iopub.execute_input":"2025-01-01T05:20:40.548308Z","iopub.status.idle":"2025-01-01T05:20:40.552221Z","shell.execute_reply.started":"2025-01-01T05:20:40.548283Z","shell.execute_reply":"2025-01-01T05:20:40.551282Z"}},"outputs":[],"execution_count":32},{"cell_type":"code","source":"t5_pad_token_id","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:41.621711Z","iopub.execute_input":"2025-01-01T05:20:41.622052Z","iopub.status.idle":"2025-01-01T05:20:41.627065Z","shell.execute_reply.started":"2025-01-01T05:20:41.622024Z","shell.execute_reply":"2025-01-01T05:20:41.626358Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":33},{"cell_type":"markdown","source":"# Context Enocder","metadata":{}},{"cell_type":"code","source":"class ContextEncoder(nn.Module): \n    def __init__(self, t5_model_name='t5-base', output_dim=768): \n        super(ContextEncoder, self).__init__()\n        \n        self.t5_encoder = T5Model.from_pretrained(t5_model_name).encoder\n        self.fc = nn.Linear(self.t5_encoder.config.d_model, output_dim)\n    \n    def forward(self, problem_student_code_ids, attention_masks=None):        \n\n        encoder_outputs = self.t5_encoder(\n            input_ids=problem_student_code_ids,\n            attention_mask=attention_masks\n        )\n        context_hidden_states = encoder_outputs.last_hidden_state   \n        \n        context_rep = context_hidden_states.mean(dim=1)\n        \n       \n        context_rep = self.fc(context_rep)\n        final_rep = context_rep.unsqueeze(1)\n        \n        return final_rep","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:42.921066Z","iopub.execute_input":"2025-01-01T05:20:42.921487Z","iopub.status.idle":"2025-01-01T05:20:42.927373Z","shell.execute_reply.started":"2025-01-01T05:20:42.921454Z","shell.execute_reply":"2025-01-01T05:20:42.926207Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"context_encoder = ContextEncoder().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:44.145273Z","iopub.execute_input":"2025-01-01T05:20:44.145593Z","iopub.status.idle":"2025-01-01T05:20:49.123142Z","shell.execute_reply.started":"2025-01-01T05:20:44.145571Z","shell.execute_reply":"2025-01-01T05:20:49.122130Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f296185f3e56494c9dbbf36f92f1161f"}},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"context_encoder","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:49.124351Z","iopub.execute_input":"2025-01-01T05:20:49.124679Z","iopub.status.idle":"2025-01-01T05:20:49.131511Z","shell.execute_reply.started":"2025-01-01T05:20:49.124639Z","shell.execute_reply":"2025-01-01T05:20:49.130695Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"ContextEncoder(\n  (t5_encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (fc): Linear(in_features=768, out_features=768, bias=True)\n)"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"class MetacognitionLayer(nn.Module):\n    def __init__(self, metacognitive_dim=16, output_dim=768 , \n                prompt_text=\"Metacognitive feedback helps students reflect on their problem-solving strategies, identify gaps in their understanding, and refine their approach to coding challenges. By focusing on self-awareness and iterative improvement, students can enhance their learning process and achieve better outcomes in programming.\"):\n        super(MetacognitionLayer, self).__init__()\n        #16 to 768 mapping\n        self.metacognitive_fc = nn.Linear(metacognitive_dim, output_dim) \n        self.final_fc = nn.Linear(output_dim, output_dim)\n\n        self.tokenizer = T5Tokenizer.from_pretrained(\"t5-base\")\n        self.t5_pad_token_id = self.tokenizer.pad_token_id\n        self.encoder = T5Model.from_pretrained(\"t5-base\").encoder \n\n        self.prompt = prompt_text\n\n        for param in self.encoder.parameters():\n            param.requires_grad = False\n\n    def forward(self, metacognitive_vector):\n\n        input_prompt = self.tokenizer(\n        self.prompt, \n        return_tensors=\"pt\", \n        padding=True, \n        truncation=True, \n        max_length=512-16  \n        )\n        input_prompt = {key: value.to(metacognitive_vector.device) for key, value in input_prompt.items()}\n        # prompt_attention_mask = (input_prompt != self.t5_pad_token_id).long().to(device)\n        outputs = self.encoder(input_ids=input_prompt[\"input_ids\"], attention_mask=input_prompt[\"attention_mask\"])\n        prompt_embedding = outputs.last_hidden_state.mean(dim=1)\n        prompt_embedding = prompt_embedding.to(metacognitive_vector.device)        \n\n        metacognitive_rep = self.metacognitive_fc(metacognitive_vector)\n        final_rep = self.final_fc(metacognitive_rep)  \n        persona_rep = final_rep.unsqueeze(1)\n        #print(\"persona_rep\",persona_rep.shape)\n        final_persona = persona_rep + prompt_embedding\n        print\n\n        return final_persona","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:49.132967Z","iopub.execute_input":"2025-01-01T05:20:49.133224Z","iopub.status.idle":"2025-01-01T05:20:49.147327Z","shell.execute_reply.started":"2025-01-01T05:20:49.133191Z","shell.execute_reply":"2025-01-01T05:20:49.146580Z"}},"outputs":[],"execution_count":37},{"cell_type":"code","source":"metacognitive_emb = MetacognitionLayer().to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:49.148508Z","iopub.execute_input":"2025-01-01T05:20:49.148753Z","iopub.status.idle":"2025-01-01T05:20:50.852206Z","shell.execute_reply.started":"2025-01-01T05:20:49.148733Z","shell.execute_reply":"2025-01-01T05:20:50.851455Z"}},"outputs":[{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"metacognitive_emb","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:50.852886Z","iopub.execute_input":"2025-01-01T05:20:50.853143Z","iopub.status.idle":"2025-01-01T05:20:50.859587Z","shell.execute_reply.started":"2025-01-01T05:20:50.853113Z","shell.execute_reply":"2025-01-01T05:20:50.858707Z"}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"MetacognitionLayer(\n  (metacognitive_fc): Linear(in_features=16, out_features=768, bias=True)\n  (final_fc): Linear(in_features=768, out_features=768, bias=True)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"class PAALayer(nn.Module):\n    def __init__(self, hidden_dimension = 768 , tau=0.8,dropout_rate=0.1):\n        super(PAALayer, self).__init__()\n        self.hidden_dimenstion = hidden_dimension\n        self.tau = tau\n\n       \n        self.fc = nn.Linear(2 * hidden_dimension, hidden_dimension)  \n        self.sigmoid = nn.Sigmoid()\n        self.fc_out = nn.Linear(hidden_dimension, hidden_dimension)\n        self.dropout = nn.Dropout(p=dropout_rate)\n\n\n    def forward(self, hR , oP, oC):\n       \n        Mp_input  = torch.cat([hR,oP], dim=-1)        \n        Mp = self.fc(Mp_input)      \n        Wp = self.sigmoid(Mp)      \n     \n        Mpersona = Wp\n        Mcontext = 1 - Wp      \n       \n        oP_weighted = Mpersona * oP       \n        oC_weighted = Mcontext * oC\n       \n        HPAA = oP_weighted + oC_weighted \n       \n        output = self.fc_out(HPAA)\n       \n        return output","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:50.860410Z","iopub.execute_input":"2025-01-01T05:20:50.860628Z","iopub.status.idle":"2025-01-01T05:20:50.904414Z","shell.execute_reply.started":"2025-01-01T05:20:50.860602Z","shell.execute_reply":"2025-01-01T05:20:50.903521Z"}},"outputs":[],"execution_count":40},{"cell_type":"code","source":"paa = PAALayer()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:50.906196Z","iopub.execute_input":"2025-01-01T05:20:50.906588Z","iopub.status.idle":"2025-01-01T05:20:50.929327Z","shell.execute_reply.started":"2025-01-01T05:20:50.906556Z","shell.execute_reply":"2025-01-01T05:20:50.928385Z"}},"outputs":[],"execution_count":41},{"cell_type":"code","source":"paa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:50.930394Z","iopub.execute_input":"2025-01-01T05:20:50.930691Z","iopub.status.idle":"2025-01-01T05:20:50.935601Z","shell.execute_reply.started":"2025-01-01T05:20:50.930664Z","shell.execute_reply":"2025-01-01T05:20:50.934888Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"PAALayer(\n  (fc): Linear(in_features=1536, out_features=768, bias=True)\n  (sigmoid): Sigmoid()\n  (fc_out): Linear(in_features=768, out_features=768, bias=True)\n  (dropout): Dropout(p=0.1, inplace=False)\n)"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"class CustomTransformerBlock(nn.Module):\n    def __init__(self, hidden_size, tau , dropout_rate=0.1):\n        super(CustomTransformerBlock, self).__init__()\n\n        self.input_self_attention = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n        self.context_attn = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n        self.persona_attn = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)\n        #self.output_attn = nn.MultiheadAttention(hidden_size, num_head = 12, batch_first = True)\n\n        #self.output_self_attention = nn.MultiheadAttention(hidden_size, num_heads=12 , batch_first = True)\n\n        self.paa_layer = PAALayer(hidden_dimension=hidden_size, tau=tau)\n        \n        self.mlp = nn.Sequential(\n            nn.Linear(hidden_size, 2048),\n            nn.ReLU(),\n            nn.Dropout(p=0.1),\n            nn.Linear(2048, hidden_size),\n            nn.LayerNorm(hidden_size)\n        )\n        self.layer_norm2 = nn.LayerNorm(hidden_size)\n       \n    def forward(self, student_initial_state, encoded_persona, encoded_context, current_state):\n\n        hR, _ = self.input_self_attention(student_initial_state, student_initial_state, student_initial_state) #query\n        #print(\"encoded_persona\",encoded_persona.shape)\n        oP, _ = self.persona_attn(hR, encoded_persona, encoded_persona)\n        #print(\"attention persona\",oP.shape)\n        #print(\"hr\",hR.shape)\n        #print(\"encoded context\",encoded_context.shape)\n        oC, _ = self.context_attn(hR, encoded_context, encoded_context)   \n\n        \n        HPAA = self.paa_layer(hR, oP, oC)\n        \n        mlp_output = self.mlp(HPAA)\n        output = self.layer_norm2(mlp_output)\n      \n        return output\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:50.936377Z","iopub.execute_input":"2025-01-01T05:20:50.936699Z","iopub.status.idle":"2025-01-01T05:20:50.947467Z","shell.execute_reply.started":"2025-01-01T05:20:50.936669Z","shell.execute_reply":"2025-01-01T05:20:50.946735Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"custom_layer = CustomTransformerBlock(768,0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:52.211223Z","iopub.execute_input":"2025-01-01T05:20:52.211514Z","iopub.status.idle":"2025-01-01T05:20:52.322731Z","shell.execute_reply.started":"2025-01-01T05:20:52.211493Z","shell.execute_reply":"2025-01-01T05:20:52.321988Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"custom_layer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:52.515593Z","iopub.execute_input":"2025-01-01T05:20:52.515887Z","iopub.status.idle":"2025-01-01T05:20:52.521081Z","shell.execute_reply.started":"2025-01-01T05:20:52.515864Z","shell.execute_reply":"2025-01-01T05:20:52.520280Z"}},"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"CustomTransformerBlock(\n  (input_self_attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (context_attn): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (persona_attn): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (paa_layer): PAALayer(\n    (fc): Linear(in_features=1536, out_features=768, bias=True)\n    (sigmoid): Sigmoid()\n    (fc_out): Linear(in_features=768, out_features=768, bias=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (mlp): Sequential(\n    (0): Linear(in_features=768, out_features=2048, bias=True)\n    (1): ReLU()\n    (2): Dropout(p=0.1, inplace=False)\n    (3): Linear(in_features=2048, out_features=768, bias=True)\n    (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n  )\n  (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":45},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class PAAModel(nn.Module):\n    def __init__(self, hidden_size=768, vocab_size = 32100 ,tau=0.8, max_length=512, num_transformer_blocks=4):\n        super(PAAModel , self).__init__()\n        self.hidden_size = hidden_size\n        self.tau = tau\n        self.vocab_size = vocab_size\n        self.max_length = max_length\n        self.num_transformer_blocks = num_transformer_blocks\n\n        self.context_encoder = ContextEncoder()\n        \n        self.metacognitive_emb = MetacognitionLayer()\n        \n        for param in self.context_encoder.parameters():\n            param.requires_grad = False\n\n        for param in self.metacognitive_emb.parameters():\n            param.requires_grad = False\n\n        self.token_embedding = nn.Embedding(vocab_size, hidden_size)\n        self.position_embedding = nn.Embedding(max_length, hidden_size)\n        self.dropout = nn.Dropout(p=0.1) \n\n        self.self_attention = nn.MultiheadAttention(hidden_size, num_heads=12, batch_first=True)        \n        self.transformer_blocks = nn.ModuleList([CustomTransformerBlock(hidden_size, tau) for _ in range(num_transformer_blocks)])\n        self.final_fc = nn.Linear(hidden_size, vocab_size)\n        self.layer_norm = nn.LayerNorm(hidden_size)\n\n    def forward(self,  metacognitive_vector_ids,\n                       problem_student_code_ids ,\n                       problem_expected_code_ids ,\n                       expected_attention_mask,\n                       student_attention_mask):\n\n        metacognitive_vector_emb = self.metacognitive_emb(metacognitive_vector_ids)\n\n        problem_student_encoded = self.context_encoder(problem_student_code_ids,\n                                                attention_masks=student_attention_mask)\n        problem_expected_encoded = self.context_encoder(problem_expected_code_ids,\n                                                       attention_masks = expected_attention_mask)\n        #print(\"metacognitive_vector_emb\",metacognitive_vector_emb.shape)\n        #print(\"problem_student_encoded\",problem_student_encoded.shape)\n        #print(\"problem_expected_encoded\",problem_expected_encoded.shape)\n        \n        seq_length = problem_student_encoded.size(1)\n        token_embeds = self.token_embedding(problem_student_code_ids)\n        position_ids = torch.arange(0, seq_length, device=problem_student_code_ids.device).unsqueeze(0)\n        position_embeds = self.position_embedding(position_ids)\n        \n        inputs_embeds = token_embeds + position_embeds\n        inputs_embeds = self.dropout(inputs_embeds)\n      \n        student_initial_state = inputs_embeds\n        transformer_output = student_initial_state\n        for transformer_block in self.transformer_blocks:\n            transformer_output = transformer_block(student_initial_state, metacognitive_vector_emb, problem_expected_encoded, transformer_output)           \n       \n        logits = self.final_fc(transformer_output)    \n\n        return logits","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:54.464205Z","iopub.execute_input":"2025-01-01T05:20:54.464540Z","iopub.status.idle":"2025-01-01T05:20:54.473729Z","shell.execute_reply.started":"2025-01-01T05:20:54.464507Z","shell.execute_reply":"2025-01-01T05:20:54.472852Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"model = PAAModel()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:56.127519Z","iopub.execute_input":"2025-01-01T05:20:56.128023Z","iopub.status.idle":"2025-01-01T05:20:59.277261Z","shell.execute_reply.started":"2025-01-01T05:20:56.127980Z","shell.execute_reply":"2025-01-01T05:20:59.276281Z"}},"outputs":[],"execution_count":47},{"cell_type":"code","source":"model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:59.278523Z","iopub.execute_input":"2025-01-01T05:20:59.278891Z","iopub.status.idle":"2025-01-01T05:20:59.808533Z","shell.execute_reply.started":"2025-01-01T05:20:59.278865Z","shell.execute_reply":"2025-01-01T05:20:59.807724Z"}},"outputs":[{"execution_count":48,"output_type":"execute_result","data":{"text/plain":"PAAModel(\n  (context_encoder): ContextEncoder(\n    (t5_encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (fc): Linear(in_features=768, out_features=768, bias=True)\n  )\n  (metacognitive_emb): MetacognitionLayer(\n    (metacognitive_fc): Linear(in_features=16, out_features=768, bias=True)\n    (final_fc): Linear(in_features=768, out_features=768, bias=True)\n    (encoder): T5Stack(\n      (embed_tokens): Embedding(32128, 768)\n      (block): ModuleList(\n        (0): T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n                (relative_attention_bias): Embedding(32, 12)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n        (1-11): 11 x T5Block(\n          (layer): ModuleList(\n            (0): T5LayerSelfAttention(\n              (SelfAttention): T5Attention(\n                (q): Linear(in_features=768, out_features=768, bias=False)\n                (k): Linear(in_features=768, out_features=768, bias=False)\n                (v): Linear(in_features=768, out_features=768, bias=False)\n                (o): Linear(in_features=768, out_features=768, bias=False)\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (1): T5LayerFF(\n              (DenseReluDense): T5DenseActDense(\n                (wi): Linear(in_features=768, out_features=3072, bias=False)\n                (wo): Linear(in_features=3072, out_features=768, bias=False)\n                (dropout): Dropout(p=0.1, inplace=False)\n                (act): ReLU()\n              )\n              (layer_norm): T5LayerNorm()\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n        )\n      )\n      (final_layer_norm): T5LayerNorm()\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n  )\n  (token_embedding): Embedding(32100, 768)\n  (position_embedding): Embedding(512, 768)\n  (dropout): Dropout(p=0.1, inplace=False)\n  (self_attention): MultiheadAttention(\n    (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n  )\n  (transformer_blocks): ModuleList(\n    (0-3): 4 x CustomTransformerBlock(\n      (input_self_attention): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n      )\n      (context_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n      )\n      (persona_attn): MultiheadAttention(\n        (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n      )\n      (paa_layer): PAALayer(\n        (fc): Linear(in_features=1536, out_features=768, bias=True)\n        (sigmoid): Sigmoid()\n        (fc_out): Linear(in_features=768, out_features=768, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (mlp): Sequential(\n        (0): Linear(in_features=768, out_features=2048, bias=True)\n        (1): ReLU()\n        (2): Dropout(p=0.1, inplace=False)\n        (3): Linear(in_features=2048, out_features=768, bias=True)\n        (4): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n      )\n      (layer_norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n    )\n  )\n  (final_fc): Linear(in_features=768, out_features=32100, bias=True)\n  (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n)"},"metadata":{}}],"execution_count":48},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:59.810027Z","iopub.execute_input":"2025-01-01T05:20:59.810314Z","iopub.status.idle":"2025-01-01T05:20:59.814064Z","shell.execute_reply.started":"2025-01-01T05:20:59.810293Z","shell.execute_reply":"2025-01-01T05:20:59.813176Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"import torch.optim as optim\noptimizer = optim.AdamW(model.parameters(), lr=5e-5)\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:20:59.815213Z","iopub.execute_input":"2025-01-01T05:20:59.815495Z","iopub.status.idle":"2025-01-01T05:21:00.272743Z","shell.execute_reply.started":"2025-01-01T05:20:59.815473Z","shell.execute_reply":"2025-01-01T05:21:00.271978Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"LOSS = torch.nn.CrossEntropyLoss()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:00.273521Z","iopub.execute_input":"2025-01-01T05:21:00.274043Z","iopub.status.idle":"2025-01-01T05:21:00.277653Z","shell.execute_reply.started":"2025-01-01T05:21:00.274007Z","shell.execute_reply":"2025-01-01T05:21:00.276640Z"}},"outputs":[],"execution_count":51},{"cell_type":"code","source":"num_epochs = 200","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:00.278546Z","iopub.execute_input":"2025-01-01T05:21:00.278800Z","iopub.status.idle":"2025-01-01T05:21:00.290167Z","shell.execute_reply.started":"2025-01-01T05:21:00.278780Z","shell.execute_reply":"2025-01-01T05:21:00.289300Z"}},"outputs":[],"execution_count":52},{"cell_type":"code","source":"df_train = df[0:5000]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:00.291012Z","iopub.execute_input":"2025-01-01T05:21:00.291247Z","iopub.status.idle":"2025-01-01T05:21:00.302831Z","shell.execute_reply.started":"2025-01-01T05:21:00.291228Z","shell.execute_reply":"2025-01-01T05:21:00.302002Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"len(df_train)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:00.304382Z","iopub.execute_input":"2025-01-01T05:21:00.304608Z","iopub.status.idle":"2025-01-01T05:21:00.315479Z","shell.execute_reply.started":"2025-01-01T05:21:00.304589Z","shell.execute_reply":"2025-01-01T05:21:00.314821Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"5000"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"df_train.isnull().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:00.762730Z","iopub.execute_input":"2025-01-01T05:21:00.763041Z","iopub.status.idle":"2025-01-01T05:21:00.776473Z","shell.execute_reply.started":"2025-01-01T05:21:00.763017Z","shell.execute_reply":"2025-01-01T05:21:00.775535Z"}},"outputs":[{"execution_count":55,"output_type":"execute_result","data":{"text/plain":"Problem                      0\nStudent_code                 0\nExpected_code                0\nQ01                          0\nQ02                          0\nQ03                          0\nQ04                          0\nQ05                          0\nQ06                          0\nQ07                          0\nQ08                          0\nQ09                          0\nQ10                          0\nQ11                          0\nQ12                          0\nQ13                          0\nQ14                          0\nQ15                          0\nQ16                          0\nmetacognitive_vector         0\nmetacognitive_feedback       0\ncombined_problem_student     0\ncombined_problem_expected    0\ndtype: int64"},"metadata":{}}],"execution_count":55},{"cell_type":"code","source":"from torch.utils.data import DataLoader\ntrain_dataset = CustomDataset(df_train, t5_tokenizer , gpt2_tokenizer)\ntrain_dataloader = DataLoader(train_dataset , batch_size = 1 ,shuffle = True )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:02.498557Z","iopub.execute_input":"2025-01-01T05:21:02.498885Z","iopub.status.idle":"2025-01-01T05:21:02.503426Z","shell.execute_reply.started":"2025-01-01T05:21:02.498861Z","shell.execute_reply":"2025-01-01T05:21:02.502345Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"from torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-28T10:28:24.367282Z","iopub.execute_input":"2024-12-28T10:28:24.367618Z","iopub.status.idle":"2024-12-28T10:28:26.683372Z","shell.execute_reply.started":"2024-12-28T10:28:24.367588Z","shell.execute_reply":"2024-12-28T10:28:26.682062Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_dir = \"./checkpoints\"\nos.makedirs(checkpoint_dir, exist_ok=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:04.701474Z","iopub.execute_input":"2025-01-01T05:21:04.701812Z","iopub.status.idle":"2025-01-01T05:21:04.705582Z","shell.execute_reply.started":"2025-01-01T05:21:04.701781Z","shell.execute_reply":"2025-01-01T05:21:04.704830Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    print(f\"Training started for epoch {epoch + 1}/{num_epochs}\")\n    model.train()\n    total_loss = 0\n\n    for idx, (metacognition_vector_ids,\n              problem_student_code_ids,\n              problem_expected_code_ids,\n              student_code_ids,\n              target_ids) in enumerate(train_dataloader):\n        \n        metacognition_vector_ids = metacognition_vector_ids.to(device)\n        problem_student_code_ids = problem_student_code_ids.to(device)\n        problem_expected_code_ids = problem_expected_code_ids.to(device)\n        student_code_ids = student_code_ids.to(device)\n        target_ids = target_ids.to(device)\n        \n        #attention masking\n        student_attention_mask = (problem_student_code_ids != t5_pad_token_id).long().to(device)\n        expected_attention_mask = (problem_expected_code_ids != t5_pad_token_id).long().to(device)\n        \n\n        optimizer.zero_grad()\n        logits = model(metacognition_vector_ids,\n                       problem_student_code_ids ,\n                       problem_expected_code_ids ,\n                       expected_attention_mask,\n                       student_attention_mask)\n\n     \n        logits = logits.view(-1, logits.size(-1))\n        target_ids = target_ids.view(-1)\n\n       \n        loss = LOSS(logits, target_ids)\n        total_loss += loss.item()\n\n      \n        loss.backward()       \n        for name, param in model.named_parameters():\n            if 'context_encoder' in name:\n                assert param.grad is None, f\"Gradients found in frozen encoder {name}\"\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)       \n        optimizer.step()    \n        \n        if idx % 10 == 0:\n            print(f\"Batch {idx + 1}/{len(train_dataloader)} | Loss: {loss.item():.4f}\" , end='\\r')\n\n\n\n\n    \n                    \n    if epoch % 10 ==0 :\n            for name, param in model.named_parameters():\n                if param.requires_grad and param.grad is not None:\n                    print(f\"Layer: {name} | Grad Norm: {param.grad.norm().item()}\")\n                elif param.requires_grad:\n                    print(f\"Layer: {name} | Grad: None\")       \n    \n    if (epoch + 1) % 20 == 0:\n        checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch + 1}.pth\")\n        torch.save({\n            'epoch': epoch + 1,\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': total_loss / max(len(train_dataloader), 1),\n        }, checkpoint_path)\n        print(f\"Checkpoint saved at {checkpoint_path}\")\n\n   \n    avg_loss = total_loss / max(len(train_dataloader), 1)\n    #writer.add_scalar(\"Loss/train\", avg_loss, epoch + 1)\n    print(f\"Epoch [{epoch + 1}/{num_epochs}] completed | Average Loss: {avg_loss:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T05:21:06.086015Z","iopub.execute_input":"2025-01-01T05:21:06.086381Z","iopub.status.idle":"2025-01-01T14:05:41.259494Z","shell.execute_reply.started":"2025-01-01T05:21:06.086357Z","shell.execute_reply":"2025-01-01T14:05:41.258027Z"}},"outputs":[{"name":"stdout","text":"Training started for epoch 1/200\nLayer: token_embedding.weight | Grad Norm: 0.005470000207424164\nLayer: position_embedding.weight | Grad Norm: 0.013493569567799568\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.33868297934532166\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.01148882694542408\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.04298647493124008\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.002771911211311817\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.05332319438457489\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.03015540912747383\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.01965225487947464\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.012919711880385876\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.026828696951270103\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.00132444326300174\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.04786653816699982\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.0033697527833282948\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.054309405386447906\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0018933741375803947\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.08752764761447906\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.014439516700804234\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.08666812628507614\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.012626600451767445\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.2904481291770935\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.034895159304142\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.013073146343231201\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.015977533534169197\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.014688427560031414\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.01710457168519497\nLayer: final_fc.weight | Grad Norm: 0.8773438930511475\nLayer: final_fc.bias | Grad Norm: 0.032027170062065125\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [1/200] completed | Average Loss: 4.6309\nTraining started for epoch 2/200\nEpoch [2/200] completed | Average Loss: 4.4583\nTraining started for epoch 3/200\nEpoch [3/200] completed | Average Loss: 4.4147\nTraining started for epoch 4/200\nEpoch [4/200] completed | Average Loss: 4.3945\nTraining started for epoch 5/200\nEpoch [5/200] completed | Average Loss: 4.3800\nTraining started for epoch 6/200\nEpoch [6/200] completed | Average Loss: 4.3699\nTraining started for epoch 7/200\nEpoch [7/200] completed | Average Loss: 4.3600\nTraining started for epoch 8/200\nEpoch [8/200] completed | Average Loss: 4.3515\nTraining started for epoch 9/200\nEpoch [9/200] completed | Average Loss: 4.3418\nTraining started for epoch 10/200\nEpoch [10/200] completed | Average Loss: 4.3319\nTraining started for epoch 11/200\nLayer: token_embedding.weight | Grad Norm: 0.005219121929258108\nLayer: position_embedding.weight | Grad Norm: 0.007860822603106499\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.14588996767997742\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.004599427804350853\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.03284073248505592\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0008830137085169554\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.02782459370791912\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.015943342819809914\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.012851275503635406\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.00818733312189579\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.05630262941122055\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.002243374241515994\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.0795212835073471\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.0021870865020900965\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.08858872205018997\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0006324338028207421\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.13176609575748444\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.006622742395848036\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.09771431982517242\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.005229537840932608\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.1731201708316803\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.019203288480639458\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.01554575003683567\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.01551246177405119\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.02331734262406826\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.02038533240556717\nLayer: final_fc.weight | Grad Norm: 0.9478856325149536\nLayer: final_fc.bias | Grad Norm: 0.04079399257898331\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [11/200] completed | Average Loss: 4.3215\nTraining started for epoch 12/200\nEpoch [12/200] completed | Average Loss: 4.3109\nTraining started for epoch 13/200\nEpoch [13/200] completed | Average Loss: 4.2993\nTraining started for epoch 14/200\nEpoch [14/200] completed | Average Loss: 4.2872\nTraining started for epoch 15/200\nEpoch [15/200] completed | Average Loss: 4.2745\nTraining started for epoch 16/200\nEpoch [16/200] completed | Average Loss: 4.2622\nTraining started for epoch 17/200\nEpoch [17/200] completed | Average Loss: 4.2486\nTraining started for epoch 18/200\nEpoch [18/200] completed | Average Loss: 4.2352\nTraining started for epoch 19/200\nEpoch [19/200] completed | Average Loss: 4.2206\nTraining started for epoch 20/200\nCheckpoint saved at ./checkpoints/model_epoch_20.pth\nEpoch [20/200] completed | Average Loss: 4.2073\nTraining started for epoch 21/200\nLayer: token_embedding.weight | Grad Norm: 0.00611788360401988\nLayer: position_embedding.weight | Grad Norm: 0.007347406353801489\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.14736324548721313\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.004542076960206032\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.05125303193926811\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0006238233181647956\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.058885931968688965\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.03301859274506569\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.03519327566027641\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.01734965480864048\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.09121081978082657\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.0036322318483144045\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.15120764076709747\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.004147558938711882\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.19117802381515503\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.00101150618866086\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.32632946968078613\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.012677914462983608\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.34915849566459656\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.014734297059476376\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.44793665409088135\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.05479990690946579\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.016290580853819847\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.01548963226377964\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.01702067442238331\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.015301755629479885\nLayer: final_fc.weight | Grad Norm: 0.6837649941444397\nLayer: final_fc.bias | Grad Norm: 0.026237471029162407\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [21/200] completed | Average Loss: 4.1934\nTraining started for epoch 22/200\nEpoch [22/200] completed | Average Loss: 4.1793\nTraining started for epoch 23/200\nEpoch [23/200] completed | Average Loss: 4.1651\nTraining started for epoch 24/200\nEpoch [24/200] completed | Average Loss: 4.1517\nTraining started for epoch 25/200\nEpoch [25/200] completed | Average Loss: 4.1372\nTraining started for epoch 26/200\nEpoch [26/200] completed | Average Loss: 4.1235\nTraining started for epoch 27/200\nEpoch [27/200] completed | Average Loss: 4.1104\nTraining started for epoch 28/200\nEpoch [28/200] completed | Average Loss: 4.0973\nTraining started for epoch 29/200\nEpoch [29/200] completed | Average Loss: 4.0841\nTraining started for epoch 30/200\nEpoch [30/200] completed | Average Loss: 4.0719\nTraining started for epoch 31/200\nLayer: token_embedding.weight | Grad Norm: 0.006475924979895353\nLayer: position_embedding.weight | Grad Norm: 0.006420412566512823\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.12621498107910156\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.003249362576752901\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.061921026557683945\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0007163979462347925\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.021513286978006363\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.012328657321631908\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.023867139592766762\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.011653759516775608\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.11118349432945251\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.0044685471802949905\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.1537753790616989\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.004263958428055048\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.21766223013401031\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0010370376985520124\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.3278484642505646\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.011546247638761997\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.3295057415962219\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.01276294607669115\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.4090553820133209\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.06103277578949928\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.017403043806552887\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.018673915416002274\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.018726451322436333\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.017544619739055634\nLayer: final_fc.weight | Grad Norm: 0.7110046148300171\nLayer: final_fc.bias | Grad Norm: 0.03394252061843872\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [31/200] completed | Average Loss: 4.0595\nTraining started for epoch 32/200\nEpoch [32/200] completed | Average Loss: 4.0483\nTraining started for epoch 33/200\nEpoch [33/200] completed | Average Loss: 4.0367\nTraining started for epoch 34/200\nEpoch [34/200] completed | Average Loss: 4.0256\nTraining started for epoch 35/200\nEpoch [35/200] completed | Average Loss: 4.0153\nTraining started for epoch 36/200\nEpoch [36/200] completed | Average Loss: 4.0043\nTraining started for epoch 37/200\nEpoch [37/200] completed | Average Loss: 3.9950\nTraining started for epoch 38/200\nEpoch [38/200] completed | Average Loss: 3.9849\nTraining started for epoch 39/200\nEpoch [39/200] completed | Average Loss: 3.9762\nTraining started for epoch 40/200\nCheckpoint saved at ./checkpoints/model_epoch_40.pth\nEpoch [40/200] completed | Average Loss: 3.9675\nTraining started for epoch 41/200\nLayer: token_embedding.weight | Grad Norm: 0.009914482943713665\nLayer: position_embedding.weight | Grad Norm: 0.01000633928924799\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.19154177606105804\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.005733299534767866\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.0817553922533989\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0011317352764308453\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.053175896406173706\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.031288813799619675\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.039479441940784454\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.020695989951491356\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.18616007268428802\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.006467336788773537\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.24341171979904175\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.006626802030950785\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.2536394000053406\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0012417465914040804\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.402627557516098\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.018964510411024094\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.42693519592285156\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.021989643573760986\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.4758259356021881\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.09475171566009521\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.014092333614826202\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.01649046316742897\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.010556833818554878\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.011782112531363964\nLayer: final_fc.weight | Grad Norm: 0.45912498235702515\nLayer: final_fc.bias | Grad Norm: 0.012052271515130997\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [41/200] completed | Average Loss: 3.9588\nTraining started for epoch 42/200\nEpoch [42/200] completed | Average Loss: 3.9507\nTraining started for epoch 43/200\nEpoch [43/200] completed | Average Loss: 3.9430\nTraining started for epoch 44/200\nEpoch [44/200] completed | Average Loss: 3.9349\nTraining started for epoch 45/200\nEpoch [45/200] completed | Average Loss: 3.9279\nTraining started for epoch 46/200\nEpoch [46/200] completed | Average Loss: 3.9202\nTraining started for epoch 47/200\nEpoch [47/200] completed | Average Loss: 3.9142\nTraining started for epoch 48/200\nEpoch [48/200] completed | Average Loss: 3.9076\nTraining started for epoch 49/200\nEpoch [49/200] completed | Average Loss: 3.9007\nTraining started for epoch 50/200\nEpoch [50/200] completed | Average Loss: 3.8950\nTraining started for epoch 51/200\nLayer: token_embedding.weight | Grad Norm: 0.00702125858515501\nLayer: position_embedding.weight | Grad Norm: 0.007352312095463276\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.11398828774690628\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.0036037166137248278\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.0808311328291893\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0009935077978298068\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.03336275741457939\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.01907406374812126\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.035334642976522446\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.017141735181212425\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.07386256009340286\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.003133609425276518\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.15807898342609406\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.00474876444786787\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.2557229697704315\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0012404295848682523\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.3869147002696991\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.013451219536364079\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.3591516315937042\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.013227689079940319\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.3997267186641693\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.06933058053255081\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.023584792390465736\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.02300434187054634\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.021880585700273514\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.01917046122252941\nLayer: final_fc.weight | Grad Norm: 0.6595020890235901\nLayer: final_fc.bias | Grad Norm: 0.030848145484924316\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [51/200] completed | Average Loss: 3.8895\nTraining started for epoch 52/200\nEpoch [52/200] completed | Average Loss: 3.8838\nTraining started for epoch 53/200\nEpoch [53/200] completed | Average Loss: 3.8781\nTraining started for epoch 54/200\nEpoch [54/200] completed | Average Loss: 3.8723\nTraining started for epoch 55/200\nEpoch [55/200] completed | Average Loss: 3.8679\nTraining started for epoch 56/200\nEpoch [56/200] completed | Average Loss: 3.8623\nTraining started for epoch 57/200\nEpoch [57/200] completed | Average Loss: 3.8576\nTraining started for epoch 58/200\nEpoch [58/200] completed | Average Loss: 3.8523\nTraining started for epoch 59/200\nEpoch [59/200] completed | Average Loss: 3.8493\nTraining started for epoch 60/200\nCheckpoint saved at ./checkpoints/model_epoch_60.pth\nEpoch [60/200] completed | Average Loss: 3.8440\nTraining started for epoch 61/200\nLayer: token_embedding.weight | Grad Norm: 0.004214275162667036\nLayer: position_embedding.weight | Grad Norm: 0.005690000951290131\nLayer: self_attention.in_proj_weight | Grad: None\nLayer: self_attention.in_proj_bias | Grad: None\nLayer: self_attention.out_proj.weight | Grad: None\nLayer: self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.0.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.0.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.0.mlp.0.weight | Grad: None\nLayer: transformer_blocks.0.mlp.0.bias | Grad: None\nLayer: transformer_blocks.0.mlp.3.weight | Grad: None\nLayer: transformer_blocks.0.mlp.3.bias | Grad: None\nLayer: transformer_blocks.0.mlp.4.weight | Grad: None\nLayer: transformer_blocks.0.mlp.4.bias | Grad: None\nLayer: transformer_blocks.0.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.0.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.1.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.1.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.1.mlp.0.weight | Grad: None\nLayer: transformer_blocks.1.mlp.0.bias | Grad: None\nLayer: transformer_blocks.1.mlp.3.weight | Grad: None\nLayer: transformer_blocks.1.mlp.3.bias | Grad: None\nLayer: transformer_blocks.1.mlp.4.weight | Grad: None\nLayer: transformer_blocks.1.mlp.4.bias | Grad: None\nLayer: transformer_blocks.1.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.1.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.input_self_attention.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.context_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.context_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.in_proj_bias | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.weight | Grad: None\nLayer: transformer_blocks.2.persona_attn.out_proj.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc.bias | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.weight | Grad: None\nLayer: transformer_blocks.2.paa_layer.fc_out.bias | Grad: None\nLayer: transformer_blocks.2.mlp.0.weight | Grad: None\nLayer: transformer_blocks.2.mlp.0.bias | Grad: None\nLayer: transformer_blocks.2.mlp.3.weight | Grad: None\nLayer: transformer_blocks.2.mlp.3.bias | Grad: None\nLayer: transformer_blocks.2.mlp.4.weight | Grad: None\nLayer: transformer_blocks.2.mlp.4.bias | Grad: None\nLayer: transformer_blocks.2.layer_norm2.weight | Grad: None\nLayer: transformer_blocks.2.layer_norm2.bias | Grad: None\nLayer: transformer_blocks.3.input_self_attention.in_proj_weight | Grad Norm: 0.07366671413183212\nLayer: transformer_blocks.3.input_self_attention.in_proj_bias | Grad Norm: 0.002983539830893278\nLayer: transformer_blocks.3.input_self_attention.out_proj.weight | Grad Norm: 0.07904227077960968\nLayer: transformer_blocks.3.input_self_attention.out_proj.bias | Grad Norm: 0.0010450620902702212\nLayer: transformer_blocks.3.context_attn.in_proj_weight | Grad Norm: 0.04082456976175308\nLayer: transformer_blocks.3.context_attn.in_proj_bias | Grad Norm: 0.024178529158234596\nLayer: transformer_blocks.3.context_attn.out_proj.weight | Grad Norm: 0.033538930118083954\nLayer: transformer_blocks.3.context_attn.out_proj.bias | Grad Norm: 0.017437314614653587\nLayer: transformer_blocks.3.persona_attn.in_proj_weight | Grad Norm: 0.08019928634166718\nLayer: transformer_blocks.3.persona_attn.in_proj_bias | Grad Norm: 0.0031617898494005203\nLayer: transformer_blocks.3.persona_attn.out_proj.weight | Grad Norm: 0.17347048223018646\nLayer: transformer_blocks.3.persona_attn.out_proj.bias | Grad Norm: 0.004706882406026125\nLayer: transformer_blocks.3.paa_layer.fc.weight | Grad Norm: 0.2513836920261383\nLayer: transformer_blocks.3.paa_layer.fc.bias | Grad Norm: 0.0011321253841742873\nLayer: transformer_blocks.3.paa_layer.fc_out.weight | Grad Norm: 0.4070877432823181\nLayer: transformer_blocks.3.paa_layer.fc_out.bias | Grad Norm: 0.01474224217236042\nLayer: transformer_blocks.3.mlp.0.weight | Grad Norm: 0.3796793818473816\nLayer: transformer_blocks.3.mlp.0.bias | Grad Norm: 0.01548556424677372\nLayer: transformer_blocks.3.mlp.3.weight | Grad Norm: 0.4897298812866211\nLayer: transformer_blocks.3.mlp.3.bias | Grad Norm: 0.11210671812295914\nLayer: transformer_blocks.3.mlp.4.weight | Grad Norm: 0.025693444535136223\nLayer: transformer_blocks.3.mlp.4.bias | Grad Norm: 0.03078250214457512\nLayer: transformer_blocks.3.layer_norm2.weight | Grad Norm: 0.020490914583206177\nLayer: transformer_blocks.3.layer_norm2.bias | Grad Norm: 0.02254469133913517\nLayer: final_fc.weight | Grad Norm: 0.5648178458213806\nLayer: final_fc.bias | Grad Norm: 0.023266762495040894\nLayer: layer_norm.weight | Grad: None\nLayer: layer_norm.bias | Grad: None\nEpoch [61/200] completed | Average Loss: 3.8402\nTraining started for epoch 62/200\nEpoch [62/200] completed | Average Loss: 3.8351\nTraining started for epoch 63/200\nEpoch [63/200] completed | Average Loss: 3.8313\nTraining started for epoch 64/200\nEpoch [64/200] completed | Average Loss: 3.8271\nTraining started for epoch 65/200\nEpoch [65/200] completed | Average Loss: 3.8234\nTraining started for epoch 66/200\nBatch 4901/5000 | Loss: 3.9553\r","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-58-675b958bee99>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         logits = model(metacognition_vector_ids,\n\u001b[0m\u001b[1;32m     25\u001b[0m                        \u001b[0mproblem_student_code_ids\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m                        \u001b[0mproblem_expected_code_ids\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-46-ec6236ea2241>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, metacognitive_vector_ids, problem_student_code_ids, problem_expected_code_ids, expected_attention_mask, student_attention_mask)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudent_initial_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtransformer_block\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_blocks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0mtransformer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudent_initial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetacognitive_vector_emb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproblem_expected_encoded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfinal_fc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-43-cf08448578ac>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, student_initial_state, encoded_persona, encoded_context, current_state)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m#print(\"hr\",hR.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#print(\"encoded context\",encoded_context.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moC\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext_attn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoded_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1273\u001b[0m                 is_causal=is_causal)\n\u001b[1;32m   1274\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1276\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_heads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_proj_bias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   5418\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0muse_separate_proj_weight\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5419\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0min_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is False but in_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5420\u001b[0;31m         \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_in_projection_packed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0min_proj_bias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5421\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5422\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mq_proj_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"use_separate_proj_weight is True but q_proj_weight is None\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36m_in_projection_packed\u001b[0;34m(q, k, v, w, b)\u001b[0m\n\u001b[1;32m   4930\u001b[0m                 \u001b[0mb_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_kv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4931\u001b[0m             \u001b[0mq_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_q\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_q\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4932\u001b[0;31m             \u001b[0mkv_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw_kv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb_kv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4933\u001b[0m             \u001b[0;31m# reshape to 2, E and not E, 2 is deliberate for better memory coalescing and keeping same order as chunk()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4934\u001b[0m             \u001b[0mkv_proj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkv_proj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":58},{"cell_type":"code","source":"torch.save(model.state_dict(), 'paamodel.pth')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:46.026131Z","iopub.execute_input":"2025-01-01T14:05:46.026445Z","iopub.status.idle":"2025-01-01T14:05:47.902123Z","shell.execute_reply.started":"2025-01-01T14:05:46.026417Z","shell.execute_reply":"2025-01-01T14:05:47.901439Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"model = PAAModel()\n\n# Load the saved state dict\nmodel.load_state_dict(torch.load('paamodel.pth'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:47.903427Z","iopub.execute_input":"2025-01-01T14:05:47.903728Z","iopub.status.idle":"2025-01-01T14:05:53.431943Z","shell.execute_reply.started":"2025-01-01T14:05:47.903699Z","shell.execute_reply":"2025-01-01T14:05:53.431194Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-60-576f8403c810>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  model.load_state_dict(torch.load('paamodel.pth'))\n","output_type":"stream"},{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"df_eval = df[9999:10000].reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:53.433194Z","iopub.execute_input":"2025-01-01T14:05:53.433449Z","iopub.status.idle":"2025-01-01T14:05:53.437970Z","shell.execute_reply.started":"2025-01-01T14:05:53.433432Z","shell.execute_reply":"2025-01-01T14:05:53.437287Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"df_eval","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:53.439038Z","iopub.execute_input":"2025-01-01T14:05:53.439301Z","iopub.status.idle":"2025-01-01T14:05:53.463518Z","shell.execute_reply.started":"2025-01-01T14:05:53.439280Z","shell.execute_reply":"2025-01-01T14:05:53.462685Z"}},"outputs":[{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"                                             Problem  \\\n0  Amicable numbers are pairs of numbers for whic...   \n\n                                        Student_code  \\\n0  def named_are_amicable():                for n...   \n\n                                       Expected_code            Q01  \\\n0  def sum_of_divisors(number):          divisors...  2 : Sometimes   \n\n             Q02            Q03        Q04               Q05            Q06  \\\n0  2 : Sometimes  2 : Sometimes  3 : Often  1 : Almost Never  2 : Sometimes   \n\n             Q07  ...            Q11            Q12               Q13  \\\n0  2 : Sometimes  ...  2 : Sometimes  2 : Sometimes  1 : Almost Never   \n\n             Q14        Q15            Q16  \\\n0  2 : Sometimes  3 : Often  2 : Sometimes   \n\n                                metacognitive_vector  \\\n0  ['2 ', '2 ', '2 ', '3 ', '1 ', '2 ', '2 ', '2 ...   \n\n                              metacognitive_feedback  \\\n0  Your implementation has a few significant issu...   \n\n                            combined_problem_student  \\\n0  Amicable numbers are pairs of numbers for whic...   \n\n                           combined_problem_expected  \n0  Amicable numbers are pairs of numbers for whic...  \n\n[1 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Problem</th>\n      <th>Student_code</th>\n      <th>Expected_code</th>\n      <th>Q01</th>\n      <th>Q02</th>\n      <th>Q03</th>\n      <th>Q04</th>\n      <th>Q05</th>\n      <th>Q06</th>\n      <th>Q07</th>\n      <th>...</th>\n      <th>Q11</th>\n      <th>Q12</th>\n      <th>Q13</th>\n      <th>Q14</th>\n      <th>Q15</th>\n      <th>Q16</th>\n      <th>metacognitive_vector</th>\n      <th>metacognitive_feedback</th>\n      <th>combined_problem_student</th>\n      <th>combined_problem_expected</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Amicable numbers are pairs of numbers for whic...</td>\n      <td>def named_are_amicable():                for n...</td>\n      <td>def sum_of_divisors(number):          divisors...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>1 : Almost Never</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>...</td>\n      <td>2 : Sometimes</td>\n      <td>2 : Sometimes</td>\n      <td>1 : Almost Never</td>\n      <td>2 : Sometimes</td>\n      <td>3 : Often</td>\n      <td>2 : Sometimes</td>\n      <td>['2 ', '2 ', '2 ', '3 ', '1 ', '2 ', '2 ', '2 ...</td>\n      <td>Your implementation has a few significant issu...</td>\n      <td>Amicable numbers are pairs of numbers for whic...</td>\n      <td>Amicable numbers are pairs of numbers for whic...</td>\n    </tr>\n  </tbody>\n</table>\n<p>1 rows × 23 columns</p>\n</div>"},"metadata":{}}],"execution_count":62},{"cell_type":"code","source":"eval_dataset = CustomDataset(df_eval, t5_tokenizer,gpt2_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:53.464292Z","iopub.execute_input":"2025-01-01T14:05:53.464577Z","iopub.status.idle":"2025-01-01T14:05:53.476444Z","shell.execute_reply.started":"2025-01-01T14:05:53.464546Z","shell.execute_reply":"2025-01-01T14:05:53.475500Z"}},"outputs":[],"execution_count":63},{"cell_type":"code","source":"\n\ndef inference(model,gpt2_tokenizer, t5_tokenizer, eval_dataset, device):\n    model.eval()\n    model.to(device) \n\n    metacognitive_vector_ids, problem_student_code_ids, problem_expected_code_ids,student_code_ids, target_ids = eval_dataset[0]\n\n    metacognitive_tensor = metacognitive_vector_ids.unsqueeze(0).to(device)  \n    problem_student_code_tensor = problem_student_code_ids.unsqueeze(0).to(device)\n    problem_expected_code_tensor = problem_expected_code_ids.unsqueeze(0).to(device)\n    target_tensor = target_ids.unsqueeze(0).to(device)\n\n    student_attention_mask = (problem_student_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n    expected_attention_mask = (problem_expected_code_tensor != t5_tokenizer.pad_token_id).long().to(device)\n\n    \n    with torch.no_grad():         \n        \n        logits = model(\n            metacognitive_vector_ids=metacognitive_tensor,\n            problem_student_code_ids=problem_student_code_tensor,\n            problem_expected_code_ids=problem_expected_code_tensor,\n            expected_attention_mask=expected_attention_mask,\n            student_attention_mask=student_attention_mask\n        )\n        \n        predictions = logits.argmax(dim=-1).squeeze().tolist()  \n        decoded_text = t5_tokenizer.decode(predictions, skip_special_tokens=True)\n\n        \n        return predictions, decoded_text\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:53.477335Z","iopub.execute_input":"2025-01-01T14:05:53.477699Z","iopub.status.idle":"2025-01-01T14:05:53.492358Z","shell.execute_reply.started":"2025-01-01T14:05:53.477654Z","shell.execute_reply":"2025-01-01T14:05:53.491671Z"}},"outputs":[],"execution_count":64},{"cell_type":"code","source":"predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:05:55.118224Z","iopub.execute_input":"2025-01-01T14:05:55.118568Z","iopub.status.idle":"2025-01-01T14:06:03.016500Z","shell.execute_reply.started":"2025-01-01T14:05:55.118543Z","shell.execute_reply":"2025-01-01T14:06:03.015753Z"}},"outputs":[],"execution_count":65},{"cell_type":"code","source":"print(\"Predicted Tokens:\", predictions)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:06:03.017558Z","iopub.execute_input":"2025-01-01T14:06:03.018117Z","iopub.status.idle":"2025-01-01T14:06:03.023471Z","shell.execute_reply.started":"2025-01-01T14:06:03.018060Z","shell.execute_reply":"2025-01-01T14:06:03.022594Z"}},"outputs":[{"name":"stdout","text":"Predicted Tokens: [0, 0, 0, 0, 8, 0, 0, 0, 0, 3, 3, 0, 0, 3, 3, 0, 0, 0, 0, 3, 5, 0, 0, 3, 8, 5, 0, 0, 3, 0, 0, 0, 0, 12, 5, 8, 3, 0, 0, 8, 8, 0, 0, 6, 3, 5, 0, 8, 8, 0, 5, 0, 5, 0, 3, 0, 0, 0, 0, 0, 8, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 8, 0, 0, 3, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 8, 0, 8, 0, 0, 0, 0, 8, 0, 3, 0, 3, 0, 0, 0, 0, 0, 8, 3, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 12, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 8, 0, 0, 8, 3, 0, 0, 3, 3, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 696, 0, 12, 11795, 8, 0, 0, 0, 12, 6, 0, 5, 0, 0, 0, 12, 5, 8, 0, 0, 3, 0, 8, 0, 0, 0, 6, 0, 0, 8, 3, 0, 8, 0, 0, 0, 0, 0, 3, 0, 8, 0, 0, 3, 0, 0, 3, 8, 0, 3, 5, 8, 0, 4179, 33, 0, 3, 8, 0, 3, 8, 0, 0, 3, 5, 7, 6, 8, 0, 0, 0, 0, 3, 0, 0, 3, 5, 0, 0, 8, 8, 0, 3, 5, 0, 3, 3, 0, 0, 8, 0, 3, 3, 0, 0, 8, 7, 0, 12, 0, 0, 8, 0, 0, 32, 3, 3, 0, 0, 3, 0, 3, 3, 8, 8, 3, 0, 12, 0, 0, 8, 0, 12, 0, 0, 0, 3, 3, 0, 5, 8, 0, 12, 0, 4179, 0, 8, 0, 0, 12, 0, 0, 0, 8, 0, 0, 3, 12, 0, 8, 0, 0, 0, 6, 0, 0, 8, 0, 0, 0, 0, 33, 0, 0, 0, 0, 0, 0, 0, 5, 0, 3, 0, 0, 33, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 6, 0, 8, 3, 0, 3, 0, 0, 12, 5, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 3, 0, 0, 12, 3, 8, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 3, 0, 0, 12, 3, 0, 0, 0, 8, 8, 0, 0, 0, 0, 3, 0, 0, 12, 3, 0, 0, 0, 0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}],"execution_count":66},{"cell_type":"code","source":"print(\"Decoded Text:\", decoded_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T14:06:03.024499Z","iopub.execute_input":"2025-01-01T14:06:03.024799Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def load_checkpoint(checkpoint_path, model, optimizer=None):\n    checkpoint = torch.load(checkpoint_path)\n    model.load_state_dict(checkpoint['model_state_dict'])\n    if optimizer:\n        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n    epoch = checkpoint['epoch']\n    loss = checkpoint['loss']\n    print(f\"Checkpoint loaded: Epoch {epoch}, Loss: {loss:.4f}\")\n    return model, optimizer, epoch, loss","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = \"./checkpoints/model_epoch_89.pth\"\nmodel, optimizer, start_epoch, _ = load_checkpoint(checkpoint_path, model, optimizer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"checkpoint_path = \"./checkpoints/model_epoch_10.pth\"\ncheckpoint = torch.load(checkpoint_path, map_location=torch.device('cpu'))  # Use GPU if available: 'cuda'\nmodel.load_state_dict(checkpoint['model_state_dict'])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"len(df)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_eval1 = df[449:450].reset_index(drop=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:22:21.77148Z","iopub.execute_input":"2024-12-26T19:22:21.771768Z","iopub.status.idle":"2024-12-26T19:22:21.776543Z","shell.execute_reply.started":"2024-12-26T19:22:21.771748Z","shell.execute_reply":"2024-12-26T19:22:21.775528Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"eval_dataset1 = CustomDataset(df_eval1, t5_tokenizer,gpt2_tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:22:26.49086Z","iopub.execute_input":"2024-12-26T19:22:26.491157Z","iopub.status.idle":"2024-12-26T19:22:26.495243Z","shell.execute_reply.started":"2024-12-26T19:22:26.491134Z","shell.execute_reply":"2024-12-26T19:22:26.494174Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions, decoded_text = inference(model, gpt2_tokenizer, t5_tokenizer, eval_dataset1, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:22:39.226221Z","iopub.execute_input":"2024-12-26T19:22:39.226559Z","iopub.status.idle":"2024-12-26T19:22:39.583175Z","shell.execute_reply.started":"2024-12-26T19:22:39.226534Z","shell.execute_reply":"2024-12-26T19:22:39.582494Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"Decoded Text:\", decoded_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-26T19:22:43.546251Z","iopub.execute_input":"2024-12-26T19:22:43.546672Z","iopub.status.idle":"2024-12-26T19:22:43.552108Z","shell.execute_reply.started":"2024-12-26T19:22:43.546636Z","shell.execute_reply":"2024-12-26T19:22:43.551007Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}